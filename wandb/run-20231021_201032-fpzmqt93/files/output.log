[32m[10/21 20:10:41 detectron2]: [39mModel:
SamDetector(
  (backbone): SAMVitDet(
    (fpn1): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (1): Norm2d(
        (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): GELU()
      (3): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn2): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn3): Identity()
    (fpn4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): samAnchorPromptRoiHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): SamRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): samMaskHead(
      (point_emb): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Flatten(start_dim=1, end_dim=-1)
        (4): Linear(in_features=12544, out_features=256, bias=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=True)
        (7): ReLU(inplace=True)
        (8): Linear(in_features=256, out_features=2048, bias=True)
      )
    )
    (generator_pe): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
  )
  (sam): Sam(
    (image_encoder): TinyViT(
      (patch_embed): PatchEmbed(
        (seq): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU()
          (2): Conv2d_BN(
            (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layers): ModuleList(
        (0): ConvLayer(
          (blocks): ModuleList(
            (0): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
            (1): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (1): BasicLayer(
          dim=128, input_resolution=(128, 128), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (2): BasicLayer(
          dim=160, input_resolution=(64, 64), depth=6
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (3): BasicLayer(
          dim=320, input_resolution=(64, 64), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (neck): Sequential(
        (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): LayerNorm2d()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (3): LayerNorm2d()
      )
    )
    (prompt_encoder): PromptEncoder(
      (pe_layer): PositionEmbeddingRandom()
      (point_embeddings): ModuleList(
        (0): Embedding(1, 256)
        (1): Embedding(1, 256)
        (2): Embedding(1, 256)
        (3): Embedding(1, 256)
      )
      (not_a_point_embed): Embedding(1, 256)
      (mask_downscaling): Sequential(
        (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
        (4): LayerNorm2d()
        (5): GELU()
        (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (no_mask_embed): Embedding(1, 256)
    )
    (mask_decoder): MaskDecoder(
      (transformer): TwoWayTransformer(
        (layers): ModuleList(
          (0): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
          (1): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
        )
        (final_attn_token_to_image): Attention(
          (q_proj): Linear(in_features=256, out_features=128, bias=True)
          (k_proj): Linear(in_features=256, out_features=128, bias=True)
          (v_proj): Linear(in_features=256, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (iou_token): Embedding(1, 256)
      (mask_tokens): Embedding(4, 256)
      (output_upscaling): Sequential(
        (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
        (4): GELU()
      )
      (output_hypernetworks_mlps): ModuleList(
        (0): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (3): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
      )
    )
  )
)
[32m[10/21 20:10:41 d2.checkpoint.detection_checkpoint]: [39m[DetectionCheckpointer] Loading from mobile_sam.pt ...
[32m[10/21 20:10:41 fvcore.common.checkpoint]: [39m[Checkpointer] Loading from mobile_sam.pt ...
[32m[10/21 20:10:41 d2.checkpoint.c2_model_loading]: [39mFollowing weights matched with submodule sam - Total num: 168
[31m[5mWARNING[39m[25m [32m[10/21 20:10:41 fvcore.common.checkpoint]: [39mSome model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn1.0.{bias, weight}
[34mbackbone.fpn1.1.ln.{bias, weight}
[34mbackbone.fpn1.3.{bias, weight}
[34mbackbone.fpn2.0.{bias, weight}
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}
[34mproposal_generator.rpn_head.conv.{bias, weight}
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}
[34mroi_heads.box_head.fc1.{bias, weight}
[34mroi_heads.box_head.fc2.{bias, weight}
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}
[34mroi_heads.box_predictor.cls_score.{bias, weight}
[34mroi_heads.mask_head.point_emb.0.{bias, weight}
[34mroi_heads.mask_head.point_emb.1.{bias, running_mean, running_var, weight}
[34mroi_heads.mask_head.point_emb.4.{bias, weight}
[34mroi_heads.mask_head.point_emb.6.{bias, weight}
[34mroi_heads.mask_head.point_emb.8.{bias, weight}
[31m[5mWARNING[39m[25m [32m[10/21 20:10:41 fvcore.common.checkpoint]: [39mThe checkpoint state_dict contains keys that are not used by the model:
  [35mimage_encoder.head.{bias, weight}
  [35mimage_encoder.norm_head.{bias, weight}
  [35mmask_decoder.iou_prediction_head.layers.0.{bias, weight}
  [35mmask_decoder.iou_prediction_head.layers.1.{bias, weight}
  [35mmask_decoder.iou_prediction_head.layers.2.{bias, weight}
[32m[10/21 20:10:41 d2.data.dataset_mapper]: [39m[DatasetMapper] Augmentations used in training: [ResizeLongestSizeFlip(longest_length=1024), RandomFlip(prob=0.5)]
[32m[10/21 20:10:56 d2.data.datasets.coco]: [39mLoading datasets/coco/annotations/instances_train2017.json takes 14.54 seconds.
[32m[10/21 20:10:57 d2.data.datasets.coco]: [39mLoaded 118287 images in COCO format from datasets/coco/annotations/instances_train2017.json
[32m[10/21 20:11:04 d2.data.build]: [39mRemoved 1021 images with no usable annotations. 117266 images left.
[32m[10/21 20:11:07 d2.data.build]: [39mDistribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
[36m|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
[36m|    person     | 257253       |   bicycle    | 7056         |      car      | 43533        |
[36m|  motorcycle   | 8654         |   airplane   | 5129         |      bus      | 6061         |
[36m|     train     | 4570         |    truck     | 9970         |     boat      | 10576        |
[36m| traffic light | 12842        | fire hydrant | 1865         |   stop sign   | 1983         |
[36m| parking meter | 1283         |    bench     | 9820         |     bird      | 10542        |
[36m|      cat      | 4766         |     dog      | 5500         |     horse     | 6567         |
[36m|     sheep     | 9223         |     cow      | 8014         |   elephant    | 5484         |
[36m|     bear      | 1294         |    zebra     | 5269         |    giraffe    | 5128         |
[36m|   backpack    | 8714         |   umbrella   | 11265        |    handbag    | 12342        |
[36m|      tie      | 6448         |   suitcase   | 6112         |    frisbee    | 2681         |
[36m|     skis      | 6623         |  snowboard   | 2681         |  sports ball  | 6299         |
[36m|     kite      | 8802         | baseball bat | 3273         | baseball gl.. | 3747         |
[36m|  skateboard   | 5536         |  surfboard   | 6095         | tennis racket | 4807         |
[36m|    bottle     | 24070        |  wine glass  | 7839         |      cup      | 20574        |
[36m|     fork      | 5474         |    knife     | 7760         |     spoon     | 6159         |
[36m|     bowl      | 14323        |    banana    | 9195         |     apple     | 5776         |
[36m|   sandwich    | 4356         |    orange    | 6302         |   broccoli    | 7261         |
[36m|    carrot     | 7758         |   hot dog    | 2884         |     pizza     | 5807         |
[36m|     donut     | 7005         |     cake     | 6296         |     chair     | 38073        |
[36m|     couch     | 5779         | potted plant | 8631         |      bed      | 4192         |
[36m| dining table  | 15695        |    toilet    | 4149         |      tv       | 5803         |
[36m|    laptop     | 4960         |    mouse     | 2261         |    remote     | 5700         |
[36m|   keyboard    | 2854         |  cell phone  | 6422         |   microwave   | 1672         |
[36m|     oven      | 3334         |   toaster    | 225          |     sink      | 5609         |
[36m| refrigerator  | 2634         |     book     | 24077        |     clock     | 6320         |
[36m|     vase      | 6577         |   scissors   | 1464         |  teddy bear   | 4729         |
[36m|  hair drier   | 198          |  toothbrush  | 1945         |               |              |
[36m|     total     | 849949       |              |              |               |              |
[32m[10/21 20:11:07 d2.data.build]: [39mUsing training sampler TrainingSampler
[32m[10/21 20:11:07 d2.data.common]: [39mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[32m[10/21 20:11:07 d2.data.common]: [39mSerializing 117266 elements to byte tensors and concatenating them all ...
[32m[10/21 20:11:10 d2.data.common]: [39mSerialized dataset takes 451.21 MiB
[32m[10/21 20:11:12 detectron2]: [39mStarting training from iteration 0
/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068694/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[32m[10/21 20:11:48 d2.utils.events]: [39m iter: 19  total_loss: 3.905  loss_box_reg: 0.001038  loss_cls: 2.861  loss_mask: 0.4372  loss_rpn_cls: 0.6896  loss_rpn_loc: 0.02549     lr: 3.8016e-05  max_mem: 5656M
[32m[10/21 20:11:52 d2.utils.events]: [39m eta: 5:16:29  iter: 39  total_loss: 1.786  loss_box_reg: 0.1509  loss_cls: 0.6863  loss_mask: 0.1701  loss_rpn_cls: 0.6662  loss_rpn_loc: 0.04627     lr: 7.8012e-05  max_mem: 7789M
[32m[10/21 20:11:57 d2.utils.events]: [39m eta: 6:04:39  iter: 59  total_loss: 1.764  loss_box_reg: 0.2453  loss_cls: 0.6549  loss_mask: 0.1602  loss_rpn_cls: 0.5336  loss_rpn_loc: 0.07397     lr: 0.00011801  max_mem: 10776M
[32m[10/21 20:12:02 d2.utils.events]: [39m eta: 5:55:14  iter: 79  total_loss: 1.354  loss_box_reg: 0.2915  loss_cls: 0.5457  loss_mask: 0.1558  loss_rpn_cls: 0.2343  loss_rpn_loc: 0.03493     lr: 0.000158  max_mem: 12639M
[32m[10/21 20:12:07 d2.utils.events]: [39m eta: 6:15:01  iter: 99  total_loss: 1.443  loss_box_reg: 0.3398  loss_cls: 0.6463  loss_mask: 0.1126  loss_rpn_cls: 0.1628  loss_rpn_loc: 0.04392     lr: 0.000198  max_mem: 12639M
[32m[10/21 20:12:12 d2.utils.events]: [39m eta: 5:57:13  iter: 119  total_loss: 1.336  loss_box_reg: 0.2858  loss_cls: 0.6139  loss_mask: 0.07494  loss_rpn_cls: 0.1259  loss_rpn_loc: 0.06487     lr: 0.0002  max_mem: 12639M
[32m[10/21 20:12:17 d2.utils.events]: [39m eta: 6:14:48  iter: 139  total_loss: 1.28  loss_box_reg: 0.3241  loss_cls: 0.59  loss_mask: 0.06283  loss_rpn_cls: 0.1481  loss_rpn_loc: 0.06527     lr: 0.0002  max_mem: 12645M
[32m[10/21 20:12:22 d2.utils.events]: [39m eta: 6:31:31  iter: 159  total_loss: 1.481  loss_box_reg: 0.3942  loss_cls: 0.6962  loss_mask: 0.0896  loss_rpn_cls: 0.1052  loss_rpn_loc: 0.05394     lr: 0.0002  max_mem: 12645M
[32m[10/21 20:12:26 d2.utils.events]: [39m eta: 5:16:19  iter: 179  total_loss: 0.8955  loss_box_reg: 0.2083  loss_cls: 0.4363  loss_mask: 0.1473  loss_rpn_cls: 0.09598  loss_rpn_loc: 0.03008     lr: 0.0002  max_mem: 12645M
[32m[10/21 20:12:31 d2.utils.events]: [39m eta: 5:54:54  iter: 199  total_loss: 1.176  loss_box_reg: 0.2443  loss_cls: 0.5285  loss_mask: 0.1049  loss_rpn_cls: 0.121  loss_rpn_loc: 0.05901     lr: 0.0002  max_mem: 12645M
[32m[10/21 20:12:35 d2.utils.events]: [39m eta: 5:26:33  iter: 219  total_loss: 0.9397  loss_box_reg: 0.1947  loss_cls: 0.4191  loss_mask: 0.0872  loss_rpn_cls: 0.1139  loss_rpn_loc: 0.05564     lr: 0.0002  max_mem: 12645M
[32m[10/21 20:12:39 d2.utils.events]: [39m eta: 5:30:52  iter: 239  total_loss: 1.026  loss_box_reg: 0.2167  loss_cls: 0.5308  loss_mask: 0.07627  loss_rpn_cls: 0.1213  loss_rpn_loc: 0.05958     lr: 0.0002  max_mem: 12645M
[32m[10/21 20:12:44 d2.utils.events]: [39m eta: 6:08:20  iter: 259  total_loss: 1.157  loss_box_reg: 0.369  loss_cls: 0.5445  loss_mask: 0.09638  loss_rpn_cls: 0.0888  loss_rpn_loc: 0.04985     lr: 0.0002  max_mem: 12645M
[32m[10/21 20:12:50 d2.utils.events]: [39m eta: 6:19:53  iter: 279  total_loss: 1.221  loss_box_reg: 0.3369  loss_cls: 0.6356  loss_mask: 0.05257  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.07659     lr: 0.0002  max_mem: 12645M
[32m[10/21 20:12:55 d2.utils.events]: [39m eta: 6:23:19  iter: 299  total_loss: 1.173  loss_box_reg: 0.3579  loss_cls: 0.6115  loss_mask: 0.07551  loss_rpn_cls: 0.1146  loss_rpn_loc: 0.06965     lr: 0.0002  max_mem: 12645M
[32m[10/21 20:13:01 d2.utils.events]: [39m eta: 7:18:48  iter: 319  total_loss: 1.585  loss_box_reg: 0.5114  loss_cls: 0.7736  loss_mask: 0.07687  loss_rpn_cls: 0.1101  loss_rpn_loc: 0.07763     lr: 0.0002  max_mem: 12645M
[32m[10/21 20:13:06 d2.utils.events]: [39m eta: 7:20:41  iter: 339  total_loss: 1.794  loss_box_reg: 0.5796  loss_cls: 1.006  loss_mask: 0.06198  loss_rpn_cls: 0.1065  loss_rpn_loc: 0.04674     lr: 0.0002  max_mem: 12646M
[32m[10/21 20:13:12 d2.utils.events]: [39m eta: 7:13:21  iter: 359  total_loss: 1.759  loss_box_reg: 0.4821  loss_cls: 0.8284  loss_mask: 0.05821  loss_rpn_cls: 0.1107  loss_rpn_loc: 0.07975     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:13:18 d2.utils.events]: [39m eta: 6:52:18  iter: 379  total_loss: 1.393  loss_box_reg: 0.4322  loss_cls: 0.7067  loss_mask: 0.06224  loss_rpn_cls: 0.07111  loss_rpn_loc: 0.0381     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:13:23 d2.utils.events]: [39m eta: 6:59:03  iter: 399  total_loss: 1.623  loss_box_reg: 0.5427  loss_cls: 0.7611  loss_mask: 0.06434  loss_rpn_cls: 0.07384  loss_rpn_loc: 0.04678     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:13:29 d2.utils.events]: [39m eta: 7:02:07  iter: 419  total_loss: 1.596  loss_box_reg: 0.5914  loss_cls: 0.8202  loss_mask: 0.06771  loss_rpn_cls: 0.06344  loss_rpn_loc: 0.03797     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:13:35 d2.utils.events]: [39m eta: 7:18:20  iter: 439  total_loss: 1.728  loss_box_reg: 0.5879  loss_cls: 0.8388  loss_mask: 0.1005  loss_rpn_cls: 0.06537  loss_rpn_loc: 0.03324     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:13:41 d2.utils.events]: [39m eta: 7:33:27  iter: 459  total_loss: 1.896  loss_box_reg: 0.6628  loss_cls: 1.012  loss_mask: 0.05305  loss_rpn_cls: 0.06382  loss_rpn_loc: 0.04452     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:13:47 d2.utils.events]: [39m eta: 7:28:50  iter: 479  total_loss: 1.894  loss_box_reg: 0.6058  loss_cls: 1.007  loss_mask: 0.07378  loss_rpn_cls: 0.0867  loss_rpn_loc: 0.03753     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:13:53 d2.utils.events]: [39m eta: 6:57:17  iter: 499  total_loss: 1.581  loss_box_reg: 0.4667  loss_cls: 0.8321  loss_mask: 0.08482  loss_rpn_cls: 0.07296  loss_rpn_loc: 0.05175     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:13:58 d2.utils.events]: [39m eta: 7:05:33  iter: 519  total_loss: 1.684  loss_box_reg: 0.5003  loss_cls: 0.8797  loss_mask: 0.08302  loss_rpn_cls: 0.0663  loss_rpn_loc: 0.04854     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:14:05 d2.utils.events]: [39m eta: 7:45:43  iter: 539  total_loss: 1.721  loss_box_reg: 0.5685  loss_cls: 0.8381  loss_mask: 0.07784  loss_rpn_cls: 0.0793  loss_rpn_loc: 0.03677     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:14:10 d2.utils.events]: [39m eta: 7:17:20  iter: 559  total_loss: 1.679  loss_box_reg: 0.5397  loss_cls: 0.8062  loss_mask: 0.05943  loss_rpn_cls: 0.1052  loss_rpn_loc: 0.05404     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:14:16 d2.utils.events]: [39m eta: 7:02:50  iter: 579  total_loss: 1.473  loss_box_reg: 0.4937  loss_cls: 0.7994  loss_mask: 0.04209  loss_rpn_cls: 0.06476  loss_rpn_loc: 0.02519     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:14:22 d2.utils.events]: [39m eta: 7:32:27  iter: 599  total_loss: 1.908  loss_box_reg: 0.6309  loss_cls: 0.9308  loss_mask: 0.05271  loss_rpn_cls: 0.06372  loss_rpn_loc: 0.04161     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:14:28 d2.utils.events]: [39m eta: 7:23:59  iter: 619  total_loss: 1.613  loss_box_reg: 0.5338  loss_cls: 0.8764  loss_mask: 0.06411  loss_rpn_cls: 0.07929  loss_rpn_loc: 0.06317     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:14:34 d2.utils.events]: [39m eta: 7:04:37  iter: 639  total_loss: 1.521  loss_box_reg: 0.5707  loss_cls: 0.7005  loss_mask: 0.05853  loss_rpn_cls: 0.06403  loss_rpn_loc: 0.05495     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:14:40 d2.utils.events]: [39m eta: 7:19:40  iter: 659  total_loss: 1.7  loss_box_reg: 0.5703  loss_cls: 0.905  loss_mask: 0.0818  loss_rpn_cls: 0.08752  loss_rpn_loc: 0.0893     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:14:45 d2.utils.events]: [39m eta: 7:10:12  iter: 679  total_loss: 1.669  loss_box_reg: 0.5421  loss_cls: 0.8212  loss_mask: 0.04558  loss_rpn_cls: 0.07439  loss_rpn_loc: 0.03685     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:14:51 d2.utils.events]: [39m eta: 6:49:08  iter: 699  total_loss: 1.523  loss_box_reg: 0.5614  loss_cls: 0.7689  loss_mask: 0.06358  loss_rpn_cls: 0.07476  loss_rpn_loc: 0.03854     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:14:57 d2.utils.events]: [39m eta: 7:40:13  iter: 719  total_loss: 1.854  loss_box_reg: 0.6651  loss_cls: 0.856  loss_mask: 0.114  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.06039     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:15:03 d2.utils.events]: [39m eta: 6:55:35  iter: 739  total_loss: 1.508  loss_box_reg: 0.573  loss_cls: 0.6661  loss_mask: 0.08904  loss_rpn_cls: 0.07282  loss_rpn_loc: 0.04678     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:15:08 d2.utils.events]: [39m eta: 7:08:11  iter: 759  total_loss: 1.578  loss_box_reg: 0.6097  loss_cls: 0.7269  loss_mask: 0.06596  loss_rpn_cls: 0.05969  loss_rpn_loc: 0.05744     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:15:14 d2.utils.events]: [39m eta: 7:09:09  iter: 779  total_loss: 1.706  loss_box_reg: 0.5886  loss_cls: 0.8417  loss_mask: 0.07271  loss_rpn_cls: 0.05749  loss_rpn_loc: 0.04255     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:15:20 d2.utils.events]: [39m eta: 7:21:44  iter: 799  total_loss: 1.556  loss_box_reg: 0.526  loss_cls: 0.7927  loss_mask: 0.07369  loss_rpn_cls: 0.06901  loss_rpn_loc: 0.04428     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:15:26 d2.utils.events]: [39m eta: 7:22:03  iter: 819  total_loss: 1.643  loss_box_reg: 0.5896  loss_cls: 0.7437  loss_mask: 0.1026  loss_rpn_cls: 0.05427  loss_rpn_loc: 0.04415     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:15:32 d2.utils.events]: [39m eta: 7:29:25  iter: 839  total_loss: 1.718  loss_box_reg: 0.5937  loss_cls: 0.8299  loss_mask: 0.07046  loss_rpn_cls: 0.08656  loss_rpn_loc: 0.05077     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:15:38 d2.utils.events]: [39m eta: 7:19:36  iter: 859  total_loss: 1.632  loss_box_reg: 0.5519  loss_cls: 0.8266  loss_mask: 0.05331  loss_rpn_cls: 0.08266  loss_rpn_loc: 0.05256     lr: 0.0002  max_mem: 12653M
[32m[10/21 20:15:44 d2.utils.events]: [39m eta: 7:05:33  iter: 879  total_loss: 1.704  loss_box_reg: 0.62  loss_cls: 0.7701  loss_mask: 0.08208  loss_rpn_cls: 0.04093  loss_rpn_loc: 0.03532     lr: 0.0002  max_mem: 12653M
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f0d4f5f1430>
Traceback (most recent call last):
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1328, in __del__
    self._shutdown_workers()
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1301, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/multiprocessing/popen_fork.py", line 44, in wait
    if not wait([self.sentinel], timeout):
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt:
Process SpawnProcess-1:
Traceback (most recent call last):
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 61, in _wrap
    pass  # SIGINT; Killed by parent, do nothing
KeyboardInterrupt