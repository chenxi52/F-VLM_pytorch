[32m[10/21 20:02:28 detectron2]: [39mRank of current process: 0. World size: 2
[32m[10/21 20:02:29 detectron2]: [39mEnvironment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]
numpy                            1.22.4
detectron2                       0.6 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/detectron2
Compiler                         GCC 7.5
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3,4,5,6,7              NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   515.76
CUDA_HOME                        /home/xchen/cuda-11.4/
Pillow                           7.2.0
torchvision                      0.11.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON,
[32m[10/21 20:02:29 detectron2]: [39mCommand line arguments: Namespace(config_file='configs/RSPrompter_anchor_tiny_Vitdet.yaml', dist_url='tcp://127.0.0.1:50165', eval_only=True, machine_rank=0, num_gpus=2, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2'], resume=False)
[32m[10/21 20:02:29 detectron2]: [39mContents of args.config_file=configs/RSPrompter_anchor_tiny_Vitdet.yaml:
[38m# _BASE_: "Base_OVCOCO_C4_1x.yaml"
[38mMODEL:
[38m  META_ARCHITECTURE: "SamDetector" 
[38m  BACKBONE:
[38m    NAME: "build_sam_vit_det_backbone" #SAM vit_h
[38m    # TYPE: "vit_h"
[38m    # TYPE: "vit_b"
[38m    TYPE: "vit_t"
[38m  WEIGHTS: "mobile_sam.pt"
[38m  # WEIGHTS: "/opt/tiger/OpenVo-Seg-master/output/wo_mask_with_prompt_encoder_roi_head_withgrad/model_final.pth"
[38m  # WEIGHTS: "sam_vit_h_4b8939.pth"
[38m  # WEIGHTS: "output/Detic-COCO/RSPrompter_anchor/model_0000999.pth"
[38m  FPN:
[38m    OUT_CHANNELS: 256
[38m    IN_CHANNELS: [256]
[38m    ANCHOR_STRIDE: [4, 8, 16, 32, 64]
[38m    NORM: 'LN'
[38m  PIXEL_MEAN: [123.675, 116.280, 103.530]
[38m  PIXEL_STD: [58.395, 57.12, 57.375]
[38m  ANCHOR_GENERATOR:
[38m    NAME: "DefaultAnchorGenerator"
[38m    SIZES: [[32],[64],[128],[256],[512]] 
[38m    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]  # Three aspect ratios (same for all in feature maps)
[38m  PROPOSAL_GENERATOR:
[38m    NAME: "RPN"
[38m  RPN:
[38m    HEAD_NAME: "StandardRPNHead"
[38m    IN_FEATURES: ["feat4","feat3","feat2","feat1","feat0"]
[38m    PRE_NMS_TOPK_TRAIN: 2000  # Per FPN level
[38m    PRE_NMS_TOPK_TEST: 1000  # Per FPN level
[38m    # Detectron1 uses 2000 proposals per-batch,
[38m    # (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)
[38m    # which is approximately 1000 proposals per-image since the default batch size for FPN is 2.
[38m    POST_NMS_TOPK_TRAIN: 1000
[38m    POST_NMS_TOPK_TEST: 1000
[38m    IOU_THRESHOLDS: [0.3, 0.7]
[38m    BATCH_SIZE_PER_IMAGE: 512 # the sampling num 
[38m    POSITIVE_FRACTION: 0.5
[38m    BBOX_REG_LOSS_TYPE: "smooth_l1"
[38m    NMS_THRESH: 0.7
[38m    SMOOTH_L1_BETA: 0.
[38m  ROI_HEADS:
[38m    NAME: "samAnchorPromptRoiHeads" 
[38m    IN_FEATURES: ["feat4","feat3","feat2","feat1"]
[38m    SCORE_THRESH_TEST: 0.02
[38m    NUM_CLASSES: 80
[38m    NMS_THRESH_TEST: 0.5
[38m    BATCH_SIZE_PER_IMAGE: 256 #the sampling num 
[38m    POSITIVE_FRACTION: 0.25
[38m    IOU_THRESHOLDS: [0.5]
[38m    IOU_LABELS: [0, 1]
[38m    ALLOW_LOW_QUALITY_MATCHES: True  
[38m    PROPOSAL_APPEND_GT: True
[38m  ROI_BOX_HEAD:
[38m    NAME: "FastRCNNConvFCHead"  # Shared2FCBBoxHead
[38m    NUM_FC: 2
[38m    CONV_DIM: 256
[38m    FC_DIM: 1024
[38m    BBOX_REG_LOSS_TYPE: "smooth_l1"
[38m    POOLER_RESOLUTION: 7
[38m    POOLER_SAMPLING_RATIO: 0
[38m    POOLER_TYPE: "ROIAlignV2"
[38m    USE_SIGMOID_CE: False
[38m    BBOX_REG_LOSS_WEIGHT: 1.0
[38m    TRAIN_ON_PRED_BOXES: True
[38m    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
[38m    SMOOTH_L1_BETA: 0.
[38m    CLS_AGNOSTIC_BBOX_REG: False
[38m  ROI_MASK_HEAD:
[38m    NAME: "samMaskHead"
[38m    NUM_CONV: 4
[38m    CLS_AGNOSTIC_MASK: True
[38m    WITH_SINCOS: True
[38m    MASK_LOSS_TYPE: "ce" 
[38m    MASK_LOSS_WEIGHT: 1.0
[38m    POOLER_RESOLUTION: 14
[38m    POOLER_SAMPLING_RATIO: 0
[38m    POOLER_TYPE: "ROIAlignV2"
[38m    PER_QUERY_POINT: 4
[38m  MASK_ON: True
[38mDATASETS:
[38m  TRAIN: ("coco_2017_train",)
[38m  TEST: ("coco_2017_val",)
[38mDATALOADER:
[38m  NUM_WORKERS: 16 # num_workers == batchsize_per_gpu
[38m  # PERSISTENT_WORKERS: True 
[38mSOLVER:
[38m  IMS_PER_BATCH: 16  # change  # max 8 imgs per batch
[38m  BASE_LR: 0.0002  # change0.000025
[38m  STEPS: (60000, 80000)  # change 
[38m  WARMUP_ITERS: 100  
[38m  WARMUP_METHOD : "linear"
[38m  WARMUP_FACTOR: 0.0001 #1.0001
[38m  # LR_SCHEDULER_NAME: "WarmupCosineLR" 
[38m  LR_SCHEDULER_NAME: "WarmupMultiStepLR"
[38m  WEIGHT_DECAY: 0.001  
[38m  MAX_ITER: 90000
[38m  CHECKPOINT_PERIOD: 5000  #  change
[38m  USE_CUSTOM_SOLVER: True
[38m  OPTIMIZER: 'ADAMW'
[38m  LOGGER_FREQ: 20  # the output freq of logger writer
[38m  AMP:
[38m    ENABLED: True
[38mINPUT:
[38m  TRAIN_SIZE: 1024
[38m  TEST_SIZE: 1024 
[38m  TEST_INPUT_TYPE: ResizeLongestSize
[38m  PROMPT_SIZE: (90, 4)
[38m  CUSTOM_AUG: ResizeLongestSize
[38m  FORMAT: "RGB"
[38m  # PAD_MASK: True
[38m  # MASK_PAD_VAL: 0.0
[38m  MASK_FORMAT: "bitmask"
[38mTEST:
[38m  DETECTIONS_PER_IMAGE: 300  #test_topk_per_image
[38m  MASK_THR_BINARY: 0.5  
[38m  DO_POSTPROCESS: True
[38m  EVAL_PERIOD: 5000 # change
[38m  IMS_PER_BATCH: 2 #every gpu has most 2 images  # change
[38mVERSION: 2
[38mFP16: True
[38mOUTPUT_DIR: './output/full_tune_tiny'
[32m[10/21 20:02:29 detectron2]: [39mRunning with full config:
[38mCUDNN_BENCHMARK: false
[38mDATALOADER:
[38m  ASPECT_RATIO_GROUPING: true
[38m  FILTER_EMPTY_ANNOTATIONS: true
[38m  NUM_WORKERS: 16
[38m  PERSISTENT_WORKERS: false
[38m  REPEAT_THRESHOLD: 0.0
[38m  SAMPLER_TRAIN: TrainingSampler
[38mDATASETS:
[38m  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
[38m  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
[38m  PROPOSAL_FILES_TEST: []
[38m  PROPOSAL_FILES_TRAIN: []
[38m  TEST:
[38m  - coco_2017_val
[38m  TRAIN:
[38m  - coco_2017_train
[38mFIND_UNUSED_PARAM: true
[38mFP16: true
[38mGLOBAL:
[38m  HACK: 1.0
[38mINPUT:
[38m  CROP:
[38m    ENABLED: false
[38m    SIZE:
[38m    - 0.9
[38m    - 0.9
[38m    TYPE: relative_range
[38m  CUSTOM_AUG: ResizeLongestSize
[38m  FORMAT: RGB
[38m  MASK_FORMAT: bitmask
[38m  MASK_PAD_VAL: 0.0
[38m  MAX_SIZE_TEST: 1333
[38m  MAX_SIZE_TRAIN: 1333
[38m  MIN_SIZE_TEST: 800
[38m  MIN_SIZE_TRAIN:
[38m  - 800
[38m  MIN_SIZE_TRAIN_SAMPLING: choice
[38m  PAD_MASK: true
[38m  PROMPT_SIZE:
[38m  - 90
[38m  - 4
[38m  RANDOM_FLIP: horizontal
[38m  SCALE_RANGE:
[38m  - 0.1
[38m  - 2.0
[38m  TEST_INPUT_TYPE: ResizeLongestSize
[38m  TEST_SIZE: 1024
[38m  TRAIN_SIZE: 1024
[38mMODEL:
[38m  ANCHOR_GENERATOR:
[38m    ANGLES:
[38m    - - -90
[38m      - 0
[38m      - 90
[38m    ASPECT_RATIOS:
[38m    - - 0.5
[38m      - 1.0
[38m      - 2.0
[38m    NAME: DefaultAnchorGenerator
[38m    OFFSET: 0.0
[38m    SIZES:
[38m    - - 32
[38m    - - 64
[38m    - - 128
[38m    - - 256
[38m    - - 512
[38m  BACKBONE:
[38m    FREEZE_AT: 2
[38m    NAME: build_sam_vit_det_backbone
[38m    TYPE: vit_t
[38m  CONFIGS:
[38m    ONLY_DECODER: false
[38m  DEVICE: cuda
[38m  FPN:
[38m    ANCHOR_STRIDE:
[38m    - 4
[38m    - 8
[38m    - 16
[38m    - 32
[38m    - 64
[38m    FUSE_TYPE: sum
[38m    INNER_CHANNELS: 32
[38m    IN_CHANNELS:
[38m    - 256
[38m    IN_FEATURES: []
[38m    NORM: LN
[38m    OUT_CHANNELS: 256
[38m    SELECTED_CHANNELS:
[38m    - 8
[38m    - 10
[38m    - 12
[38m    - 14
[38m    - 16
[38m    - 18
[38m    - 20
[38m    - 22
[38m    - 24
[38m    - 26
[38m    - 28
[38m    - 30
[38m    UP_SAMPLE_SCALE: 4
[38m  KEYPOINT_ON: false
[38m  LOAD_PROPOSALS: false
[38m  MASK_ON: true
[38m  META_ARCHITECTURE: SamDetector
[38m  PANOPTIC_FPN:
[38m    COMBINE:
[38m      ENABLED: true
[38m      INSTANCES_CONFIDENCE_THRESH: 0.5
[38m      OVERLAP_THRESH: 0.5
[38m      STUFF_AREA_LIMIT: 4096
[38m    INSTANCE_LOSS_WEIGHT: 1.0
[38m  PIXEL_MEAN:
[38m  - 123.675
[38m  - 116.28
[38m  - 103.53
[38m  PIXEL_STD:
[38m  - 58.395
[38m  - 57.12
[38m  - 57.375
[38m  PROPOSAL_GENERATOR:
[38m    MIN_SIZE: 0
[38m    NAME: RPN
[38m  RESNETS:
[38m    DEFORM_MODULATED: false
[38m    DEFORM_NUM_GROUPS: 1
[38m    DEFORM_ON_PER_STAGE:
[38m    - false
[38m    - false
[38m    - false
[38m    - false
[38m    DEPTH: 50
[38m    NORM: FrozenBN
[38m    NUM_GROUPS: 1
[38m    OUT_FEATURES:
[38m    - res4
[38m    RES2_OUT_CHANNELS: 256
[38m    RES5_DILATION: 1
[38m    STEM_OUT_CHANNELS: 64
[38m    STRIDE_IN_1X1: true
[38m    WIDTH_PER_GROUP: 64
[38m  RETINANET:
[38m    BBOX_REG_LOSS_TYPE: smooth_l1
[38m    BBOX_REG_WEIGHTS: &id001
[38m    - 1.0
[38m    - 1.0
[38m    - 1.0
[38m    - 1.0
[38m    FOCAL_LOSS_ALPHA: 0.25
[38m    FOCAL_LOSS_GAMMA: 2.0
[38m    IN_FEATURES:
[38m    - p3
[38m    - p4
[38m    - p5
[38m    - p6
[38m    - p7
[38m    IOU_LABELS:
[38m    - 0
[38m    - -1
[38m    - 1
[38m    IOU_THRESHOLDS:
[38m    - 0.4
[38m    - 0.5
[38m    NMS_THRESH_TEST: 0.5
[38m    NORM: ''
[38m    NUM_CLASSES: 80
[38m    NUM_CONVS: 4
[38m    PRIOR_PROB: 0.01
[38m    SCORE_THRESH_TEST: 0.05
[38m    SMOOTH_L1_LOSS_BETA: 0.1
[38m    TOPK_CANDIDATES_TEST: 1000
[38m  ROI_BOX_CASCADE_HEAD:
[38m    BBOX_REG_WEIGHTS:
[38m    - - 10.0
[38m      - 10.0
[38m      - 5.0
[38m      - 5.0
[38m    - - 20.0
[38m      - 20.0
[38m      - 10.0
[38m      - 10.0
[38m    - - 30.0
[38m      - 30.0
[38m      - 15.0
[38m      - 15.0
[38m    IOUS:
[38m    - 0.5
[38m    - 0.6
[38m    - 0.7
[38m  ROI_BOX_HEAD:
[38m    BBOX_REG_LOSS_TYPE: smooth_l1
[38m    BBOX_REG_LOSS_WEIGHT: 1.0
[38m    BBOX_REG_WEIGHTS:
[38m    - 10.0
[38m    - 10.0
[38m    - 5.0
[38m    - 5.0
[38m    CLS_AGNOSTIC_BBOX_REG: false
[38m    CONV_DIM: 256
[38m    FC_DIM: 1024
[38m    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
[38m    FED_LOSS_NUM_CLASSES: 50
[38m    NAME: FastRCNNConvFCHead
[38m    NORM: ''
[38m    NUM_CONV: 0
[38m    NUM_FC: 2
[38m    POOLER_RESOLUTION: 7
[38m    POOLER_SAMPLING_RATIO: 0
[38m    POOLER_TYPE: ROIAlignV2
[38m    SMOOTH_L1_BETA: 0.0
[38m    TRAIN_ON_PRED_BOXES: true
[38m    USE_FED_LOSS: false
[38m    USE_SIGMOID_CE: false
[38m  ROI_HEADS:
[38m    ALLOW_LOW_QUALITY_MATCHES: true
[38m    BATCH_SIZE_PER_IMAGE: 256
[38m    IN_FEATURES:
[38m    - feat4
[38m    - feat3
[38m    - feat2
[38m    - feat1
[38m    IOU_LABELS:
[38m    - 0
[38m    - 1
[38m    IOU_THRESHOLDS:
[38m    - 0.5
[38m    NAME: samAnchorPromptRoiHeads
[38m    NMS_THRESH_TEST: 0.5
[38m    NUM_CLASSES: 80
[38m    POSITIVE_FRACTION: 0.25
[38m    PROPOSAL_APPEND_GT: true
[38m    SCORE_THRESH_TEST: 0.02
[38m  ROI_KEYPOINT_HEAD:
[38m    CONV_DIMS:
[38m    - 512
[38m    - 512
[38m    - 512
[38m    - 512
[38m    - 512
[38m    - 512
[38m    - 512
[38m    - 512
[38m    LOSS_WEIGHT: 1.0
[38m    MIN_KEYPOINTS_PER_IMAGE: 1
[38m    NAME: KRCNNConvDeconvUpsampleHead
[38m    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
[38m    NUM_KEYPOINTS: 17
[38m    POOLER_RESOLUTION: 14
[38m    POOLER_SAMPLING_RATIO: 0
[38m    POOLER_TYPE: ROIAlignV2
[38m  ROI_MASK_HEAD:
[38m    CLS_AGNOSTIC_MASK: true
[38m    CONV_DIM: 256
[38m    MASK_LOSS_TYPE: ce
[38m    MASK_LOSS_WEIGHT: 1.0
[38m    NAME: samMaskHead
[38m    NORM: ''
[38m    NUM_CONV: 4
[38m    PER_QUERY_POINT: 4
[38m    POOLER_RESOLUTION: 14
[38m    POOLER_SAMPLING_RATIO: 0
[38m    POOLER_TYPE: ROIAlignV2
[38m    WITH_SINCOS: true
[38m  RPN:
[38m    BATCH_SIZE_PER_IMAGE: 512
[38m    BBOX_REG_LOSS_TYPE: smooth_l1
[38m    BBOX_REG_LOSS_WEIGHT: 1.0
[38m    BBOX_REG_WEIGHTS: *id001
[38m    BOUNDARY_THRESH: -1
[38m    CONV_DIMS:
[38m    - -1
[38m    HEAD_NAME: StandardRPNHead
[38m    IN_FEATURES:
[38m    - feat4
[38m    - feat3
[38m    - feat2
[38m    - feat1
[38m    - feat0
[38m    IOU_LABELS:
[38m    - 0
[38m    - -1
[38m    - 1
[38m    IOU_THRESHOLDS:
[38m    - 0.3
[38m    - 0.7
[38m    LOSS_WEIGHT: 1.0
[38m    NMS_THRESH: 0.7
[38m    POSITIVE_FRACTION: 0.5
[38m    POST_NMS_TOPK_TEST: 1000
[38m    POST_NMS_TOPK_TRAIN: 1000
[38m    PRE_NMS_TOPK_TEST: 1000
[38m    PRE_NMS_TOPK_TRAIN: 2000
[38m    SMOOTH_L1_BETA: 0.0
[38m  SEM_SEG_HEAD:
[38m    COMMON_STRIDE: 4
[38m    CONVS_DIM: 128
[38m    IGNORE_VALUE: 255
[38m    IN_FEATURES:
[38m    - p2
[38m    - p3
[38m    - p4
[38m    - p5
[38m    LOSS_WEIGHT: 1.0
[38m    NAME: SemSegFPNHead
[38m    NORM: GN
[38m    NUM_CLASSES: 54
[38m  WEIGHTS: mobile_sam.pt
[38mOUTPUT_DIR: ./output/full_tune_tiny
[38mSEED: -1
[38mSOLVER:
[38m  AMP:
[38m    ENABLED: true
[38m  BASE_LR: 0.0002
[38m  BASE_LR_END: 0.0
[38m  BIAS_LR_FACTOR: 1.0
[38m  CHECKPOINT_PERIOD: 5000
[38m  CLIP_GRADIENTS:
[38m    CLIP_TYPE: value
[38m    CLIP_VALUE: 1.0
[38m    ENABLED: false
[38m    NORM_TYPE: 2.0
[38m  GAMMA: 0.1
[38m  IMS_PER_BATCH: 2
[38m  LOGGER_FREQ: 20
[38m  LR_SCHEDULER_NAME: WarmupMultiStepLR
[38m  MAX_ITER: 90000
[38m  MOMENTUM: 0.9
[38m  NESTEROV: false
[38m  NUM_DECAYS: 3
[38m  OPTIMIZER: ADAMW
[38m  REFERENCE_WORLD_SIZE: 0
[38m  RESCALE_INTERVAL: false
[38m  STEPS:
[38m  - 60000
[38m  - 80000
[38m  USE_CUSTOM_SOLVER: true
[38m  WARMUP_FACTOR: 0.0001
[38m  WARMUP_ITERS: 100
[38m  WARMUP_METHOD: linear
[38m  WEIGHT_DECAY: 0.001
[38m  WEIGHT_DECAY_BIAS: null
[38m  WEIGHT_DECAY_NORM: 0.0
[38mTEST:
[38m  AUG:
[38m    ENABLED: false
[38m    FLIP: true
[38m    MAX_SIZE: 4000
[38m    MIN_SIZES:
[38m    - 400
[38m    - 500
[38m    - 600
[38m    - 700
[38m    - 800
[38m    - 900
[38m    - 1000
[38m    - 1100
[38m    - 1200
[38m  DETECTIONS_PER_IMAGE: 300
[38m  DO_POSTPROCESS: true
[38m  EVAL_PERIOD: 5000
[38m  EXPECTED_RESULTS: []
[38m  IMS_PER_BATCH: 2
[38m  KEYPOINT_OKS_SIGMAS: []
[38m  MASK_THR_BINARY: 0.5
[38m  PRECISE_BN:
[38m    ENABLED: false
[38m    NUM_ITER: 200
[38mVERSION: 2
[38mVIS_PERIOD: 0
[32m[10/21 20:02:29 detectron2]: [39mFull config saved to ./output/full_tune_tiny/config.yaml
[32m[10/21 20:02:29 d2.utils.env]: [39mUsing a generated random seed 31592045
[32m[10/21 20:02:30 detectron2]: [39mModel:
SamDetector(
  (backbone): SAMVitDet(
    (fpn1): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (1): Norm2d(
        (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): GELU()
      (3): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn2): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn3): Identity()
    (fpn4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): samAnchorPromptRoiHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): SamRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): samMaskHead(
      (point_emb): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Flatten(start_dim=1, end_dim=-1)
        (4): Linear(in_features=12544, out_features=256, bias=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=True)
        (7): ReLU(inplace=True)
        (8): Linear(in_features=256, out_features=2048, bias=True)
      )
    )
    (generator_pe): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
  )
  (sam): Sam(
    (image_encoder): TinyViT(
      (patch_embed): PatchEmbed(
        (seq): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU()
          (2): Conv2d_BN(
            (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layers): ModuleList(
        (0): ConvLayer(
          (blocks): ModuleList(
            (0): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
            (1): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (1): BasicLayer(
          dim=128, input_resolution=(128, 128), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (2): BasicLayer(
          dim=160, input_resolution=(64, 64), depth=6
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (3): BasicLayer(
          dim=320, input_resolution=(64, 64), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (neck): Sequential(
        (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): LayerNorm2d()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (3): LayerNorm2d()
      )
    )
    (prompt_encoder): PromptEncoder(
      (pe_layer): PositionEmbeddingRandom()
      (point_embeddings): ModuleList(
        (0): Embedding(1, 256)
        (1): Embedding(1, 256)
        (2): Embedding(1, 256)
        (3): Embedding(1, 256)
      )
      (not_a_point_embed): Embedding(1, 256)
      (mask_downscaling): Sequential(
        (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
        (4): LayerNorm2d()
        (5): GELU()
        (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (no_mask_embed): Embedding(1, 256)
    )
    (mask_decoder): MaskDecoder(
      (transformer): TwoWayTransformer(
        (layers): ModuleList(
          (0): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
          (1): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
        )
        (final_attn_token_to_image): Attention(
          (q_proj): Linear(in_features=256, out_features=128, bias=True)
          (k_proj): Linear(in_features=256, out_features=128, bias=True)
          (v_proj): Linear(in_features=256, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (iou_token): Embedding(1, 256)
      (mask_tokens): Embedding(4, 256)
      (output_upscaling): Sequential(
        (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
        (4): GELU()
      )
      (output_hypernetworks_mlps): ModuleList(
        (0): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (3): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
      )
    )
  )
)
[32m[10/21 20:02:30 d2.checkpoint.detection_checkpoint]: [39m[DetectionCheckpointer] Loading from mobile_sam.pt ...
[32m[10/21 20:02:30 fvcore.common.checkpoint]: [39m[Checkpointer] Loading from mobile_sam.pt ...
[32m[10/21 20:02:30 d2.checkpoint.c2_model_loading]: [39mFollowing weights matched with submodule sam - Total num: 168
[31m[5mWARNING[39m[25m [32m[10/21 20:02:30 fvcore.common.checkpoint]: [39mSome model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn1.0.{bias, weight}
[34mbackbone.fpn1.1.ln.{bias, weight}
[34mbackbone.fpn1.3.{bias, weight}
[34mbackbone.fpn2.0.{bias, weight}
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}
[34mproposal_generator.rpn_head.conv.{bias, weight}
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}
[34mroi_heads.box_head.fc1.{bias, weight}
[34mroi_heads.box_head.fc2.{bias, weight}
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}
[34mroi_heads.box_predictor.cls_score.{bias, weight}
[34mroi_heads.mask_head.point_emb.0.{bias, weight}
[34mroi_heads.mask_head.point_emb.1.{bias, running_mean, running_var, weight}
[34mroi_heads.mask_head.point_emb.4.{bias, weight}
[34mroi_heads.mask_head.point_emb.6.{bias, weight}
[34mroi_heads.mask_head.point_emb.8.{bias, weight}
[31m[5mWARNING[39m[25m [32m[10/21 20:02:30 fvcore.common.checkpoint]: [39mThe checkpoint state_dict contains keys that are not used by the model:
  [35mimage_encoder.head.{bias, weight}
  [35mimage_encoder.norm_head.{bias, weight}
  [35mmask_decoder.iou_prediction_head.layers.0.{bias, weight}
  [35mmask_decoder.iou_prediction_head.layers.1.{bias, weight}
  [35mmask_decoder.iou_prediction_head.layers.2.{bias, weight}
[32m[10/21 20:02:30 d2.data.dataset_mapper]: [39m[DatasetMapper] Augmentations used in inference: [ResizeLongestSizeFlip(longest_length=1024)]
[32m[10/21 20:02:31 d2.data.datasets.coco]: [39mLoaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[32m[10/21 20:02:31 d2.data.build]: [39mDistribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
[36m|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
[36m|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
[36m|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
[36m|     train     | 190          |    truck     | 414          |     boat      | 424          |
[36m| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
[36m| parking meter | 60           |    bench     | 411          |     bird      | 427          |
[36m|      cat      | 202          |     dog      | 218          |     horse     | 272          |
[36m|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
[36m|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
[36m|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
[36m|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
[36m|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
[36m|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
[36m|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
[36m|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
[36m|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
[36m|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
[36m|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
[36m|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
[36m|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
[36m|     couch     | 261          | potted plant | 342          |      bed      | 163          |
[36m| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
[36m|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
[36m|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
[36m|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
[36m| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
[36m|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
[36m|  hair drier   | 11           |  toothbrush  | 57           |               |              |
[36m|     total     | 36335        |              |              |               |              |
[32m[10/21 20:02:31 d2.data.common]: [39mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[32m[10/21 20:02:31 d2.data.common]: [39mSerializing 5000 elements to byte tensors and concatenating them all ...
[32m[10/21 20:02:31 d2.data.common]: [39mSerialized dataset takes 18.89 MiB
[31m[5mWARNING[39m[25m [32m[10/21 20:02:31 d2.evaluation.coco_evaluation]: [39mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[32m[10/21 20:02:32 d2.evaluation.evaluator]: [39mStart inference on 1250 batches
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f1d40551430>
Traceback (most recent call last):
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1328, in __del__
    self._shutdown_workers()
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1301, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/multiprocessing/popen_fork.py", line 44, in wait
    if not wait([self.sentinel], timeout):
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt:
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/wandb/analytics/sentry.py", line 43, in wrapper
    return func(self, *args, **kwargs)
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/wandb/analytics/sentry.py", line 178, in end_session
    client.flush()
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/sentry_sdk/client.py", line 646, in flush
    self.transport.flush(timeout=timeout, callback=callback)
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/sentry_sdk/transport.py", line 550, in flush
    self._worker.flush(timeout, callback)
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/sentry_sdk/worker.py", line 95, in flush
    self._wait_flush(timeout, callback)
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/sentry_sdk/worker.py", line 105, in _wait_flush
    if not self._timed_queue_join(initial_timeout):
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/sentry_sdk/worker.py", line 56, in _timed_queue_join
    queue.all_tasks_done.wait(timeout=delay)
  File "/home/xchen/anaconda3/envs/Agri/lib/python3.8/threading.py", line 306, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt