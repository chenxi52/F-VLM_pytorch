_BASE_: "OpenDet_tiny_coco.yaml"
MODEL:
  BACKBONE:
    TYPE: "vit_t"
    CLIP_TYPE: "RN50"
  CLIP_TEXT_FEATS_PATH: "datasets/coco/coco_cls.pkl"
  WEIGHTS: ""
  SAM_WEIGHTS: "mobile_sam.pt"
  PROPOSAL_GENERATOR:
    NAME: "SAMRPN"
  SAM_PIXEL_MEAN: [123.675, 116.280, 103.530]
  SAM_PIXEL_STD: [58.395, 57.12, 57.375]
  RPN:
    HEAD_NAME: "StandardRPNHead"
    POST_NMS_TOPK_TEST: 100
    BATCH_SIZE_PER_IMAGE: 256
  ROI_HEADS:
    NMS_THRESH_TEST: 0.4
    BATCH_SIZE_PER_IMAGE: 128
    NUM_CLASSES: 80 # num of seen classes
  ROI_BOX_HEAD:
    BASE_ALPHA: 0.2
    NOVEL_BETA: 0.45
    TRAIN_ON_PRED_BOXES: False #!!!!!
  ROI_MASK_HEAD:
    NAME: "samMaskHead"
    WITH_SINCOS: True
    PER_QUERY_POINT: 4
    SELECT_FORE_CLS: False # !!!!!
    ADD_PE_CONTEXT: True # !!!!
  MASK_ON: True
  SAM_ON: True # !!!!
DATASETS:
  TRAIN: ("coco_zeroshot_train",)
  TEST: ("coco_generalized_zeroshot_val",)
DATALOADER:
  NUM_WORKERS: 4 # num_workers == batchsize_per_gpu
INPUT:
  CLIP_TRAIN_SIZE: 1024
  CUSTOM_AUG: ResizeLongLSJ2 # !!!!
TEST:
  DETECTIONS_PER_IMAGE: 100  #test_topk_per_image
  IMS_PER_BATCH: 4 #every gpu has most 2 images  # change
  SCORE_TYPE: 'cls'
  GEOMETRIC_FACT: 0.35
OUTPUT_DIR: './output/clipRpn/SamOn'
EVAL_AR: False