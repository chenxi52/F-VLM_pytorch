_BASE_: "Base_ov_mine.yaml"
MODEL:
  BACKBONE:
    TYPE: "vit_t"
    CLIP_TYPE: "RN50"
  CLIP_TEXT_FEATS_PATH: "datasets/coco/coco_cls_seen.pkl"
  SAM_WEIGHTS: "mobile_sam.pt"
  PROPOSAL_GENERATOR:
    NAME: "SAMRPN"
  SAM_PIXEL_MEAN: [123.675, 116.280, 103.530]
  SAM_PIXEL_STD: [58.395, 57.12, 57.375]
  RPN:
    HEAD_NAME: "StandardRPNHead"
    POST_NMS_TOPK_TEST: 300
    BATCH_SIZE_PER_IMAGE: 256
  ROI_HEADS:
    NMS_THRESH_TEST: 0.4
    BATCH_SIZE_PER_IMAGE: 32  #!!!!!!
    NUM_CLASSES: 48 # num of seen classes
  ROI_BOX_HEAD:
    BACKGROUND_WEIGHT: 0.2
    IGNORE_ZERO_CATS: True  # open-vocabulary
    # CAT_FREQ_PATH: 'datasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json'
    CAT_FREQ_PATH: '' # whether consider unseen classes in softmax ce loss
    BASE_ALPHA: 0.2
    NOVEL_BETA: 0.45
  ROI_MASK_HEAD:
    NAME: "samMaskHead"
    MASK_LOSS_TYPE: "ce_dice" 
    WITH_SINCOS: True
    PER_QUERY_POINT: 4
    SELECT_FORE_CLS: False # !!!!! consider the background class is important
    BOX_PROMPTER: False # !!!!! 
    ADD_PE_CONTEXT: True # !!!!!
    IOU_LOSS_WEIGHT: 0. # !!!!
    ADD_PE_BEFORE_POOL: True # !!!!
  MASK_ON: True
  SAM_ON: True # !!!!
DATASETS:
  TRAIN: ("coco_zeroshot_train",)
  TEST: ("coco_generalized_zeroshot_val",)
DATALOADER:
  NUM_WORKERS: 16 # num_workers == batchsize_per_gpu
SOLVER:
  IMS_PER_BATCH: 32  # change  # max 8 imgs per batch
  BASE_LR: 0.001  # change0.000025
  MAX_ITER: 22500
  CHECKPOINT_PERIOD: 20000  #  change
  OPTIMIZER: 'SGD'
  WEIGHT_DECAY: 0.01
  LR_SCHEDULER_NAME: "WarmupMultiStepLR"
  WARMUP_FACTOR: 0.16
  WARMUP_METHOD: "linear"
  WARMUP_ITERS: 2000
  STEPS: (20250, 21375, 21738)
  GAMMA: 0.1
  MOMENTUM: 0.9
INPUT:
  CLIP_TRAIN_SIZE: 1024
  CUSTOM_AUG: ResizeLongLSJ2 # !!!!
TEST:
  DETECTIONS_PER_IMAGE: 300  #test_topk_per_image
  EVAL_PERIOD: 90000 # change
  IMS_PER_BATCH: 1 #every gpu has most 2 images  # change
  SCORE_TYPE: 'cls'
OUTPUT_DIR: './output/clipRpn/SamOn'