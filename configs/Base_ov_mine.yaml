MODEL:
  META_ARCHITECTURE: "ClipOpenDetector" 
  BACKBONE:
    NAME: "build_clip_fpn_backbone" #SAM vit_h
    TYPE: "vit_t"
    CLIP_TYPE: "ViT-B/16"
    ADD_UNFROZEN: 'xxx' # unfrozen extra part of model, the name is relative to sam and clip
  WEIGHTS: "mobile_sam.pt"
  FPN:
    OUT_CHANNELS: 256
    IN_CHANNELS: [256]
    ANCHOR_STRIDE: [4, 8, 16, 32, 64]
    NORM: 'LN'
    IN_FEATURES: ["res2", "res3", "res4", "res5"] 
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.12, 57.375]
  ANCHOR_GENERATOR:
    NAME: "DefaultAnchorGenerator"
    SIZES: [[32],[64],[128],[256],[512]] 
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]  # Three aspect ratios (same for all in feature maps)
  PROPOSAL_GENERATOR:
    NAME: "SAMRPN"
  RPN:
    HEAD_NAME: "StandardRPNHead"
    IN_FEATURES: ["p2", "p3", "p4", "p5", "p6"] 
    PRE_NMS_TOPK_TRAIN: 2000  # Per FPN level
    PRE_NMS_TOPK_TEST: 1000  # Per FPN level
    # Detectron1 uses 2000 proposals per-batch,
    # (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)
    # which is approximately 1000 proposals per-image since the default batch size for FPN is 2.
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 1000
    IOU_THRESHOLDS: [0.3, 0.7]
    BATCH_SIZE_PER_IMAGE: 256 # the sampling num 
    POSITIVE_FRACTION: 0.5
    BBOX_REG_LOSS_TYPE: "smooth_l1"
    NMS_THRESH: 0.7
    SMOOTH_L1_BETA: 0.
    OBJECTNESS_LOSS_TYPE: "binary_ce" # options: centerness, binary_ce
  ROI_HEADS:
    NAME: "samAnchorPromptRoiHeads" 
    IN_FEATURES: ["p2", "p3", "p4", "p5"]
    SCORE_THRESH_TEST: 0.02
    NUM_CLASSES: 80
    NMS_THRESH_TEST: 0.5
    BATCH_SIZE_PER_IMAGE: 512 #the sampling num 
    POSITIVE_FRACTION: 0.25
    IOU_THRESHOLDS: [0.5]
    IOU_LABELS: [0, 1]
    ALLOW_LOW_QUALITY_MATCHES: True  
    PROPOSAL_APPEND_GT: True
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"  # Shared2FCBBoxHead
    NUM_FC: 2
    CONV_DIM: 256
    FC_DIM: 1024
    BBOX_REG_LOSS_TYPE: "smooth_l1"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: "ROIAlignV2"
    USE_SIGMOID_CE: False
    BBOX_REG_LOSS_WEIGHT: 1.0
    TRAIN_ON_PRED_BOXES: False
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    SMOOTH_L1_BETA: 0.
    CLS_AGNOSTIC_BBOX_REG: True
    IGNORE_ZERO_CATS: True
    CAT_FREQ_PATH: 'datasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json'
  ROI_MASK_HEAD:
    NAME: "samMaskHead"
    NUM_CONV: 4
    CLS_AGNOSTIC_MASK: True
    WITH_SINCOS: True
    MASK_LOSS_TYPE: "ce_dice" 
    MASK_LOSS_WEIGHT: 1.0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: "ROIAlignV2"
    PER_QUERY_POINT: 4
  MASK_ON: True
DATASETS:
  TRAIN: ("coco_zeroshot_train_oriorder",)
  TEST: ("coco_generalized_zeroshot_val",)
DATALOADER:
  NUM_WORKERS: 8 # num_workers == batchsize_per_gpu
SOLVER:
  IMS_PER_BATCH: 16  # change  # max 8 imgs per batch
  BASE_LR: 0.0005  # change0.000025
  STEPS: (60000, 80000)  # change 
  WARMUP_ITERS: 7500  
  WARMUP_METHOD : "linear"
  WARMUP_FACTOR: 0.0001 #1.0001
  LR_SCHEDULER_NAME: "WarmupCosineLR" 
  # LR_SCHEDULER_NAME: "WarmupMultiStepLR"
  WEIGHT_DECAY: 0.001  
  MAX_ITER: 90000
  CHECKPOINT_PERIOD: 5000  #  change
  USE_CUSTOM_SOLVER: True
  OPTIMIZER: 'ADAMW'
  LOGGER_FREQ: 20  # the output freq of logger writer
  AMP:
    ENABLED: True
INPUT:
  TRAIN_SIZE: 1024
  TEST_SIZE: 1024 
  TEST_INPUT_TYPE: ResizeLongestSize
  PROMPT_SIZE: (90, 4)
  CUSTOM_AUG: ResizeLongestSize
  FORMAT: "RGB"
  MASK_FORMAT: "bitmask"
  CLIP_TRAIN_SIZE: 224
TEST:
  DETECTIONS_PER_IMAGE: 300  #test_topk_per_image
  MASK_THR_BINARY: 0.5  
  DO_POSTPROCESS: True
  EVAL_PERIOD: 90000 # change
  IMS_PER_BATCH: 1 #every gpu has most 2 images  # change
VERSION: 2
FP16: True
OUTPUT_DIR: './output/ovcoco'
WANDB: False