[12/07 15:49:50] detectron2 INFO: Rank of current process: 0. World size: 1
[12/07 15:49:51] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]
numpy                            1.23.4
detectron2                       0.6 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/detectron2
Compiler                         GCC 7.5
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3,4,5,6,7              NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   515.76
CUDA_HOME                        /home/xchen/cuda-11.4/
Pillow                           9.4.0
torchvision                      0.11.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/07 15:49:51] detectron2 INFO: Command line arguments: Namespace(config_file='configs/OpenDet_tiny_coco.yaml', dist_url='tcp://127.0.0.1:50165', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2', 'OUTPUT_DIR', '.output/test'], resume=False)
[12/07 15:49:51] detectron2 INFO: Contents of args.config_file=configs/OpenDet_tiny_coco.yaml:
[38;5;245m# _BASE_: "Base_OVCOCO_C4_1x.yaml"[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSamOpenDetector[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_sam_vit_det_backbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m#SAM vit_h[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mvit_t[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mViT-B/16[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcontext_former_pe[39m[38;5;186m'[39m[38;5;15m [39m[38;5;245m# unfrozen extra part of model, the name is relative to sam and clip[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmobile_sam.pt[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "/opt/tiger/OpenVo-Seg-master/output/wo_mask_with_prompt_encoder_roi_head_withgrad/model_final.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "sam_vit_h_4b8939.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "output/Detic-COCO/RSPrompter_anchor/model_0000999.pth"[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m4[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m16[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m32[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m64[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mLN[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m123.675[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m116.280[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m103.530[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m58.395[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.375[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDefaultAnchorGenerator[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m32[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m64[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m128[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m512[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1.0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m2.0[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m  [39m[38;5;245m# Three aspect ratios (same for all in feature maps)[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSAMRPN[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStandardRPNHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat0[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;245m# Detectron1 uses 2000 proposals per-batch,[39m
[38;5;15m    [39m[38;5;245m# (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)[39m
[38;5;15m    [39m[38;5;245m# which is approximately 1000 proposals per-image since the default batch size for FPN is 2.[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.3[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m0.7[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m[38;5;15m [39m[38;5;245m# the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbinary_ce[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m# options: centerness, binary_ce[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamAnchorPromptRoiHeads[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m[38;5;15m [39m[38;5;245m#the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m[38;5;15m  [39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mFastRCNNConvFCHead[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;245m# Shared2FCBBoxHead[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(10.0,[39m[38;5;141m [39m[38;5;141m10.0,[39m[38;5;141m [39m[38;5;141m5.0,[39m[38;5;141m [39m[38;5;141m5.0)[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamMaskHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mce_dice[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_zeroshot_train_oriorder",)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_not_zeroshot_val",)[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m [39m[38;5;245m# num_workers == batchsize_per_gpu[39m
[38;5;15m  [39m[38;5;245m# PERSISTENT_WORKERS: True [39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m  [39m[38;5;245m# change  # max 8 imgs per batch[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m[38;5;15m  [39m[38;5;245m# change0.000025[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(60000,[39m[38;5;141m [39m[38;5;141m80000)[39m[38;5;15m  [39m[38;5;245m# change [39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD [39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m[38;5;15m [39m[38;5;245m#1.0001[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mWarmupCosineLR[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;245m# LR_SCHEDULER_NAME: "WarmupMultiStepLR"[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m[38;5;15m  [39m[38;5;245m#  change[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mADAMW[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m[38;5;15m  [39m[38;5;245m# the output freq of logger writer[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(90,[39m[38;5;141m [39m[38;5;141m4)[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# PAD_MASK: True[39m
[38;5;15m  [39m[38;5;245m# MASK_PAD_VAL: 0.0[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbitmask[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m[38;5;15m  [39m[38;5;245m#test_topk_per_image[39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m[38;5;15m [39m[38;5;245m# change[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m[38;5;15m [39m[38;5;245m#every gpu has most 2 images  # change[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcls[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m./output/ovcoco[39m[38;5;186m'[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m

[12/07 15:49:51] detectron2 INFO: Running with full config:
[38;5;204mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;204mPERSISTENT_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_not_zeroshot_val[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_zeroshot_train_oriorder[39m
[38;5;204mFIND_UNUSED_PARAM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m  [39m[38;5;204mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbitmask[39m
[38;5;15m  [39m[38;5;204mMASK_PAD_VAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;204mPAD_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;204mSCALE_RANGE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;204mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcontext_former_pe[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mViT-B/16[39m
[38;5;15m    [39m[38;5;204mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_sam_vit_det_backbone[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvit_t[39m
[38;5;15m  [39m[38;5;204mCONFIGS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mONLY_DECODER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;204mINNER_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mLN[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mSELECTED_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m22[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m26[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m28[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30[39m
[38;5;15m    [39m[38;5;204mUP_SAMPLE_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSamOpenDetector[39m
[38;5;15m  [39m[38;5;204mNUM_SAMPLE_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m  [39m[38;5;204mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSAMRPN[39m
[38;5;15m  [39m[38;5;204mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;204mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;204mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;204mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFastRCNNConvFCHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamAnchorPromptRoiHeads[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m  [39m[38;5;204mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mce_dice[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamMaskHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;204mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat0[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbinary_ce[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAM_FROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSemSegFPNHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m54[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmobile_sam.pt[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m.output/test[39m
[38;5;204mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m
[38;5;15m  [39m[38;5;204mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;204mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvalue[39m
[38;5;15m    [39m[38;5;204mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupCosineLR[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;204mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m80000[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;204mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m  [39m[38;5;204mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcls[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m

[12/07 15:49:51] detectron2 INFO: Full config saved to .output/test/config.yaml
[12/07 15:49:51] d2.utils.env INFO: Using a generated random seed 52466145
[12/07 15:50:10] detectron2 INFO: Rank of current process: 0. World size: 1
[12/07 15:50:11] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]
numpy                            1.23.4
detectron2                       0.6 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/detectron2
Compiler                         GCC 7.5
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3,4,5,6,7              NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   515.76
CUDA_HOME                        /home/xchen/cuda-11.4/
Pillow                           9.4.0
torchvision                      0.11.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/07 15:50:11] detectron2 INFO: Command line arguments: Namespace(config_file='configs/OpenDet_tiny_coco.yaml', dist_url='tcp://127.0.0.1:50165', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2', 'OUTPUT_DIR', '.output/test'], resume=False)
[12/07 15:50:11] detectron2 INFO: Contents of args.config_file=configs/OpenDet_tiny_coco.yaml:
[38;5;245m# _BASE_: "Base_OVCOCO_C4_1x.yaml"[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSamOpenDetector[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_sam_vit_det_backbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m#SAM vit_h[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mvit_t[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mViT-B/16[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcontext_former_pe[39m[38;5;186m'[39m[38;5;15m [39m[38;5;245m# unfrozen extra part of model, the name is relative to sam and clip[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmobile_sam.pt[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "/opt/tiger/OpenVo-Seg-master/output/wo_mask_with_prompt_encoder_roi_head_withgrad/model_final.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "sam_vit_h_4b8939.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "output/Detic-COCO/RSPrompter_anchor/model_0000999.pth"[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m4[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m16[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m32[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m64[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mLN[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m123.675[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m116.280[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m103.530[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m58.395[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.375[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDefaultAnchorGenerator[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m32[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m64[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m128[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m512[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1.0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m2.0[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m  [39m[38;5;245m# Three aspect ratios (same for all in feature maps)[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSAMRPN[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStandardRPNHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat0[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;245m# Detectron1 uses 2000 proposals per-batch,[39m
[38;5;15m    [39m[38;5;245m# (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)[39m
[38;5;15m    [39m[38;5;245m# which is approximately 1000 proposals per-image since the default batch size for FPN is 2.[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.3[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m0.7[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m[38;5;15m [39m[38;5;245m# the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbinary_ce[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m# options: centerness, binary_ce[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamAnchorPromptRoiHeads[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m[38;5;15m [39m[38;5;245m#the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m[38;5;15m  [39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mFastRCNNConvFCHead[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;245m# Shared2FCBBoxHead[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(10.0,[39m[38;5;141m [39m[38;5;141m10.0,[39m[38;5;141m [39m[38;5;141m5.0,[39m[38;5;141m [39m[38;5;141m5.0)[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamMaskHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mce_dice[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_zeroshot_train_oriorder",)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_not_zeroshot_val",)[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m [39m[38;5;245m# num_workers == batchsize_per_gpu[39m
[38;5;15m  [39m[38;5;245m# PERSISTENT_WORKERS: True [39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m  [39m[38;5;245m# change  # max 8 imgs per batch[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m[38;5;15m  [39m[38;5;245m# change0.000025[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(60000,[39m[38;5;141m [39m[38;5;141m80000)[39m[38;5;15m  [39m[38;5;245m# change [39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD [39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m[38;5;15m [39m[38;5;245m#1.0001[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mWarmupCosineLR[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;245m# LR_SCHEDULER_NAME: "WarmupMultiStepLR"[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m[38;5;15m  [39m[38;5;245m#  change[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mADAMW[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m[38;5;15m  [39m[38;5;245m# the output freq of logger writer[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(90,[39m[38;5;141m [39m[38;5;141m4)[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# PAD_MASK: True[39m
[38;5;15m  [39m[38;5;245m# MASK_PAD_VAL: 0.0[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbitmask[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m[38;5;15m  [39m[38;5;245m#test_topk_per_image[39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m[38;5;15m [39m[38;5;245m# change[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m[38;5;15m [39m[38;5;245m#every gpu has most 2 images  # change[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcls[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m./output/ovcoco[39m[38;5;186m'[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m

[12/07 15:50:11] detectron2 INFO: Running with full config:
[38;5;204mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;204mPERSISTENT_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_not_zeroshot_val[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_zeroshot_train_oriorder[39m
[38;5;204mFIND_UNUSED_PARAM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m  [39m[38;5;204mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbitmask[39m
[38;5;15m  [39m[38;5;204mMASK_PAD_VAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;204mPAD_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;204mSCALE_RANGE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;204mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcontext_former_pe[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mViT-B/16[39m
[38;5;15m    [39m[38;5;204mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_sam_vit_det_backbone[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvit_t[39m
[38;5;15m  [39m[38;5;204mCONFIGS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mONLY_DECODER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;204mINNER_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mLN[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mSELECTED_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m22[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m26[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m28[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30[39m
[38;5;15m    [39m[38;5;204mUP_SAMPLE_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSamOpenDetector[39m
[38;5;15m  [39m[38;5;204mNUM_SAMPLE_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m  [39m[38;5;204mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSAMRPN[39m
[38;5;15m  [39m[38;5;204mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;204mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;204mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;204mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFastRCNNConvFCHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamAnchorPromptRoiHeads[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m  [39m[38;5;204mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mce_dice[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamMaskHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;204mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat0[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbinary_ce[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAM_FROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSemSegFPNHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m54[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmobile_sam.pt[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m.output/test[39m
[38;5;204mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m
[38;5;15m  [39m[38;5;204mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;204mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvalue[39m
[38;5;15m    [39m[38;5;204mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupCosineLR[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;204mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m80000[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;204mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m  [39m[38;5;204mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcls[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m

[12/07 15:50:11] detectron2 INFO: Full config saved to .output/test/config.yaml
[12/07 15:50:11] d2.utils.env INFO: Using a generated random seed 12347455
[12/07 15:50:22] detectron2 INFO: Model:
SamOpenDetector(
  (backbone): SAMVitDet(
    (fpn1): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (1): Norm2d(
        (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): GELU()
      (3): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn2): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn3): Identity()
    (fpn4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (proposal_generator): SAMRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): samAnchorPromptRoiHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): SamRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): samMaskHead(
      (point_emb): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Flatten(start_dim=1, end_dim=-1)
        (4): Linear(in_features=12544, out_features=256, bias=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=True)
        (7): ReLU(inplace=True)
        (8): Linear(in_features=256, out_features=2048, bias=True)
      )
      (contextformer): build_contextformer(
        (decoder1): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (decoder2): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (q_proj): Linear(in_features=256, out_features=768, bias=True)
        (kv_proj): Linear(in_features=1536, out_features=768, bias=True)
      )
    )
    (generator_pe): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
  )
  (sam): Sam(
    (image_encoder): TinyViT(
      (patch_embed): PatchEmbed(
        (seq): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU()
          (2): Conv2d_BN(
            (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layers): ModuleList(
        (0): ConvLayer(
          (blocks): ModuleList(
            (0): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
            (1): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (1): BasicLayer(
          dim=128, input_resolution=(128, 128), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (2): BasicLayer(
          dim=160, input_resolution=(64, 64), depth=6
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (3): BasicLayer(
          dim=320, input_resolution=(64, 64), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (neck): Sequential(
        (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): LayerNorm2d()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (3): LayerNorm2d()
      )
    )
    (prompt_encoder): PromptEncoder(
      (pe_layer): PositionEmbeddingRandom()
      (point_embeddings): ModuleList(
        (0): Embedding(1, 256)
        (1): Embedding(1, 256)
        (2): Embedding(1, 256)
        (3): Embedding(1, 256)
      )
      (not_a_point_embed): Embedding(1, 256)
      (mask_downscaling): Sequential(
        (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
        (4): LayerNorm2d()
        (5): GELU()
        (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (no_mask_embed): Embedding(1, 256)
    )
    (mask_decoder): MaskDecoder(
      (transformer): TwoWayTransformer(
        (layers): ModuleList(
          (0): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
          (1): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
        )
        (final_attn_token_to_image): Attention(
          (q_proj): Linear(in_features=256, out_features=128, bias=True)
          (k_proj): Linear(in_features=256, out_features=128, bias=True)
          (v_proj): Linear(in_features=256, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (iou_token): Embedding(1, 256)
      (mask_tokens): Embedding(4, 256)
      (output_upscaling): Sequential(
        (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
        (4): GELU()
      )
      (output_hypernetworks_mlps): ModuleList(
        (0): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (3): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
      )
      (iou_prediction_head): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
    )
  )
  (clip): CLIP(
    (visual): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
[12/07 15:50:22] detectron2 INFO: Optimized parameters:
{'backbone.fpn1.0.bias',
 'backbone.fpn1.0.weight',
 'backbone.fpn1.1.ln.bias',
 'backbone.fpn1.1.ln.weight',
 'backbone.fpn1.3.bias',
 'backbone.fpn1.3.weight',
 'backbone.fpn2.0.bias',
 'backbone.fpn2.0.weight',
 'context_former_pe',
 'proposal_generator.rpn_head.anchor_deltas.bias',
 'proposal_generator.rpn_head.anchor_deltas.weight',
 'proposal_generator.rpn_head.conv.bias',
 'proposal_generator.rpn_head.conv.weight',
 'proposal_generator.rpn_head.objectness_logits.bias',
 'proposal_generator.rpn_head.objectness_logits.weight',
 'roi_heads.box_head.fc1.bias',
 'roi_heads.box_head.fc1.weight',
 'roi_heads.box_head.fc2.bias',
 'roi_heads.box_head.fc2.weight',
 'roi_heads.box_predictor.bbox_pred.bias',
 'roi_heads.box_predictor.bbox_pred.weight',
 'roi_heads.box_predictor.cls_score.bias',
 'roi_heads.box_predictor.cls_score.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.norm.bias',
 'roi_heads.mask_head.contextformer.decoder1.norm.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.kv_proj.bias',
 'roi_heads.mask_head.contextformer.kv_proj.weight',
 'roi_heads.mask_head.contextformer.logit_scale',
 'roi_heads.mask_head.contextformer.q_proj.bias',
 'roi_heads.mask_head.contextformer.q_proj.weight',
 'roi_heads.mask_head.point_emb.0.bias',
 'roi_heads.mask_head.point_emb.0.weight',
 'roi_heads.mask_head.point_emb.1.bias',
 'roi_heads.mask_head.point_emb.1.weight',
 'roi_heads.mask_head.point_emb.4.bias',
 'roi_heads.mask_head.point_emb.4.weight',
 'roi_heads.mask_head.point_emb.6.bias',
 'roi_heads.mask_head.point_emb.6.weight',
 'roi_heads.mask_head.point_emb.8.bias',
 'roi_heads.mask_head.point_emb.8.weight'}
[12/07 15:50:22] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from mobile_sam.pt ...
[12/07 15:50:22] fvcore.common.checkpoint INFO: [Checkpointer] Loading from mobile_sam.pt ...
[12/07 15:50:22] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule sam - Total num: 171
[12/07 15:50:22] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn1.0.{bias, weight}[0m
[34mbackbone.fpn1.1.ln.{bias, weight}[0m
[34mbackbone.fpn1.3.{bias, weight}[0m
[34mbackbone.fpn2.0.{bias, weight}[0m
[34mclip.ln_final.{bias, weight}[0m
[34mclip.token_embedding.weight[0m
[34mclip.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.conv1.weight[0m
[34mclip.visual.ln_post.{bias, weight}[0m
[34mclip.visual.ln_pre.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.{class_embedding, positional_embedding, proj}[0m
[34mclip.{logit_scale, positional_embedding, text_projection}[0m
[34mcontext_former_pe[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.kv_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.logit_scale[0m
[34mroi_heads.mask_head.contextformer.q_proj.{bias, weight}[0m
[34mroi_heads.mask_head.freq_weight[0m
[34mroi_heads.mask_head.point_emb.0.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.1.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.mask_head.point_emb.4.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.6.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.8.{bias, weight}[0m
[12/07 15:50:22] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mimage_encoder.head.{bias, weight}[0m
  [35mimage_encoder.norm_head.{bias, weight}[0m
[12/07 15:50:22] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeLongestSizeFlip(longest_length=1024), RandomFlip(prob=0.5)]
[12/07 15:50:34] d2.data.datasets.coco INFO: Loading datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json takes 11.97 seconds.
[12/07 15:50:36] d2.data.datasets.coco INFO: Loaded 107761 images in COCO format from datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json
[12/07 15:50:40] d2.data.build INFO: Removed 0 images with no usable annotations. 107761 images left.
[12/07 15:50:43] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 257253       |   bicycle    | 7056         |      car      | 43533        |
|  motorcycle   | 8654         |   airplane   | 0            |      bus      | 0            |
|     train     | 4570         |    truck     | 9970         |     boat      | 10576        |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 9820         |     bird      | 10542        |
|      cat      | 0            |     dog      | 0            |     horse     | 6567         |
|     sheep     | 9223         |     cow      | 0            |   elephant    | 0            |
|     bear      | 1294         |    zebra     | 5269         |    giraffe    | 5128         |
|   backpack    | 8714         |   umbrella   | 0            |    handbag    | 12342        |
|      tie      | 0            |   suitcase   | 6112         |    frisbee    | 2681         |
|     skis      | 6623         |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 8802         | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 6095         | tennis racket | 0            |
|    bottle     | 24070        |  wine glass  | 0            |      cup      | 0            |
|     fork      | 5474         |    knife     | 0            |     spoon     | 6159         |
|     bowl      | 14323        |    banana    | 9195         |     apple     | 5776         |
|   sandwich    | 4356         |    orange    | 6302         |   broccoli    | 7261         |
|    carrot     | 7758         |   hot dog    | 0            |     pizza     | 5807         |
|     donut     | 7005         |     cake     | 0            |     chair     | 38073        |
|     couch     | 0            | potted plant | 0            |      bed      | 4192         |
| dining table  | 0            |    toilet    | 4149         |      tv       | 5803         |
|    laptop     | 4960         |    mouse     | 2261         |    remote     | 5700         |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 1672         |
|     oven      | 3334         |   toaster    | 225          |     sink      | 0            |
| refrigerator  | 2634         |     book     | 24077        |     clock     | 6320         |
|     vase      | 6577         |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 1945         |               |              |
|     total     | 656232       |              |              |               |              |[0m
[12/07 15:50:43] d2.data.build INFO: Using training sampler TrainingSampler
[12/07 15:50:43] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 15:50:43] d2.data.common INFO: Serializing 107761 elements to byte tensors and concatenating them all ...
[12/07 15:50:45] d2.data.common INFO: Serialized dataset takes 361.37 MiB
[12/07 15:50:47] detectron2 INFO: Starting training from iteration 0
[12/07 15:52:51] detectron2 INFO: Rank of current process: 0. World size: 1
[12/07 15:52:52] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]
numpy                            1.23.4
detectron2                       0.6 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/detectron2
Compiler                         GCC 7.5
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3,4,5,6,7              NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   515.76
CUDA_HOME                        /home/xchen/cuda-11.4/
Pillow                           9.4.0
torchvision                      0.11.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/07 15:52:52] detectron2 INFO: Command line arguments: Namespace(config_file='configs/OpenDet_tiny_coco.yaml', dist_url='tcp://127.0.0.1:50165', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2', 'OUTPUT_DIR', '.output/test'], resume=False)
[12/07 15:52:52] detectron2 INFO: Contents of args.config_file=configs/OpenDet_tiny_coco.yaml:
[38;5;245m# _BASE_: "Base_OVCOCO_C4_1x.yaml"[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSamOpenDetector[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_sam_vit_det_backbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m#SAM vit_h[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mvit_t[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mViT-B/16[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcontext_former_pe[39m[38;5;186m'[39m[38;5;15m [39m[38;5;245m# unfrozen extra part of model, the name is relative to sam and clip[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmobile_sam.pt[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "/opt/tiger/OpenVo-Seg-master/output/wo_mask_with_prompt_encoder_roi_head_withgrad/model_final.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "sam_vit_h_4b8939.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "output/Detic-COCO/RSPrompter_anchor/model_0000999.pth"[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m4[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m16[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m32[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m64[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mLN[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m123.675[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m116.280[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m103.530[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m58.395[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.375[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDefaultAnchorGenerator[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m32[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m64[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m128[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m512[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1.0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m2.0[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m  [39m[38;5;245m# Three aspect ratios (same for all in feature maps)[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSAMRPN[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStandardRPNHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat0[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;245m# Detectron1 uses 2000 proposals per-batch,[39m
[38;5;15m    [39m[38;5;245m# (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)[39m
[38;5;15m    [39m[38;5;245m# which is approximately 1000 proposals per-image since the default batch size for FPN is 2.[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.3[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m0.7[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m[38;5;15m [39m[38;5;245m# the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbinary_ce[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m# options: centerness, binary_ce[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamAnchorPromptRoiHeads[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m[38;5;15m [39m[38;5;245m#the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m[38;5;15m  [39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mFastRCNNConvFCHead[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;245m# Shared2FCBBoxHead[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(10.0,[39m[38;5;141m [39m[38;5;141m10.0,[39m[38;5;141m [39m[38;5;141m5.0,[39m[38;5;141m [39m[38;5;141m5.0)[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamMaskHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mce_dice[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_zeroshot_train_oriorder",)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_not_zeroshot_val",)[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m [39m[38;5;245m# num_workers == batchsize_per_gpu[39m
[38;5;15m  [39m[38;5;245m# PERSISTENT_WORKERS: True [39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m  [39m[38;5;245m# change  # max 8 imgs per batch[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m[38;5;15m  [39m[38;5;245m# change0.000025[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(60000,[39m[38;5;141m [39m[38;5;141m80000)[39m[38;5;15m  [39m[38;5;245m# change [39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD [39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m[38;5;15m [39m[38;5;245m#1.0001[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mWarmupCosineLR[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;245m# LR_SCHEDULER_NAME: "WarmupMultiStepLR"[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m[38;5;15m  [39m[38;5;245m#  change[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mADAMW[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m[38;5;15m  [39m[38;5;245m# the output freq of logger writer[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(90,[39m[38;5;141m [39m[38;5;141m4)[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# PAD_MASK: True[39m
[38;5;15m  [39m[38;5;245m# MASK_PAD_VAL: 0.0[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbitmask[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m[38;5;15m  [39m[38;5;245m#test_topk_per_image[39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m[38;5;15m [39m[38;5;245m# change[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m[38;5;15m [39m[38;5;245m#every gpu has most 2 images  # change[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcls[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m./output/ovcoco[39m[38;5;186m'[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m

[12/07 15:52:52] detectron2 INFO: Running with full config:
[38;5;204mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;204mPERSISTENT_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_not_zeroshot_val[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_zeroshot_train_oriorder[39m
[38;5;204mFIND_UNUSED_PARAM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m  [39m[38;5;204mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbitmask[39m
[38;5;15m  [39m[38;5;204mMASK_PAD_VAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;204mPAD_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;204mSCALE_RANGE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;204mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcontext_former_pe[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mViT-B/16[39m
[38;5;15m    [39m[38;5;204mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_sam_vit_det_backbone[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvit_t[39m
[38;5;15m  [39m[38;5;204mCONFIGS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mONLY_DECODER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;204mINNER_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mLN[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mSELECTED_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m22[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m26[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m28[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30[39m
[38;5;15m    [39m[38;5;204mUP_SAMPLE_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSamOpenDetector[39m
[38;5;15m  [39m[38;5;204mNUM_SAMPLE_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m  [39m[38;5;204mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSAMRPN[39m
[38;5;15m  [39m[38;5;204mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;204mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;204mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;204mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFastRCNNConvFCHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamAnchorPromptRoiHeads[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m  [39m[38;5;204mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mce_dice[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamMaskHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;204mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat0[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbinary_ce[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAM_FROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSemSegFPNHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m54[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmobile_sam.pt[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m.output/test[39m
[38;5;204mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m
[38;5;15m  [39m[38;5;204mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;204mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvalue[39m
[38;5;15m    [39m[38;5;204mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupCosineLR[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;204mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m80000[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;204mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m  [39m[38;5;204mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcls[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m

[12/07 15:52:52] detectron2 INFO: Full config saved to .output/test/config.yaml
[12/07 15:52:52] d2.utils.env INFO: Using a generated random seed 53246328
[12/07 15:53:02] detectron2 INFO: Model:
SamOpenDetector(
  (backbone): SAMVitDet(
    (fpn1): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (1): Norm2d(
        (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): GELU()
      (3): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn2): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn3): Identity()
    (fpn4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (proposal_generator): SAMRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): samAnchorPromptRoiHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): SamRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): samMaskHead(
      (point_emb): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Flatten(start_dim=1, end_dim=-1)
        (4): Linear(in_features=12544, out_features=256, bias=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=True)
        (7): ReLU(inplace=True)
        (8): Linear(in_features=256, out_features=2048, bias=True)
      )
      (contextformer): build_contextformer(
        (decoder1): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (decoder2): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (q_proj): Linear(in_features=256, out_features=768, bias=True)
        (kv_proj): Linear(in_features=1536, out_features=768, bias=True)
      )
    )
    (generator_pe): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
  )
  (sam): Sam(
    (image_encoder): TinyViT(
      (patch_embed): PatchEmbed(
        (seq): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU()
          (2): Conv2d_BN(
            (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layers): ModuleList(
        (0): ConvLayer(
          (blocks): ModuleList(
            (0): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
            (1): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (1): BasicLayer(
          dim=128, input_resolution=(128, 128), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (2): BasicLayer(
          dim=160, input_resolution=(64, 64), depth=6
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (3): BasicLayer(
          dim=320, input_resolution=(64, 64), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (neck): Sequential(
        (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): LayerNorm2d()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (3): LayerNorm2d()
      )
    )
    (prompt_encoder): PromptEncoder(
      (pe_layer): PositionEmbeddingRandom()
      (point_embeddings): ModuleList(
        (0): Embedding(1, 256)
        (1): Embedding(1, 256)
        (2): Embedding(1, 256)
        (3): Embedding(1, 256)
      )
      (not_a_point_embed): Embedding(1, 256)
      (mask_downscaling): Sequential(
        (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
        (4): LayerNorm2d()
        (5): GELU()
        (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (no_mask_embed): Embedding(1, 256)
    )
    (mask_decoder): MaskDecoder(
      (transformer): TwoWayTransformer(
        (layers): ModuleList(
          (0): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
          (1): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
        )
        (final_attn_token_to_image): Attention(
          (q_proj): Linear(in_features=256, out_features=128, bias=True)
          (k_proj): Linear(in_features=256, out_features=128, bias=True)
          (v_proj): Linear(in_features=256, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (iou_token): Embedding(1, 256)
      (mask_tokens): Embedding(4, 256)
      (output_upscaling): Sequential(
        (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
        (4): GELU()
      )
      (output_hypernetworks_mlps): ModuleList(
        (0): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (3): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
      )
      (iou_prediction_head): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
    )
  )
  (clip): CLIP(
    (visual): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
[12/07 15:53:02] detectron2 INFO: Optimized parameters:
{'backbone.fpn1.0.bias',
 'backbone.fpn1.0.weight',
 'backbone.fpn1.1.ln.bias',
 'backbone.fpn1.1.ln.weight',
 'backbone.fpn1.3.bias',
 'backbone.fpn1.3.weight',
 'backbone.fpn2.0.bias',
 'backbone.fpn2.0.weight',
 'context_former_pe',
 'proposal_generator.rpn_head.anchor_deltas.bias',
 'proposal_generator.rpn_head.anchor_deltas.weight',
 'proposal_generator.rpn_head.conv.bias',
 'proposal_generator.rpn_head.conv.weight',
 'proposal_generator.rpn_head.objectness_logits.bias',
 'proposal_generator.rpn_head.objectness_logits.weight',
 'roi_heads.box_head.fc1.bias',
 'roi_heads.box_head.fc1.weight',
 'roi_heads.box_head.fc2.bias',
 'roi_heads.box_head.fc2.weight',
 'roi_heads.box_predictor.bbox_pred.bias',
 'roi_heads.box_predictor.bbox_pred.weight',
 'roi_heads.box_predictor.cls_score.bias',
 'roi_heads.box_predictor.cls_score.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.norm.bias',
 'roi_heads.mask_head.contextformer.decoder1.norm.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.kv_proj.bias',
 'roi_heads.mask_head.contextformer.kv_proj.weight',
 'roi_heads.mask_head.contextformer.logit_scale',
 'roi_heads.mask_head.contextformer.q_proj.bias',
 'roi_heads.mask_head.contextformer.q_proj.weight',
 'roi_heads.mask_head.point_emb.0.bias',
 'roi_heads.mask_head.point_emb.0.weight',
 'roi_heads.mask_head.point_emb.1.bias',
 'roi_heads.mask_head.point_emb.1.weight',
 'roi_heads.mask_head.point_emb.4.bias',
 'roi_heads.mask_head.point_emb.4.weight',
 'roi_heads.mask_head.point_emb.6.bias',
 'roi_heads.mask_head.point_emb.6.weight',
 'roi_heads.mask_head.point_emb.8.bias',
 'roi_heads.mask_head.point_emb.8.weight'}
[12/07 15:53:02] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from mobile_sam.pt ...
[12/07 15:53:02] fvcore.common.checkpoint INFO: [Checkpointer] Loading from mobile_sam.pt ...
[12/07 15:53:03] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule sam - Total num: 171
[12/07 15:53:03] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn1.0.{bias, weight}[0m
[34mbackbone.fpn1.1.ln.{bias, weight}[0m
[34mbackbone.fpn1.3.{bias, weight}[0m
[34mbackbone.fpn2.0.{bias, weight}[0m
[34mclip.ln_final.{bias, weight}[0m
[34mclip.token_embedding.weight[0m
[34mclip.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.conv1.weight[0m
[34mclip.visual.ln_post.{bias, weight}[0m
[34mclip.visual.ln_pre.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.{class_embedding, positional_embedding, proj}[0m
[34mclip.{logit_scale, positional_embedding, text_projection}[0m
[34mcontext_former_pe[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.kv_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.logit_scale[0m
[34mroi_heads.mask_head.contextformer.q_proj.{bias, weight}[0m
[34mroi_heads.mask_head.freq_weight[0m
[34mroi_heads.mask_head.point_emb.0.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.1.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.mask_head.point_emb.4.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.6.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.8.{bias, weight}[0m
[12/07 15:53:03] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mimage_encoder.head.{bias, weight}[0m
  [35mimage_encoder.norm_head.{bias, weight}[0m
[12/07 15:53:03] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeLongestSizeFlip(longest_length=1024), RandomFlip(prob=0.5)]
[12/07 15:53:14] d2.data.datasets.coco INFO: Loading datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json takes 10.91 seconds.
[12/07 15:53:15] d2.data.datasets.coco INFO: Loaded 107761 images in COCO format from datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json
[12/07 15:53:19] d2.data.build INFO: Removed 0 images with no usable annotations. 107761 images left.
[12/07 15:53:22] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 257253       |   bicycle    | 7056         |      car      | 43533        |
|  motorcycle   | 8654         |   airplane   | 0            |      bus      | 0            |
|     train     | 4570         |    truck     | 9970         |     boat      | 10576        |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 9820         |     bird      | 10542        |
|      cat      | 0            |     dog      | 0            |     horse     | 6567         |
|     sheep     | 9223         |     cow      | 0            |   elephant    | 0            |
|     bear      | 1294         |    zebra     | 5269         |    giraffe    | 5128         |
|   backpack    | 8714         |   umbrella   | 0            |    handbag    | 12342        |
|      tie      | 0            |   suitcase   | 6112         |    frisbee    | 2681         |
|     skis      | 6623         |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 8802         | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 6095         | tennis racket | 0            |
|    bottle     | 24070        |  wine glass  | 0            |      cup      | 0            |
|     fork      | 5474         |    knife     | 0            |     spoon     | 6159         |
|     bowl      | 14323        |    banana    | 9195         |     apple     | 5776         |
|   sandwich    | 4356         |    orange    | 6302         |   broccoli    | 7261         |
|    carrot     | 7758         |   hot dog    | 0            |     pizza     | 5807         |
|     donut     | 7005         |     cake     | 0            |     chair     | 38073        |
|     couch     | 0            | potted plant | 0            |      bed      | 4192         |
| dining table  | 0            |    toilet    | 4149         |      tv       | 5803         |
|    laptop     | 4960         |    mouse     | 2261         |    remote     | 5700         |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 1672         |
|     oven      | 3334         |   toaster    | 225          |     sink      | 0            |
| refrigerator  | 2634         |     book     | 24077        |     clock     | 6320         |
|     vase      | 6577         |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 1945         |               |              |
|     total     | 656232       |              |              |               |              |[0m
[12/07 15:53:22] d2.data.build INFO: Using training sampler TrainingSampler
[12/07 15:53:22] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 15:53:22] d2.data.common INFO: Serializing 107761 elements to byte tensors and concatenating them all ...
[12/07 15:53:25] d2.data.common INFO: Serialized dataset takes 361.37 MiB
[12/07 15:53:26] detectron2 INFO: Starting training from iteration 0
[12/07 16:50:50] detectron2 INFO: Rank of current process: 0. World size: 1
[12/07 16:50:50] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]
numpy                            1.23.4
detectron2                       0.6 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/detectron2
Compiler                         GCC 7.5
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3,4,5,6,7              NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   515.76
CUDA_HOME                        /home/xchen/cuda-11.4/
Pillow                           9.4.0
torchvision                      0.11.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/07 16:50:50] detectron2 INFO: Command line arguments: Namespace(config_file='configs/OpenDet_tiny_coco.yaml', dist_url='tcp://127.0.0.1:50165', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2', 'OUTPUT_DIR', '.output/test'], resume=False)
[12/07 16:50:50] detectron2 INFO: Contents of args.config_file=configs/OpenDet_tiny_coco.yaml:
[38;5;245m# _BASE_: "Base_OVCOCO_C4_1x.yaml"[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSamOpenDetector[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_sam_vit_det_backbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m#SAM vit_h[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mvit_t[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mViT-B/16[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcontext_former_pe[39m[38;5;186m'[39m[38;5;15m [39m[38;5;245m# unfrozen extra part of model, the name is relative to sam and clip[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmobile_sam.pt[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "/opt/tiger/OpenVo-Seg-master/output/wo_mask_with_prompt_encoder_roi_head_withgrad/model_final.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "sam_vit_h_4b8939.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "output/Detic-COCO/RSPrompter_anchor/model_0000999.pth"[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m4[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m16[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m32[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m64[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mLN[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m123.675[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m116.280[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m103.530[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m58.395[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.375[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDefaultAnchorGenerator[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m32[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m64[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m128[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m512[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1.0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m2.0[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m  [39m[38;5;245m# Three aspect ratios (same for all in feature maps)[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSAMRPN[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStandardRPNHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat0[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;245m# Detectron1 uses 2000 proposals per-batch,[39m
[38;5;15m    [39m[38;5;245m# (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)[39m
[38;5;15m    [39m[38;5;245m# which is approximately 1000 proposals per-image since the default batch size for FPN is 2.[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.3[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m0.7[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m[38;5;15m [39m[38;5;245m# the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbinary_ce[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m# options: centerness, binary_ce[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamAnchorPromptRoiHeads[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m[38;5;15m [39m[38;5;245m#the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m[38;5;15m  [39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mFastRCNNConvFCHead[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;245m# Shared2FCBBoxHead[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(10.0,[39m[38;5;141m [39m[38;5;141m10.0,[39m[38;5;141m [39m[38;5;141m5.0,[39m[38;5;141m [39m[38;5;141m5.0)[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamMaskHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mce_dice[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_zeroshot_train_oriorder",)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_not_zeroshot_val",)[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m [39m[38;5;245m# num_workers == batchsize_per_gpu[39m
[38;5;15m  [39m[38;5;245m# PERSISTENT_WORKERS: True [39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m  [39m[38;5;245m# change  # max 8 imgs per batch[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m[38;5;15m  [39m[38;5;245m# change0.000025[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(60000,[39m[38;5;141m [39m[38;5;141m80000)[39m[38;5;15m  [39m[38;5;245m# change [39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD [39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m[38;5;15m [39m[38;5;245m#1.0001[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mWarmupCosineLR[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;245m# LR_SCHEDULER_NAME: "WarmupMultiStepLR"[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m[38;5;15m  [39m[38;5;245m#  change[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mADAMW[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m[38;5;15m  [39m[38;5;245m# the output freq of logger writer[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(90,[39m[38;5;141m [39m[38;5;141m4)[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# PAD_MASK: True[39m
[38;5;15m  [39m[38;5;245m# MASK_PAD_VAL: 0.0[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbitmask[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m[38;5;15m  [39m[38;5;245m#test_topk_per_image[39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m[38;5;15m [39m[38;5;245m# change[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m[38;5;15m [39m[38;5;245m#every gpu has most 2 images  # change[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcls[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m./output/ovcoco[39m[38;5;186m'[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m

[12/07 16:50:51] detectron2 INFO: Running with full config:
[38;5;204mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;204mPERSISTENT_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_not_zeroshot_val[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_zeroshot_train_oriorder[39m
[38;5;204mFIND_UNUSED_PARAM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m  [39m[38;5;204mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbitmask[39m
[38;5;15m  [39m[38;5;204mMASK_PAD_VAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;204mPAD_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;204mSCALE_RANGE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;204mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcontext_former_pe[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mViT-B/16[39m
[38;5;15m    [39m[38;5;204mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_sam_vit_det_backbone[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvit_t[39m
[38;5;15m  [39m[38;5;204mCONFIGS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mONLY_DECODER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;204mINNER_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mLN[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mSELECTED_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m22[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m26[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m28[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30[39m
[38;5;15m    [39m[38;5;204mUP_SAMPLE_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSamOpenDetector[39m
[38;5;15m  [39m[38;5;204mNUM_SAMPLE_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m  [39m[38;5;204mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSAMRPN[39m
[38;5;15m  [39m[38;5;204mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;204mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;204mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;204mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFastRCNNConvFCHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamAnchorPromptRoiHeads[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m  [39m[38;5;204mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mce_dice[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamMaskHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;204mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat0[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbinary_ce[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAM_FROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSemSegFPNHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m54[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmobile_sam.pt[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m.output/test[39m
[38;5;204mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m
[38;5;15m  [39m[38;5;204mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;204mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvalue[39m
[38;5;15m    [39m[38;5;204mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupCosineLR[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;204mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m80000[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;204mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m  [39m[38;5;204mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcls[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m

[12/07 16:50:51] detectron2 INFO: Full config saved to .output/test/config.yaml
[12/07 16:50:51] d2.utils.env INFO: Using a generated random seed 52207399
[12/07 16:51:02] detectron2 INFO: Model:
SamOpenDetector(
  (backbone): SAMVitDet(
    (fpn1): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (1): Norm2d(
        (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): GELU()
      (3): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn2): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn3): Identity()
    (fpn4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (proposal_generator): SAMRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): samAnchorPromptRoiHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): SamRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): samMaskHead(
      (point_emb): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Flatten(start_dim=1, end_dim=-1)
        (4): Linear(in_features=12544, out_features=256, bias=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=True)
        (7): ReLU(inplace=True)
        (8): Linear(in_features=256, out_features=2048, bias=True)
      )
      (contextformer): build_contextformer(
        (decoder1): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (decoder2): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (q_proj): Linear(in_features=256, out_features=768, bias=True)
        (kv_proj): Linear(in_features=1536, out_features=768, bias=True)
        (proj): Linear(in_features=768, out_features=512, bias=True)
        (ln_mask): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (generator_pe): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
  )
  (sam): Sam(
    (image_encoder): TinyViT(
      (patch_embed): PatchEmbed(
        (seq): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU()
          (2): Conv2d_BN(
            (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layers): ModuleList(
        (0): ConvLayer(
          (blocks): ModuleList(
            (0): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
            (1): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (1): BasicLayer(
          dim=128, input_resolution=(128, 128), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (2): BasicLayer(
          dim=160, input_resolution=(64, 64), depth=6
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (3): BasicLayer(
          dim=320, input_resolution=(64, 64), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (neck): Sequential(
        (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): LayerNorm2d()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (3): LayerNorm2d()
      )
    )
    (prompt_encoder): PromptEncoder(
      (pe_layer): PositionEmbeddingRandom()
      (point_embeddings): ModuleList(
        (0): Embedding(1, 256)
        (1): Embedding(1, 256)
        (2): Embedding(1, 256)
        (3): Embedding(1, 256)
      )
      (not_a_point_embed): Embedding(1, 256)
      (mask_downscaling): Sequential(
        (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
        (4): LayerNorm2d()
        (5): GELU()
        (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (no_mask_embed): Embedding(1, 256)
    )
    (mask_decoder): MaskDecoder(
      (transformer): TwoWayTransformer(
        (layers): ModuleList(
          (0): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
          (1): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
        )
        (final_attn_token_to_image): Attention(
          (q_proj): Linear(in_features=256, out_features=128, bias=True)
          (k_proj): Linear(in_features=256, out_features=128, bias=True)
          (v_proj): Linear(in_features=256, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (iou_token): Embedding(1, 256)
      (mask_tokens): Embedding(4, 256)
      (output_upscaling): Sequential(
        (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
        (4): GELU()
      )
      (output_hypernetworks_mlps): ModuleList(
        (0): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (3): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
      )
      (iou_prediction_head): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
    )
  )
  (clip): CLIP(
    (visual): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
[12/07 16:51:02] detectron2 INFO: Optimized parameters:
{'backbone.fpn1.0.bias',
 'backbone.fpn1.0.weight',
 'backbone.fpn1.1.ln.bias',
 'backbone.fpn1.1.ln.weight',
 'backbone.fpn1.3.bias',
 'backbone.fpn1.3.weight',
 'backbone.fpn2.0.bias',
 'backbone.fpn2.0.weight',
 'context_former_pe',
 'proposal_generator.rpn_head.anchor_deltas.bias',
 'proposal_generator.rpn_head.anchor_deltas.weight',
 'proposal_generator.rpn_head.conv.bias',
 'proposal_generator.rpn_head.conv.weight',
 'proposal_generator.rpn_head.objectness_logits.bias',
 'proposal_generator.rpn_head.objectness_logits.weight',
 'roi_heads.box_head.fc1.bias',
 'roi_heads.box_head.fc1.weight',
 'roi_heads.box_head.fc2.bias',
 'roi_heads.box_head.fc2.weight',
 'roi_heads.box_predictor.bbox_pred.bias',
 'roi_heads.box_predictor.bbox_pred.weight',
 'roi_heads.box_predictor.cls_score.bias',
 'roi_heads.box_predictor.cls_score.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.norm.bias',
 'roi_heads.mask_head.contextformer.decoder1.norm.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.kv_proj.bias',
 'roi_heads.mask_head.contextformer.kv_proj.weight',
 'roi_heads.mask_head.contextformer.ln_mask.bias',
 'roi_heads.mask_head.contextformer.ln_mask.weight',
 'roi_heads.mask_head.contextformer.logit_scale',
 'roi_heads.mask_head.contextformer.proj.bias',
 'roi_heads.mask_head.contextformer.proj.weight',
 'roi_heads.mask_head.contextformer.q_proj.bias',
 'roi_heads.mask_head.contextformer.q_proj.weight',
 'roi_heads.mask_head.point_emb.0.bias',
 'roi_heads.mask_head.point_emb.0.weight',
 'roi_heads.mask_head.point_emb.1.bias',
 'roi_heads.mask_head.point_emb.1.weight',
 'roi_heads.mask_head.point_emb.4.bias',
 'roi_heads.mask_head.point_emb.4.weight',
 'roi_heads.mask_head.point_emb.6.bias',
 'roi_heads.mask_head.point_emb.6.weight',
 'roi_heads.mask_head.point_emb.8.bias',
 'roi_heads.mask_head.point_emb.8.weight'}
[12/07 16:51:02] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from mobile_sam.pt ...
[12/07 16:51:02] fvcore.common.checkpoint INFO: [Checkpointer] Loading from mobile_sam.pt ...
[12/07 16:51:02] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule sam - Total num: 171
[12/07 16:51:02] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn1.0.{bias, weight}[0m
[34mbackbone.fpn1.1.ln.{bias, weight}[0m
[34mbackbone.fpn1.3.{bias, weight}[0m
[34mbackbone.fpn2.0.{bias, weight}[0m
[34mclip.ln_final.{bias, weight}[0m
[34mclip.token_embedding.weight[0m
[34mclip.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.conv1.weight[0m
[34mclip.visual.ln_post.{bias, weight}[0m
[34mclip.visual.ln_pre.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.{class_embedding, positional_embedding, proj}[0m
[34mclip.{logit_scale, positional_embedding, text_projection}[0m
[34mcontext_former_pe[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.kv_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.ln_mask.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.logit_scale[0m
[34mroi_heads.mask_head.contextformer.proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.q_proj.{bias, weight}[0m
[34mroi_heads.mask_head.freq_weight[0m
[34mroi_heads.mask_head.point_emb.0.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.1.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.mask_head.point_emb.4.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.6.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.8.{bias, weight}[0m
[12/07 16:51:02] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mimage_encoder.head.{bias, weight}[0m
  [35mimage_encoder.norm_head.{bias, weight}[0m
[12/07 16:51:02] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeLongestSizeFlip(longest_length=1024), RandomFlip(prob=0.5)]
[12/07 16:51:13] d2.data.datasets.coco INFO: Loading datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json takes 11.10 seconds.
[12/07 16:51:14] d2.data.datasets.coco INFO: Loaded 107761 images in COCO format from datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json
[12/07 16:51:18] d2.data.build INFO: Removed 0 images with no usable annotations. 107761 images left.
[12/07 16:51:22] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 257253       |   bicycle    | 7056         |      car      | 43533        |
|  motorcycle   | 8654         |   airplane   | 0            |      bus      | 0            |
|     train     | 4570         |    truck     | 9970         |     boat      | 10576        |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 9820         |     bird      | 10542        |
|      cat      | 0            |     dog      | 0            |     horse     | 6567         |
|     sheep     | 9223         |     cow      | 0            |   elephant    | 0            |
|     bear      | 1294         |    zebra     | 5269         |    giraffe    | 5128         |
|   backpack    | 8714         |   umbrella   | 0            |    handbag    | 12342        |
|      tie      | 0            |   suitcase   | 6112         |    frisbee    | 2681         |
|     skis      | 6623         |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 8802         | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 6095         | tennis racket | 0            |
|    bottle     | 24070        |  wine glass  | 0            |      cup      | 0            |
|     fork      | 5474         |    knife     | 0            |     spoon     | 6159         |
|     bowl      | 14323        |    banana    | 9195         |     apple     | 5776         |
|   sandwich    | 4356         |    orange    | 6302         |   broccoli    | 7261         |
|    carrot     | 7758         |   hot dog    | 0            |     pizza     | 5807         |
|     donut     | 7005         |     cake     | 0            |     chair     | 38073        |
|     couch     | 0            | potted plant | 0            |      bed      | 4192         |
| dining table  | 0            |    toilet    | 4149         |      tv       | 5803         |
|    laptop     | 4960         |    mouse     | 2261         |    remote     | 5700         |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 1672         |
|     oven      | 3334         |   toaster    | 225          |     sink      | 0            |
| refrigerator  | 2634         |     book     | 24077        |     clock     | 6320         |
|     vase      | 6577         |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 1945         |               |              |
|     total     | 656232       |              |              |               |              |[0m
[12/07 16:51:22] d2.data.build INFO: Using training sampler TrainingSampler
[12/07 16:51:22] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 16:51:22] d2.data.common INFO: Serializing 107761 elements to byte tensors and concatenating them all ...
[12/07 16:51:24] d2.data.common INFO: Serialized dataset takes 361.37 MiB
[12/07 16:51:25] detectron2 INFO: Starting training from iteration 0
[12/07 17:43:24] detectron2 INFO: Rank of current process: 0. World size: 1
[12/07 17:43:25] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]
numpy                            1.23.4
detectron2                       0.6 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/detectron2
Compiler                         GCC 7.5
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3,4,5,6,7              NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   515.76
CUDA_HOME                        /home/xchen/cuda-11.4/
Pillow                           9.4.0
torchvision                      0.11.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/07 17:43:25] detectron2 INFO: Command line arguments: Namespace(config_file='configs/OpenDet_tiny_coco.yaml', dist_url='tcp://127.0.0.1:50165', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2', 'OUTPUT_DIR', '.output/test'], resume=False)
[12/07 17:43:25] detectron2 INFO: Contents of args.config_file=configs/OpenDet_tiny_coco.yaml:
[38;5;245m# _BASE_: "Base_OVCOCO_C4_1x.yaml"[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSamOpenDetector[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_sam_vit_det_backbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m#SAM vit_h[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mvit_t[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mViT-B/16[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcontext_former_pe[39m[38;5;186m'[39m[38;5;15m [39m[38;5;245m# unfrozen extra part of model, the name is relative to sam and clip[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmobile_sam.pt[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "/opt/tiger/OpenVo-Seg-master/output/wo_mask_with_prompt_encoder_roi_head_withgrad/model_final.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "sam_vit_h_4b8939.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "output/Detic-COCO/RSPrompter_anchor/model_0000999.pth"[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m4[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m16[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m32[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m64[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mLN[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m123.675[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m116.280[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m103.530[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m58.395[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.375[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDefaultAnchorGenerator[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m32[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m64[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m128[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m512[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1.0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m2.0[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m  [39m[38;5;245m# Three aspect ratios (same for all in feature maps)[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSAMRPN[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStandardRPNHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat0[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;245m# Detectron1 uses 2000 proposals per-batch,[39m
[38;5;15m    [39m[38;5;245m# (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)[39m
[38;5;15m    [39m[38;5;245m# which is approximately 1000 proposals per-image since the default batch size for FPN is 2.[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.3[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m0.7[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m[38;5;15m [39m[38;5;245m# the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbinary_ce[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m# options: centerness, binary_ce[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamAnchorPromptRoiHeads[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m[38;5;15m [39m[38;5;245m#the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m[38;5;15m  [39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mFastRCNNConvFCHead[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;245m# Shared2FCBBoxHead[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(10.0,[39m[38;5;141m [39m[38;5;141m10.0,[39m[38;5;141m [39m[38;5;141m5.0,[39m[38;5;141m [39m[38;5;141m5.0)[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamMaskHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mce_dice[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_zeroshot_train_oriorder",)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_not_zeroshot_val",)[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m [39m[38;5;245m# num_workers == batchsize_per_gpu[39m
[38;5;15m  [39m[38;5;245m# PERSISTENT_WORKERS: True [39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m  [39m[38;5;245m# change  # max 8 imgs per batch[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m[38;5;15m  [39m[38;5;245m# change0.000025[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(60000,[39m[38;5;141m [39m[38;5;141m80000)[39m[38;5;15m  [39m[38;5;245m# change [39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD [39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m[38;5;15m [39m[38;5;245m#1.0001[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mWarmupCosineLR[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;245m# LR_SCHEDULER_NAME: "WarmupMultiStepLR"[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m[38;5;15m  [39m[38;5;245m#  change[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mADAMW[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m[38;5;15m  [39m[38;5;245m# the output freq of logger writer[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(90,[39m[38;5;141m [39m[38;5;141m4)[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# PAD_MASK: True[39m
[38;5;15m  [39m[38;5;245m# MASK_PAD_VAL: 0.0[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbitmask[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m[38;5;15m  [39m[38;5;245m#test_topk_per_image[39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m[38;5;15m [39m[38;5;245m# change[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m[38;5;15m [39m[38;5;245m#every gpu has most 2 images  # change[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcls[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m./output/ovcoco[39m[38;5;186m'[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m

[12/07 17:43:25] detectron2 INFO: Running with full config:
[38;5;204mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;204mPERSISTENT_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_not_zeroshot_val[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_zeroshot_train_oriorder[39m
[38;5;204mFIND_UNUSED_PARAM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m  [39m[38;5;204mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbitmask[39m
[38;5;15m  [39m[38;5;204mMASK_PAD_VAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;204mPAD_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;204mSCALE_RANGE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;204mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcontext_former_pe[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mViT-B/16[39m
[38;5;15m    [39m[38;5;204mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_sam_vit_det_backbone[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvit_t[39m
[38;5;15m  [39m[38;5;204mCONFIGS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mONLY_DECODER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;204mINNER_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mLN[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mSELECTED_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m22[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m26[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m28[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30[39m
[38;5;15m    [39m[38;5;204mUP_SAMPLE_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSamOpenDetector[39m
[38;5;15m  [39m[38;5;204mNUM_SAMPLE_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m  [39m[38;5;204mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSAMRPN[39m
[38;5;15m  [39m[38;5;204mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;204mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;204mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;204mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFastRCNNConvFCHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamAnchorPromptRoiHeads[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m  [39m[38;5;204mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mce_dice[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamMaskHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;204mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat0[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbinary_ce[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAM_FROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSemSegFPNHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m54[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmobile_sam.pt[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m.output/test[39m
[38;5;204mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m
[38;5;15m  [39m[38;5;204mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;204mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvalue[39m
[38;5;15m    [39m[38;5;204mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupCosineLR[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;204mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m80000[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;204mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m  [39m[38;5;204mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcls[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m

[12/07 17:43:25] detectron2 INFO: Full config saved to .output/test/config.yaml
[12/07 17:43:25] d2.utils.env INFO: Using a generated random seed 26441685
[12/07 17:43:36] detectron2 INFO: Model:
SamOpenDetector(
  (backbone): SAMVitDet(
    (fpn1): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (1): Norm2d(
        (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): GELU()
      (3): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn2): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn3): Identity()
    (fpn4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (proposal_generator): SAMRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): samAnchorPromptRoiHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): SamRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): samMaskHead(
      (point_emb): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Flatten(start_dim=1, end_dim=-1)
        (4): Linear(in_features=12544, out_features=256, bias=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=True)
        (7): ReLU(inplace=True)
        (8): Linear(in_features=256, out_features=2048, bias=True)
      )
      (contextformer): build_contextformer(
        (decoder1): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (decoder2): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (q_proj): Linear(in_features=256, out_features=768, bias=True)
        (kv_proj): Linear(in_features=1536, out_features=768, bias=True)
        (proj): Linear(in_features=768, out_features=512, bias=True)
        (ln_mask): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (generator_pe): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
  )
  (sam): Sam(
    (image_encoder): TinyViT(
      (patch_embed): PatchEmbed(
        (seq): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU()
          (2): Conv2d_BN(
            (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layers): ModuleList(
        (0): ConvLayer(
          (blocks): ModuleList(
            (0): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
            (1): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (1): BasicLayer(
          dim=128, input_resolution=(128, 128), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (2): BasicLayer(
          dim=160, input_resolution=(64, 64), depth=6
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (3): BasicLayer(
          dim=320, input_resolution=(64, 64), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (neck): Sequential(
        (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): LayerNorm2d()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (3): LayerNorm2d()
      )
    )
    (prompt_encoder): PromptEncoder(
      (pe_layer): PositionEmbeddingRandom()
      (point_embeddings): ModuleList(
        (0): Embedding(1, 256)
        (1): Embedding(1, 256)
        (2): Embedding(1, 256)
        (3): Embedding(1, 256)
      )
      (not_a_point_embed): Embedding(1, 256)
      (mask_downscaling): Sequential(
        (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
        (4): LayerNorm2d()
        (5): GELU()
        (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (no_mask_embed): Embedding(1, 256)
    )
    (mask_decoder): MaskDecoder(
      (transformer): TwoWayTransformer(
        (layers): ModuleList(
          (0): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
          (1): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
        )
        (final_attn_token_to_image): Attention(
          (q_proj): Linear(in_features=256, out_features=128, bias=True)
          (k_proj): Linear(in_features=256, out_features=128, bias=True)
          (v_proj): Linear(in_features=256, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (iou_token): Embedding(1, 256)
      (mask_tokens): Embedding(4, 256)
      (output_upscaling): Sequential(
        (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
        (4): GELU()
      )
      (output_hypernetworks_mlps): ModuleList(
        (0): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (3): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
      )
      (iou_prediction_head): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
    )
  )
  (clip): CLIP(
    (visual): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
[12/07 17:43:36] detectron2 INFO: Optimized parameters:
{'backbone.fpn1.0.bias',
 'backbone.fpn1.0.weight',
 'backbone.fpn1.1.ln.bias',
 'backbone.fpn1.1.ln.weight',
 'backbone.fpn1.3.bias',
 'backbone.fpn1.3.weight',
 'backbone.fpn2.0.bias',
 'backbone.fpn2.0.weight',
 'context_former_pe',
 'proposal_generator.rpn_head.anchor_deltas.bias',
 'proposal_generator.rpn_head.anchor_deltas.weight',
 'proposal_generator.rpn_head.conv.bias',
 'proposal_generator.rpn_head.conv.weight',
 'proposal_generator.rpn_head.objectness_logits.bias',
 'proposal_generator.rpn_head.objectness_logits.weight',
 'roi_heads.box_head.fc1.bias',
 'roi_heads.box_head.fc1.weight',
 'roi_heads.box_head.fc2.bias',
 'roi_heads.box_head.fc2.weight',
 'roi_heads.box_predictor.bbox_pred.bias',
 'roi_heads.box_predictor.bbox_pred.weight',
 'roi_heads.box_predictor.cls_score.bias',
 'roi_heads.box_predictor.cls_score.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.norm.bias',
 'roi_heads.mask_head.contextformer.decoder1.norm.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.kv_proj.bias',
 'roi_heads.mask_head.contextformer.kv_proj.weight',
 'roi_heads.mask_head.contextformer.ln_mask.bias',
 'roi_heads.mask_head.contextformer.ln_mask.weight',
 'roi_heads.mask_head.contextformer.logit_scale',
 'roi_heads.mask_head.contextformer.proj.bias',
 'roi_heads.mask_head.contextformer.proj.weight',
 'roi_heads.mask_head.contextformer.q_proj.bias',
 'roi_heads.mask_head.contextformer.q_proj.weight',
 'roi_heads.mask_head.point_emb.0.bias',
 'roi_heads.mask_head.point_emb.0.weight',
 'roi_heads.mask_head.point_emb.1.bias',
 'roi_heads.mask_head.point_emb.1.weight',
 'roi_heads.mask_head.point_emb.4.bias',
 'roi_heads.mask_head.point_emb.4.weight',
 'roi_heads.mask_head.point_emb.6.bias',
 'roi_heads.mask_head.point_emb.6.weight',
 'roi_heads.mask_head.point_emb.8.bias',
 'roi_heads.mask_head.point_emb.8.weight'}
[12/07 17:43:36] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from mobile_sam.pt ...
[12/07 17:43:36] fvcore.common.checkpoint INFO: [Checkpointer] Loading from mobile_sam.pt ...
[12/07 17:43:36] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule sam - Total num: 171
[12/07 17:43:36] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn1.0.{bias, weight}[0m
[34mbackbone.fpn1.1.ln.{bias, weight}[0m
[34mbackbone.fpn1.3.{bias, weight}[0m
[34mbackbone.fpn2.0.{bias, weight}[0m
[34mclip.ln_final.{bias, weight}[0m
[34mclip.token_embedding.weight[0m
[34mclip.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.conv1.weight[0m
[34mclip.visual.ln_post.{bias, weight}[0m
[34mclip.visual.ln_pre.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.{class_embedding, positional_embedding, proj}[0m
[34mclip.{logit_scale, positional_embedding, text_projection}[0m
[34mcontext_former_pe[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.kv_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.ln_mask.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.logit_scale[0m
[34mroi_heads.mask_head.contextformer.proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.q_proj.{bias, weight}[0m
[34mroi_heads.mask_head.freq_weight[0m
[34mroi_heads.mask_head.point_emb.0.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.1.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.mask_head.point_emb.4.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.6.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.8.{bias, weight}[0m
[12/07 17:43:36] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mimage_encoder.head.{bias, weight}[0m
  [35mimage_encoder.norm_head.{bias, weight}[0m
[12/07 17:43:36] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeLongestSizeFlip(longest_length=1024), RandomFlip(prob=0.5)]
[12/07 17:43:47] d2.data.datasets.coco INFO: Loading datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json takes 11.16 seconds.
[12/07 17:43:49] d2.data.datasets.coco INFO: Loaded 107761 images in COCO format from datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json
[12/07 17:43:53] d2.data.build INFO: Removed 0 images with no usable annotations. 107761 images left.
[12/07 17:43:57] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 257253       |   bicycle    | 7056         |      car      | 43533        |
|  motorcycle   | 8654         |   airplane   | 0            |      bus      | 0            |
|     train     | 4570         |    truck     | 9970         |     boat      | 10576        |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 9820         |     bird      | 10542        |
|      cat      | 0            |     dog      | 0            |     horse     | 6567         |
|     sheep     | 9223         |     cow      | 0            |   elephant    | 0            |
|     bear      | 1294         |    zebra     | 5269         |    giraffe    | 5128         |
|   backpack    | 8714         |   umbrella   | 0            |    handbag    | 12342        |
|      tie      | 0            |   suitcase   | 6112         |    frisbee    | 2681         |
|     skis      | 6623         |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 8802         | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 6095         | tennis racket | 0            |
|    bottle     | 24070        |  wine glass  | 0            |      cup      | 0            |
|     fork      | 5474         |    knife     | 0            |     spoon     | 6159         |
|     bowl      | 14323        |    banana    | 9195         |     apple     | 5776         |
|   sandwich    | 4356         |    orange    | 6302         |   broccoli    | 7261         |
|    carrot     | 7758         |   hot dog    | 0            |     pizza     | 5807         |
|     donut     | 7005         |     cake     | 0            |     chair     | 38073        |
|     couch     | 0            | potted plant | 0            |      bed      | 4192         |
| dining table  | 0            |    toilet    | 4149         |      tv       | 5803         |
|    laptop     | 4960         |    mouse     | 2261         |    remote     | 5700         |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 1672         |
|     oven      | 3334         |   toaster    | 225          |     sink      | 0            |
| refrigerator  | 2634         |     book     | 24077        |     clock     | 6320         |
|     vase      | 6577         |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 1945         |               |              |
|     total     | 656232       |              |              |               |              |[0m
[12/07 17:43:57] d2.data.build INFO: Using training sampler TrainingSampler
[12/07 17:43:57] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 17:43:57] d2.data.common INFO: Serializing 107761 elements to byte tensors and concatenating them all ...
[12/07 17:43:59] d2.data.common INFO: Serialized dataset takes 361.37 MiB
[12/07 17:44:00] detectron2 INFO: Starting training from iteration 0
[12/07 17:47:09] detectron2 INFO: Rank of current process: 0. World size: 1
[12/07 17:47:10] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]
numpy                            1.23.4
detectron2                       0.6 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/detectron2
Compiler                         GCC 7.5
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3,4,5,6,7              NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   515.76
CUDA_HOME                        /home/xchen/cuda-11.4/
Pillow                           9.4.0
torchvision                      0.11.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/07 17:47:10] detectron2 INFO: Command line arguments: Namespace(config_file='configs/OpenDet_tiny_coco.yaml', dist_url='tcp://127.0.0.1:50165', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2', 'OUTPUT_DIR', '.output/test'], resume=False)
[12/07 17:47:10] detectron2 INFO: Contents of args.config_file=configs/OpenDet_tiny_coco.yaml:
[38;5;245m# _BASE_: "Base_OVCOCO_C4_1x.yaml"[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSamOpenDetector[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_sam_vit_det_backbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m#SAM vit_h[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mvit_t[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mViT-B/16[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcontext_former_pe[39m[38;5;186m'[39m[38;5;15m [39m[38;5;245m# unfrozen extra part of model, the name is relative to sam and clip[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmobile_sam.pt[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "/opt/tiger/OpenVo-Seg-master/output/wo_mask_with_prompt_encoder_roi_head_withgrad/model_final.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "sam_vit_h_4b8939.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "output/Detic-COCO/RSPrompter_anchor/model_0000999.pth"[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m4[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m16[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m32[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m64[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mLN[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m123.675[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m116.280[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m103.530[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m58.395[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.375[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDefaultAnchorGenerator[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m32[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m64[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m128[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m512[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1.0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m2.0[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m  [39m[38;5;245m# Three aspect ratios (same for all in feature maps)[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSAMRPN[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStandardRPNHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat0[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;245m# Detectron1 uses 2000 proposals per-batch,[39m
[38;5;15m    [39m[38;5;245m# (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)[39m
[38;5;15m    [39m[38;5;245m# which is approximately 1000 proposals per-image since the default batch size for FPN is 2.[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.3[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m0.7[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m[38;5;15m [39m[38;5;245m# the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbinary_ce[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m# options: centerness, binary_ce[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamAnchorPromptRoiHeads[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m[38;5;15m [39m[38;5;245m#the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m[38;5;15m  [39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mFastRCNNConvFCHead[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;245m# Shared2FCBBoxHead[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(10.0,[39m[38;5;141m [39m[38;5;141m10.0,[39m[38;5;141m [39m[38;5;141m5.0,[39m[38;5;141m [39m[38;5;141m5.0)[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamMaskHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mce_dice[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_zeroshot_train_oriorder",)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_not_zeroshot_val",)[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m [39m[38;5;245m# num_workers == batchsize_per_gpu[39m
[38;5;15m  [39m[38;5;245m# PERSISTENT_WORKERS: True [39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m  [39m[38;5;245m# change  # max 8 imgs per batch[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m[38;5;15m  [39m[38;5;245m# change0.000025[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(60000,[39m[38;5;141m [39m[38;5;141m80000)[39m[38;5;15m  [39m[38;5;245m# change [39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD [39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m[38;5;15m [39m[38;5;245m#1.0001[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mWarmupCosineLR[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;245m# LR_SCHEDULER_NAME: "WarmupMultiStepLR"[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m[38;5;15m  [39m[38;5;245m#  change[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mADAMW[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m[38;5;15m  [39m[38;5;245m# the output freq of logger writer[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(90,[39m[38;5;141m [39m[38;5;141m4)[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# PAD_MASK: True[39m
[38;5;15m  [39m[38;5;245m# MASK_PAD_VAL: 0.0[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbitmask[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m[38;5;15m  [39m[38;5;245m#test_topk_per_image[39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m[38;5;15m [39m[38;5;245m# change[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m[38;5;15m [39m[38;5;245m#every gpu has most 2 images  # change[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcls[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m./output/ovcoco[39m[38;5;186m'[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m

[12/07 17:47:10] detectron2 INFO: Running with full config:
[38;5;204mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;204mPERSISTENT_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_not_zeroshot_val[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_zeroshot_train_oriorder[39m
[38;5;204mFIND_UNUSED_PARAM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m  [39m[38;5;204mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbitmask[39m
[38;5;15m  [39m[38;5;204mMASK_PAD_VAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;204mPAD_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;204mSCALE_RANGE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;204mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcontext_former_pe[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mViT-B/16[39m
[38;5;15m    [39m[38;5;204mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_sam_vit_det_backbone[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvit_t[39m
[38;5;15m  [39m[38;5;204mCONFIGS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mONLY_DECODER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;204mINNER_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mLN[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mSELECTED_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m22[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m26[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m28[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30[39m
[38;5;15m    [39m[38;5;204mUP_SAMPLE_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSamOpenDetector[39m
[38;5;15m  [39m[38;5;204mNUM_SAMPLE_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m  [39m[38;5;204mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSAMRPN[39m
[38;5;15m  [39m[38;5;204mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;204mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;204mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;204mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFastRCNNConvFCHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamAnchorPromptRoiHeads[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m  [39m[38;5;204mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mce_dice[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamMaskHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;204mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat0[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbinary_ce[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAM_FROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSemSegFPNHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m54[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmobile_sam.pt[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m.output/test[39m
[38;5;204mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m
[38;5;15m  [39m[38;5;204mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;204mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvalue[39m
[38;5;15m    [39m[38;5;204mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupCosineLR[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;204mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m80000[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;204mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m  [39m[38;5;204mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcls[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m

[12/07 17:47:10] detectron2 INFO: Full config saved to .output/test/config.yaml
[12/07 17:47:10] d2.utils.env INFO: Using a generated random seed 11488018
[12/07 17:47:21] detectron2 INFO: Model:
SamOpenDetector(
  (backbone): SAMVitDet(
    (fpn1): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (1): Norm2d(
        (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): GELU()
      (3): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn2): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn3): Identity()
    (fpn4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (proposal_generator): SAMRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): samAnchorPromptRoiHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): SamRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): samMaskHead(
      (point_emb): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Flatten(start_dim=1, end_dim=-1)
        (4): Linear(in_features=12544, out_features=256, bias=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=True)
        (7): ReLU(inplace=True)
        (8): Linear(in_features=256, out_features=2048, bias=True)
      )
      (contextformer): build_contextformer(
        (decoder1): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (decoder2): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (q_proj): Linear(in_features=256, out_features=768, bias=True)
        (kv_proj): Linear(in_features=1536, out_features=768, bias=True)
        (proj): Linear(in_features=768, out_features=512, bias=True)
        (ln_mask): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (generator_pe): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
  )
  (sam): Sam(
    (image_encoder): TinyViT(
      (patch_embed): PatchEmbed(
        (seq): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU()
          (2): Conv2d_BN(
            (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layers): ModuleList(
        (0): ConvLayer(
          (blocks): ModuleList(
            (0): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
            (1): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (1): BasicLayer(
          dim=128, input_resolution=(128, 128), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (2): BasicLayer(
          dim=160, input_resolution=(64, 64), depth=6
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (3): BasicLayer(
          dim=320, input_resolution=(64, 64), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (neck): Sequential(
        (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): LayerNorm2d()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (3): LayerNorm2d()
      )
    )
    (prompt_encoder): PromptEncoder(
      (pe_layer): PositionEmbeddingRandom()
      (point_embeddings): ModuleList(
        (0): Embedding(1, 256)
        (1): Embedding(1, 256)
        (2): Embedding(1, 256)
        (3): Embedding(1, 256)
      )
      (not_a_point_embed): Embedding(1, 256)
      (mask_downscaling): Sequential(
        (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
        (4): LayerNorm2d()
        (5): GELU()
        (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (no_mask_embed): Embedding(1, 256)
    )
    (mask_decoder): MaskDecoder(
      (transformer): TwoWayTransformer(
        (layers): ModuleList(
          (0): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
          (1): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
        )
        (final_attn_token_to_image): Attention(
          (q_proj): Linear(in_features=256, out_features=128, bias=True)
          (k_proj): Linear(in_features=256, out_features=128, bias=True)
          (v_proj): Linear(in_features=256, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (iou_token): Embedding(1, 256)
      (mask_tokens): Embedding(4, 256)
      (output_upscaling): Sequential(
        (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
        (4): GELU()
      )
      (output_hypernetworks_mlps): ModuleList(
        (0): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (3): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
      )
      (iou_prediction_head): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
    )
  )
  (clip): CLIP(
    (visual): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
[12/07 17:47:21] detectron2 INFO: Optimized parameters:
{'backbone.fpn1.0.bias',
 'backbone.fpn1.0.weight',
 'backbone.fpn1.1.ln.bias',
 'backbone.fpn1.1.ln.weight',
 'backbone.fpn1.3.bias',
 'backbone.fpn1.3.weight',
 'backbone.fpn2.0.bias',
 'backbone.fpn2.0.weight',
 'context_former_pe',
 'proposal_generator.rpn_head.anchor_deltas.bias',
 'proposal_generator.rpn_head.anchor_deltas.weight',
 'proposal_generator.rpn_head.conv.bias',
 'proposal_generator.rpn_head.conv.weight',
 'proposal_generator.rpn_head.objectness_logits.bias',
 'proposal_generator.rpn_head.objectness_logits.weight',
 'roi_heads.box_head.fc1.bias',
 'roi_heads.box_head.fc1.weight',
 'roi_heads.box_head.fc2.bias',
 'roi_heads.box_head.fc2.weight',
 'roi_heads.box_predictor.bbox_pred.bias',
 'roi_heads.box_predictor.bbox_pred.weight',
 'roi_heads.box_predictor.cls_score.bias',
 'roi_heads.box_predictor.cls_score.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.norm.bias',
 'roi_heads.mask_head.contextformer.decoder1.norm.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.kv_proj.bias',
 'roi_heads.mask_head.contextformer.kv_proj.weight',
 'roi_heads.mask_head.contextformer.ln_mask.bias',
 'roi_heads.mask_head.contextformer.ln_mask.weight',
 'roi_heads.mask_head.contextformer.logit_scale',
 'roi_heads.mask_head.contextformer.proj.bias',
 'roi_heads.mask_head.contextformer.proj.weight',
 'roi_heads.mask_head.contextformer.q_proj.bias',
 'roi_heads.mask_head.contextformer.q_proj.weight',
 'roi_heads.mask_head.point_emb.0.bias',
 'roi_heads.mask_head.point_emb.0.weight',
 'roi_heads.mask_head.point_emb.1.bias',
 'roi_heads.mask_head.point_emb.1.weight',
 'roi_heads.mask_head.point_emb.4.bias',
 'roi_heads.mask_head.point_emb.4.weight',
 'roi_heads.mask_head.point_emb.6.bias',
 'roi_heads.mask_head.point_emb.6.weight',
 'roi_heads.mask_head.point_emb.8.bias',
 'roi_heads.mask_head.point_emb.8.weight'}
[12/07 17:47:21] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from mobile_sam.pt ...
[12/07 17:47:21] fvcore.common.checkpoint INFO: [Checkpointer] Loading from mobile_sam.pt ...
[12/07 17:47:21] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule sam - Total num: 171
[12/07 17:47:21] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn1.0.{bias, weight}[0m
[34mbackbone.fpn1.1.ln.{bias, weight}[0m
[34mbackbone.fpn1.3.{bias, weight}[0m
[34mbackbone.fpn2.0.{bias, weight}[0m
[34mclip.ln_final.{bias, weight}[0m
[34mclip.token_embedding.weight[0m
[34mclip.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.conv1.weight[0m
[34mclip.visual.ln_post.{bias, weight}[0m
[34mclip.visual.ln_pre.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.{class_embedding, positional_embedding, proj}[0m
[34mclip.{logit_scale, positional_embedding, text_projection}[0m
[34mcontext_former_pe[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.kv_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.ln_mask.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.logit_scale[0m
[34mroi_heads.mask_head.contextformer.proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.q_proj.{bias, weight}[0m
[34mroi_heads.mask_head.freq_weight[0m
[34mroi_heads.mask_head.point_emb.0.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.1.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.mask_head.point_emb.4.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.6.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.8.{bias, weight}[0m
[12/07 17:47:21] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mimage_encoder.head.{bias, weight}[0m
  [35mimage_encoder.norm_head.{bias, weight}[0m
[12/07 17:47:21] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeLongestSizeFlip(longest_length=1024), RandomFlip(prob=0.5)]
[12/07 17:47:32] d2.data.datasets.coco INFO: Loading datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json takes 11.13 seconds.
[12/07 17:47:34] d2.data.datasets.coco INFO: Loaded 107761 images in COCO format from datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json
[12/07 17:47:38] d2.data.build INFO: Removed 0 images with no usable annotations. 107761 images left.
[12/07 17:47:42] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 257253       |   bicycle    | 7056         |      car      | 43533        |
|  motorcycle   | 8654         |   airplane   | 0            |      bus      | 0            |
|     train     | 4570         |    truck     | 9970         |     boat      | 10576        |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 9820         |     bird      | 10542        |
|      cat      | 0            |     dog      | 0            |     horse     | 6567         |
|     sheep     | 9223         |     cow      | 0            |   elephant    | 0            |
|     bear      | 1294         |    zebra     | 5269         |    giraffe    | 5128         |
|   backpack    | 8714         |   umbrella   | 0            |    handbag    | 12342        |
|      tie      | 0            |   suitcase   | 6112         |    frisbee    | 2681         |
|     skis      | 6623         |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 8802         | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 6095         | tennis racket | 0            |
|    bottle     | 24070        |  wine glass  | 0            |      cup      | 0            |
|     fork      | 5474         |    knife     | 0            |     spoon     | 6159         |
|     bowl      | 14323        |    banana    | 9195         |     apple     | 5776         |
|   sandwich    | 4356         |    orange    | 6302         |   broccoli    | 7261         |
|    carrot     | 7758         |   hot dog    | 0            |     pizza     | 5807         |
|     donut     | 7005         |     cake     | 0            |     chair     | 38073        |
|     couch     | 0            | potted plant | 0            |      bed      | 4192         |
| dining table  | 0            |    toilet    | 4149         |      tv       | 5803         |
|    laptop     | 4960         |    mouse     | 2261         |    remote     | 5700         |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 1672         |
|     oven      | 3334         |   toaster    | 225          |     sink      | 0            |
| refrigerator  | 2634         |     book     | 24077        |     clock     | 6320         |
|     vase      | 6577         |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 1945         |               |              |
|     total     | 656232       |              |              |               |              |[0m
[12/07 17:47:42] d2.data.build INFO: Using training sampler TrainingSampler
[12/07 17:47:42] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 17:47:42] d2.data.common INFO: Serializing 107761 elements to byte tensors and concatenating them all ...
[12/07 17:47:45] d2.data.common INFO: Serialized dataset takes 361.37 MiB
[12/07 17:47:46] detectron2 INFO: Starting training from iteration 0
[12/07 17:53:18] detectron2 INFO: Rank of current process: 0. World size: 1
[12/07 17:53:18] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]
numpy                            1.23.4
detectron2                       0.6 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/detectron2
Compiler                         GCC 7.5
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3,4,5,6,7              NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   515.76
CUDA_HOME                        /home/xchen/cuda-11.4/
Pillow                           9.4.0
torchvision                      0.11.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/07 17:53:18] detectron2 INFO: Command line arguments: Namespace(config_file='configs/OpenDet_tiny_coco.yaml', dist_url='tcp://127.0.0.1:50165', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2', 'OUTPUT_DIR', '.output/test'], resume=False)
[12/07 17:53:18] detectron2 INFO: Contents of args.config_file=configs/OpenDet_tiny_coco.yaml:
[38;5;245m# _BASE_: "Base_OVCOCO_C4_1x.yaml"[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSamOpenDetector[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_sam_vit_det_backbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m#SAM vit_h[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mvit_t[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mViT-B/16[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcontext_former_pe[39m[38;5;186m'[39m[38;5;15m [39m[38;5;245m# unfrozen extra part of model, the name is relative to sam and clip[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmobile_sam.pt[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "/opt/tiger/OpenVo-Seg-master/output/wo_mask_with_prompt_encoder_roi_head_withgrad/model_final.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "sam_vit_h_4b8939.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "output/Detic-COCO/RSPrompter_anchor/model_0000999.pth"[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m4[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m16[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m32[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m64[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mLN[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m123.675[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m116.280[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m103.530[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m58.395[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.375[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDefaultAnchorGenerator[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m32[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m64[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m128[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m512[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1.0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m2.0[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m  [39m[38;5;245m# Three aspect ratios (same for all in feature maps)[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSAMRPN[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStandardRPNHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat0[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;245m# Detectron1 uses 2000 proposals per-batch,[39m
[38;5;15m    [39m[38;5;245m# (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)[39m
[38;5;15m    [39m[38;5;245m# which is approximately 1000 proposals per-image since the default batch size for FPN is 2.[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.3[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m0.7[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m[38;5;15m [39m[38;5;245m# the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbinary_ce[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m# options: centerness, binary_ce[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamAnchorPromptRoiHeads[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m[38;5;15m [39m[38;5;245m#the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m[38;5;15m  [39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mFastRCNNConvFCHead[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;245m# Shared2FCBBoxHead[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(10.0,[39m[38;5;141m [39m[38;5;141m10.0,[39m[38;5;141m [39m[38;5;141m5.0,[39m[38;5;141m [39m[38;5;141m5.0)[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamMaskHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mce_dice[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_zeroshot_train_oriorder",)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_not_zeroshot_val",)[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m [39m[38;5;245m# num_workers == batchsize_per_gpu[39m
[38;5;15m  [39m[38;5;245m# PERSISTENT_WORKERS: True [39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m  [39m[38;5;245m# change  # max 8 imgs per batch[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m[38;5;15m  [39m[38;5;245m# change0.000025[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(60000,[39m[38;5;141m [39m[38;5;141m80000)[39m[38;5;15m  [39m[38;5;245m# change [39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD [39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m[38;5;15m [39m[38;5;245m#1.0001[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mWarmupCosineLR[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;245m# LR_SCHEDULER_NAME: "WarmupMultiStepLR"[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m[38;5;15m  [39m[38;5;245m#  change[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mADAMW[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m[38;5;15m  [39m[38;5;245m# the output freq of logger writer[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(90,[39m[38;5;141m [39m[38;5;141m4)[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# PAD_MASK: True[39m
[38;5;15m  [39m[38;5;245m# MASK_PAD_VAL: 0.0[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbitmask[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m[38;5;15m  [39m[38;5;245m#test_topk_per_image[39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m[38;5;15m [39m[38;5;245m# change[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m[38;5;15m [39m[38;5;245m#every gpu has most 2 images  # change[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcls[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m./output/ovcoco[39m[38;5;186m'[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m

[12/07 17:53:18] detectron2 INFO: Running with full config:
[38;5;204mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;204mPERSISTENT_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_not_zeroshot_val[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_zeroshot_train_oriorder[39m
[38;5;204mFIND_UNUSED_PARAM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m  [39m[38;5;204mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbitmask[39m
[38;5;15m  [39m[38;5;204mMASK_PAD_VAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;204mPAD_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;204mSCALE_RANGE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;204mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcontext_former_pe[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mViT-B/16[39m
[38;5;15m    [39m[38;5;204mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_sam_vit_det_backbone[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvit_t[39m
[38;5;15m  [39m[38;5;204mCONFIGS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mONLY_DECODER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;204mINNER_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mLN[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mSELECTED_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m22[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m26[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m28[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30[39m
[38;5;15m    [39m[38;5;204mUP_SAMPLE_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSamOpenDetector[39m
[38;5;15m  [39m[38;5;204mNUM_SAMPLE_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m  [39m[38;5;204mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSAMRPN[39m
[38;5;15m  [39m[38;5;204mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;204mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;204mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;204mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFastRCNNConvFCHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamAnchorPromptRoiHeads[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m  [39m[38;5;204mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mce_dice[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamMaskHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;204mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat0[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbinary_ce[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAM_FROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSemSegFPNHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m54[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmobile_sam.pt[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m.output/test[39m
[38;5;204mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m
[38;5;15m  [39m[38;5;204mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;204mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvalue[39m
[38;5;15m    [39m[38;5;204mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupCosineLR[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;204mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m80000[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;204mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m  [39m[38;5;204mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcls[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m

[12/07 17:53:18] detectron2 INFO: Full config saved to .output/test/config.yaml
[12/07 17:53:19] d2.utils.env INFO: Using a generated random seed 20214949
[12/07 17:53:30] detectron2 INFO: Model:
SamOpenDetector(
  (backbone): SAMVitDet(
    (fpn1): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (1): Norm2d(
        (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): GELU()
      (3): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn2): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn3): Identity()
    (fpn4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (proposal_generator): SAMRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): samAnchorPromptRoiHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): SamRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): samMaskHead(
      (point_emb): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Flatten(start_dim=1, end_dim=-1)
        (4): Linear(in_features=12544, out_features=256, bias=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=True)
        (7): ReLU(inplace=True)
        (8): Linear(in_features=256, out_features=2048, bias=True)
      )
      (contextformer): build_contextformer(
        (decoder1): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (decoder2): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (q_proj): Linear(in_features=256, out_features=768, bias=True)
        (kv_proj): Linear(in_features=1536, out_features=768, bias=True)
        (proj): Linear(in_features=768, out_features=512, bias=True)
        (ln_mask): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (generator_pe): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
  )
  (sam): Sam(
    (image_encoder): TinyViT(
      (patch_embed): PatchEmbed(
        (seq): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU()
          (2): Conv2d_BN(
            (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layers): ModuleList(
        (0): ConvLayer(
          (blocks): ModuleList(
            (0): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
            (1): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (1): BasicLayer(
          dim=128, input_resolution=(128, 128), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (2): BasicLayer(
          dim=160, input_resolution=(64, 64), depth=6
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (3): BasicLayer(
          dim=320, input_resolution=(64, 64), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (neck): Sequential(
        (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): LayerNorm2d()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (3): LayerNorm2d()
      )
    )
    (prompt_encoder): PromptEncoder(
      (pe_layer): PositionEmbeddingRandom()
      (point_embeddings): ModuleList(
        (0): Embedding(1, 256)
        (1): Embedding(1, 256)
        (2): Embedding(1, 256)
        (3): Embedding(1, 256)
      )
      (not_a_point_embed): Embedding(1, 256)
      (mask_downscaling): Sequential(
        (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
        (4): LayerNorm2d()
        (5): GELU()
        (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (no_mask_embed): Embedding(1, 256)
    )
    (mask_decoder): MaskDecoder(
      (transformer): TwoWayTransformer(
        (layers): ModuleList(
          (0): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
          (1): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
        )
        (final_attn_token_to_image): Attention(
          (q_proj): Linear(in_features=256, out_features=128, bias=True)
          (k_proj): Linear(in_features=256, out_features=128, bias=True)
          (v_proj): Linear(in_features=256, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (iou_token): Embedding(1, 256)
      (mask_tokens): Embedding(4, 256)
      (output_upscaling): Sequential(
        (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
        (4): GELU()
      )
      (output_hypernetworks_mlps): ModuleList(
        (0): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (3): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
      )
      (iou_prediction_head): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
    )
  )
  (clip): CLIP(
    (visual): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
[12/07 17:53:30] detectron2 INFO: Optimized parameters:
{'backbone.fpn1.0.bias',
 'backbone.fpn1.0.weight',
 'backbone.fpn1.1.ln.bias',
 'backbone.fpn1.1.ln.weight',
 'backbone.fpn1.3.bias',
 'backbone.fpn1.3.weight',
 'backbone.fpn2.0.bias',
 'backbone.fpn2.0.weight',
 'context_former_pe',
 'proposal_generator.rpn_head.anchor_deltas.bias',
 'proposal_generator.rpn_head.anchor_deltas.weight',
 'proposal_generator.rpn_head.conv.bias',
 'proposal_generator.rpn_head.conv.weight',
 'proposal_generator.rpn_head.objectness_logits.bias',
 'proposal_generator.rpn_head.objectness_logits.weight',
 'roi_heads.box_head.fc1.bias',
 'roi_heads.box_head.fc1.weight',
 'roi_heads.box_head.fc2.bias',
 'roi_heads.box_head.fc2.weight',
 'roi_heads.box_predictor.bbox_pred.bias',
 'roi_heads.box_predictor.bbox_pred.weight',
 'roi_heads.box_predictor.cls_score.bias',
 'roi_heads.box_predictor.cls_score.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.norm.bias',
 'roi_heads.mask_head.contextformer.decoder1.norm.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.kv_proj.bias',
 'roi_heads.mask_head.contextformer.kv_proj.weight',
 'roi_heads.mask_head.contextformer.ln_mask.bias',
 'roi_heads.mask_head.contextformer.ln_mask.weight',
 'roi_heads.mask_head.contextformer.logit_scale',
 'roi_heads.mask_head.contextformer.proj.bias',
 'roi_heads.mask_head.contextformer.proj.weight',
 'roi_heads.mask_head.contextformer.q_proj.bias',
 'roi_heads.mask_head.contextformer.q_proj.weight',
 'roi_heads.mask_head.point_emb.0.bias',
 'roi_heads.mask_head.point_emb.0.weight',
 'roi_heads.mask_head.point_emb.1.bias',
 'roi_heads.mask_head.point_emb.1.weight',
 'roi_heads.mask_head.point_emb.4.bias',
 'roi_heads.mask_head.point_emb.4.weight',
 'roi_heads.mask_head.point_emb.6.bias',
 'roi_heads.mask_head.point_emb.6.weight',
 'roi_heads.mask_head.point_emb.8.bias',
 'roi_heads.mask_head.point_emb.8.weight'}
[12/07 17:53:30] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from mobile_sam.pt ...
[12/07 17:53:30] fvcore.common.checkpoint INFO: [Checkpointer] Loading from mobile_sam.pt ...
[12/07 17:53:30] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule sam - Total num: 171
[12/07 17:53:30] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn1.0.{bias, weight}[0m
[34mbackbone.fpn1.1.ln.{bias, weight}[0m
[34mbackbone.fpn1.3.{bias, weight}[0m
[34mbackbone.fpn2.0.{bias, weight}[0m
[34mclip.ln_final.{bias, weight}[0m
[34mclip.token_embedding.weight[0m
[34mclip.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.conv1.weight[0m
[34mclip.visual.ln_post.{bias, weight}[0m
[34mclip.visual.ln_pre.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.{class_embedding, positional_embedding, proj}[0m
[34mclip.{logit_scale, positional_embedding, text_projection}[0m
[34mcontext_former_pe[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.kv_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.ln_mask.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.logit_scale[0m
[34mroi_heads.mask_head.contextformer.proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.q_proj.{bias, weight}[0m
[34mroi_heads.mask_head.freq_weight[0m
[34mroi_heads.mask_head.point_emb.0.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.1.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.mask_head.point_emb.4.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.6.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.8.{bias, weight}[0m
[12/07 17:53:30] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mimage_encoder.head.{bias, weight}[0m
  [35mimage_encoder.norm_head.{bias, weight}[0m
[12/07 17:53:30] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeLongestSizeFlip(longest_length=1024), RandomFlip(prob=0.5)]
[12/07 17:53:41] d2.data.datasets.coco INFO: Loading datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json takes 10.90 seconds.
[12/07 17:53:42] d2.data.datasets.coco INFO: Loaded 107761 images in COCO format from datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json
[12/07 17:53:46] d2.data.build INFO: Removed 0 images with no usable annotations. 107761 images left.
[12/07 17:53:49] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 257253       |   bicycle    | 7056         |      car      | 43533        |
|  motorcycle   | 8654         |   airplane   | 0            |      bus      | 0            |
|     train     | 4570         |    truck     | 9970         |     boat      | 10576        |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 9820         |     bird      | 10542        |
|      cat      | 0            |     dog      | 0            |     horse     | 6567         |
|     sheep     | 9223         |     cow      | 0            |   elephant    | 0            |
|     bear      | 1294         |    zebra     | 5269         |    giraffe    | 5128         |
|   backpack    | 8714         |   umbrella   | 0            |    handbag    | 12342        |
|      tie      | 0            |   suitcase   | 6112         |    frisbee    | 2681         |
|     skis      | 6623         |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 8802         | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 6095         | tennis racket | 0            |
|    bottle     | 24070        |  wine glass  | 0            |      cup      | 0            |
|     fork      | 5474         |    knife     | 0            |     spoon     | 6159         |
|     bowl      | 14323        |    banana    | 9195         |     apple     | 5776         |
|   sandwich    | 4356         |    orange    | 6302         |   broccoli    | 7261         |
|    carrot     | 7758         |   hot dog    | 0            |     pizza     | 5807         |
|     donut     | 7005         |     cake     | 0            |     chair     | 38073        |
|     couch     | 0            | potted plant | 0            |      bed      | 4192         |
| dining table  | 0            |    toilet    | 4149         |      tv       | 5803         |
|    laptop     | 4960         |    mouse     | 2261         |    remote     | 5700         |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 1672         |
|     oven      | 3334         |   toaster    | 225          |     sink      | 0            |
| refrigerator  | 2634         |     book     | 24077        |     clock     | 6320         |
|     vase      | 6577         |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 1945         |               |              |
|     total     | 656232       |              |              |               |              |[0m
[12/07 17:53:49] d2.data.build INFO: Using training sampler TrainingSampler
[12/07 17:53:49] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 17:53:49] d2.data.common INFO: Serializing 107761 elements to byte tensors and concatenating them all ...
[12/07 17:53:52] d2.data.common INFO: Serialized dataset takes 361.37 MiB
[12/07 17:53:53] detectron2 INFO: Starting training from iteration 0
[12/07 19:18:27] detectron2 INFO: Rank of current process: 0. World size: 1
[12/07 19:18:28] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]
numpy                            1.23.4
detectron2                       0.6 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/detectron2
Compiler                         GCC 7.5
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3,4,5,6,7              NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   515.76
CUDA_HOME                        /home/xchen/cuda-11.4/
Pillow                           9.4.0
torchvision                      0.11.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/07 19:18:28] detectron2 INFO: Command line arguments: Namespace(config_file='configs/OpenDet_tiny_coco.yaml', dist_url='tcp://127.0.0.1:50165', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2', 'OUTPUT_DIR', '.output/test'], resume=False)
[12/07 19:18:28] detectron2 INFO: Contents of args.config_file=configs/OpenDet_tiny_coco.yaml:
[38;5;245m# _BASE_: "Base_OVCOCO_C4_1x.yaml"[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSamOpenDetector[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_sam_vit_det_backbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m#SAM vit_h[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mvit_t[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mViT-B/16[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcontext_former_pe[39m[38;5;186m'[39m[38;5;15m [39m[38;5;245m# unfrozen extra part of model, the name is relative to sam and clip[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmobile_sam.pt[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "/opt/tiger/OpenVo-Seg-master/output/wo_mask_with_prompt_encoder_roi_head_withgrad/model_final.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "sam_vit_h_4b8939.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "output/Detic-COCO/RSPrompter_anchor/model_0000999.pth"[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m4[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m16[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m32[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m64[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mLN[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m123.675[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m116.280[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m103.530[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m58.395[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.375[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDefaultAnchorGenerator[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m32[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m64[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m128[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m512[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1.0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m2.0[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m  [39m[38;5;245m# Three aspect ratios (same for all in feature maps)[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSAMRPN[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStandardRPNHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat0[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;245m# Detectron1 uses 2000 proposals per-batch,[39m
[38;5;15m    [39m[38;5;245m# (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)[39m
[38;5;15m    [39m[38;5;245m# which is approximately 1000 proposals per-image since the default batch size for FPN is 2.[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.3[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m0.7[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m[38;5;15m [39m[38;5;245m# the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbinary_ce[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m# options: centerness, binary_ce[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamAnchorPromptRoiHeads[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m[38;5;15m [39m[38;5;245m#the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m[38;5;15m  [39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mFastRCNNConvFCHead[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;245m# Shared2FCBBoxHead[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(10.0,[39m[38;5;141m [39m[38;5;141m10.0,[39m[38;5;141m [39m[38;5;141m5.0,[39m[38;5;141m [39m[38;5;141m5.0)[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamMaskHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mce_dice[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_zeroshot_train_oriorder",)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_not_zeroshot_val",)[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m [39m[38;5;245m# num_workers == batchsize_per_gpu[39m
[38;5;15m  [39m[38;5;245m# PERSISTENT_WORKERS: True [39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m  [39m[38;5;245m# change  # max 8 imgs per batch[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m[38;5;15m  [39m[38;5;245m# change0.000025[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(60000,[39m[38;5;141m [39m[38;5;141m80000)[39m[38;5;15m  [39m[38;5;245m# change [39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD [39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m[38;5;15m [39m[38;5;245m#1.0001[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mWarmupCosineLR[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;245m# LR_SCHEDULER_NAME: "WarmupMultiStepLR"[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m[38;5;15m  [39m[38;5;245m#  change[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mADAMW[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m[38;5;15m  [39m[38;5;245m# the output freq of logger writer[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(90,[39m[38;5;141m [39m[38;5;141m4)[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# PAD_MASK: True[39m
[38;5;15m  [39m[38;5;245m# MASK_PAD_VAL: 0.0[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbitmask[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m[38;5;15m  [39m[38;5;245m#test_topk_per_image[39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m[38;5;15m [39m[38;5;245m# change[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m[38;5;15m [39m[38;5;245m#every gpu has most 2 images  # change[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcls[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m./output/ovcoco[39m[38;5;186m'[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m

[12/07 19:18:28] detectron2 INFO: Running with full config:
[38;5;204mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;204mPERSISTENT_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_not_zeroshot_val[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_zeroshot_train_oriorder[39m
[38;5;204mFIND_UNUSED_PARAM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m  [39m[38;5;204mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbitmask[39m
[38;5;15m  [39m[38;5;204mMASK_PAD_VAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;204mPAD_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;204mSCALE_RANGE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;204mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcontext_former_pe[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mViT-B/16[39m
[38;5;15m    [39m[38;5;204mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_sam_vit_det_backbone[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvit_t[39m
[38;5;15m  [39m[38;5;204mCONFIGS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mONLY_DECODER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;204mINNER_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mLN[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mSELECTED_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m22[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m26[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m28[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30[39m
[38;5;15m    [39m[38;5;204mUP_SAMPLE_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSamOpenDetector[39m
[38;5;15m  [39m[38;5;204mNUM_SAMPLE_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m  [39m[38;5;204mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSAMRPN[39m
[38;5;15m  [39m[38;5;204mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;204mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;204mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;204mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFastRCNNConvFCHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamAnchorPromptRoiHeads[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m  [39m[38;5;204mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mce_dice[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamMaskHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;204mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat0[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbinary_ce[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAM_FROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSemSegFPNHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m54[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmobile_sam.pt[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m.output/test[39m
[38;5;204mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m
[38;5;15m  [39m[38;5;204mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;204mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvalue[39m
[38;5;15m    [39m[38;5;204mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupCosineLR[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;204mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m80000[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;204mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m  [39m[38;5;204mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcls[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m

[12/07 19:18:28] detectron2 INFO: Full config saved to .output/test/config.yaml
[12/07 19:18:28] d2.utils.env INFO: Using a generated random seed 29764774
[12/07 19:18:39] detectron2 INFO: Model:
SamOpenDetector(
  (backbone): SAMVitDet(
    (fpn1): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (1): Norm2d(
        (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): GELU()
      (3): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn2): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn3): Identity()
    (fpn4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (proposal_generator): SAMRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): samAnchorPromptRoiHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): SamRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): samMaskHead(
      (point_emb): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Flatten(start_dim=1, end_dim=-1)
        (4): Linear(in_features=12544, out_features=256, bias=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=True)
        (7): ReLU(inplace=True)
        (8): Linear(in_features=256, out_features=2048, bias=True)
      )
      (contextformer): build_contextformer(
        (decoder1): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (decoder2): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (q_proj): Linear(in_features=256, out_features=768, bias=True)
        (kv_proj): Linear(in_features=1536, out_features=768, bias=True)
        (proj): Linear(in_features=768, out_features=512, bias=True)
        (ln_mask): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (generator_pe): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
  )
  (sam): Sam(
    (image_encoder): TinyViT(
      (patch_embed): PatchEmbed(
        (seq): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU()
          (2): Conv2d_BN(
            (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layers): ModuleList(
        (0): ConvLayer(
          (blocks): ModuleList(
            (0): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
            (1): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (1): BasicLayer(
          dim=128, input_resolution=(128, 128), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (2): BasicLayer(
          dim=160, input_resolution=(64, 64), depth=6
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (3): BasicLayer(
          dim=320, input_resolution=(64, 64), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (neck): Sequential(
        (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): LayerNorm2d()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (3): LayerNorm2d()
      )
    )
    (prompt_encoder): PromptEncoder(
      (pe_layer): PositionEmbeddingRandom()
      (point_embeddings): ModuleList(
        (0): Embedding(1, 256)
        (1): Embedding(1, 256)
        (2): Embedding(1, 256)
        (3): Embedding(1, 256)
      )
      (not_a_point_embed): Embedding(1, 256)
      (mask_downscaling): Sequential(
        (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
        (4): LayerNorm2d()
        (5): GELU()
        (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (no_mask_embed): Embedding(1, 256)
    )
    (mask_decoder): MaskDecoder(
      (transformer): TwoWayTransformer(
        (layers): ModuleList(
          (0): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
          (1): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
        )
        (final_attn_token_to_image): Attention(
          (q_proj): Linear(in_features=256, out_features=128, bias=True)
          (k_proj): Linear(in_features=256, out_features=128, bias=True)
          (v_proj): Linear(in_features=256, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (iou_token): Embedding(1, 256)
      (mask_tokens): Embedding(4, 256)
      (output_upscaling): Sequential(
        (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
        (4): GELU()
      )
      (output_hypernetworks_mlps): ModuleList(
        (0): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (3): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
      )
      (iou_prediction_head): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
    )
  )
  (clip): CLIP(
    (visual): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
[12/07 19:18:39] detectron2 INFO: Optimized parameters:
{'backbone.fpn1.0.bias',
 'backbone.fpn1.0.weight',
 'backbone.fpn1.1.ln.bias',
 'backbone.fpn1.1.ln.weight',
 'backbone.fpn1.3.bias',
 'backbone.fpn1.3.weight',
 'backbone.fpn2.0.bias',
 'backbone.fpn2.0.weight',
 'context_former_pe',
 'proposal_generator.rpn_head.anchor_deltas.bias',
 'proposal_generator.rpn_head.anchor_deltas.weight',
 'proposal_generator.rpn_head.conv.bias',
 'proposal_generator.rpn_head.conv.weight',
 'proposal_generator.rpn_head.objectness_logits.bias',
 'proposal_generator.rpn_head.objectness_logits.weight',
 'roi_heads.box_head.fc1.bias',
 'roi_heads.box_head.fc1.weight',
 'roi_heads.box_head.fc2.bias',
 'roi_heads.box_head.fc2.weight',
 'roi_heads.box_predictor.bbox_pred.bias',
 'roi_heads.box_predictor.bbox_pred.weight',
 'roi_heads.box_predictor.cls_score.bias',
 'roi_heads.box_predictor.cls_score.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.norm.bias',
 'roi_heads.mask_head.contextformer.decoder1.norm.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.kv_proj.bias',
 'roi_heads.mask_head.contextformer.kv_proj.weight',
 'roi_heads.mask_head.contextformer.ln_mask.bias',
 'roi_heads.mask_head.contextformer.ln_mask.weight',
 'roi_heads.mask_head.contextformer.logit_scale',
 'roi_heads.mask_head.contextformer.proj.bias',
 'roi_heads.mask_head.contextformer.proj.weight',
 'roi_heads.mask_head.contextformer.q_proj.bias',
 'roi_heads.mask_head.contextformer.q_proj.weight',
 'roi_heads.mask_head.point_emb.0.bias',
 'roi_heads.mask_head.point_emb.0.weight',
 'roi_heads.mask_head.point_emb.1.bias',
 'roi_heads.mask_head.point_emb.1.weight',
 'roi_heads.mask_head.point_emb.4.bias',
 'roi_heads.mask_head.point_emb.4.weight',
 'roi_heads.mask_head.point_emb.6.bias',
 'roi_heads.mask_head.point_emb.6.weight',
 'roi_heads.mask_head.point_emb.8.bias',
 'roi_heads.mask_head.point_emb.8.weight'}
[12/07 19:18:39] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from mobile_sam.pt ...
[12/07 19:18:39] fvcore.common.checkpoint INFO: [Checkpointer] Loading from mobile_sam.pt ...
[12/07 19:18:39] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule sam - Total num: 171
[12/07 19:18:39] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn1.0.{bias, weight}[0m
[34mbackbone.fpn1.1.ln.{bias, weight}[0m
[34mbackbone.fpn1.3.{bias, weight}[0m
[34mbackbone.fpn2.0.{bias, weight}[0m
[34mclip.ln_final.{bias, weight}[0m
[34mclip.token_embedding.weight[0m
[34mclip.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.conv1.weight[0m
[34mclip.visual.ln_post.{bias, weight}[0m
[34mclip.visual.ln_pre.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.{class_embedding, positional_embedding, proj}[0m
[34mclip.{logit_scale, positional_embedding, text_projection}[0m
[34mcontext_former_pe[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.kv_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.ln_mask.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.logit_scale[0m
[34mroi_heads.mask_head.contextformer.proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.q_proj.{bias, weight}[0m
[34mroi_heads.mask_head.freq_weight[0m
[34mroi_heads.mask_head.point_emb.0.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.1.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.mask_head.point_emb.4.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.6.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.8.{bias, weight}[0m
[12/07 19:18:39] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mimage_encoder.head.{bias, weight}[0m
  [35mimage_encoder.norm_head.{bias, weight}[0m
[12/07 19:18:39] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeLongestSizeFlip(longest_length=1024), RandomFlip(prob=0.5)]
[12/07 19:18:50] d2.data.datasets.coco INFO: Loading datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json takes 11.16 seconds.
[12/07 19:18:52] d2.data.datasets.coco INFO: Loaded 107761 images in COCO format from datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json
[12/07 19:18:56] d2.data.build INFO: Removed 0 images with no usable annotations. 107761 images left.
[12/07 19:18:59] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 257253       |   bicycle    | 7056         |      car      | 43533        |
|  motorcycle   | 8654         |   airplane   | 0            |      bus      | 0            |
|     train     | 4570         |    truck     | 9970         |     boat      | 10576        |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 9820         |     bird      | 10542        |
|      cat      | 0            |     dog      | 0            |     horse     | 6567         |
|     sheep     | 9223         |     cow      | 0            |   elephant    | 0            |
|     bear      | 1294         |    zebra     | 5269         |    giraffe    | 5128         |
|   backpack    | 8714         |   umbrella   | 0            |    handbag    | 12342        |
|      tie      | 0            |   suitcase   | 6112         |    frisbee    | 2681         |
|     skis      | 6623         |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 8802         | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 6095         | tennis racket | 0            |
|    bottle     | 24070        |  wine glass  | 0            |      cup      | 0            |
|     fork      | 5474         |    knife     | 0            |     spoon     | 6159         |
|     bowl      | 14323        |    banana    | 9195         |     apple     | 5776         |
|   sandwich    | 4356         |    orange    | 6302         |   broccoli    | 7261         |
|    carrot     | 7758         |   hot dog    | 0            |     pizza     | 5807         |
|     donut     | 7005         |     cake     | 0            |     chair     | 38073        |
|     couch     | 0            | potted plant | 0            |      bed      | 4192         |
| dining table  | 0            |    toilet    | 4149         |      tv       | 5803         |
|    laptop     | 4960         |    mouse     | 2261         |    remote     | 5700         |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 1672         |
|     oven      | 3334         |   toaster    | 225          |     sink      | 0            |
| refrigerator  | 2634         |     book     | 24077        |     clock     | 6320         |
|     vase      | 6577         |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 1945         |               |              |
|     total     | 656232       |              |              |               |              |[0m
[12/07 19:18:59] d2.data.build INFO: Using training sampler TrainingSampler
[12/07 19:18:59] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 19:18:59] d2.data.common INFO: Serializing 107761 elements to byte tensors and concatenating them all ...
[12/07 19:19:01] d2.data.common INFO: Serialized dataset takes 361.37 MiB
[12/07 19:19:03] detectron2 INFO: Starting training from iteration 0
[12/07 19:19:55] detectron2 INFO: Rank of current process: 0. World size: 1
[12/07 19:19:55] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]
numpy                            1.23.4
detectron2                       0.6 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/detectron2
Compiler                         GCC 7.5
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3,4,5,6,7              NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   515.76
CUDA_HOME                        /home/xchen/cuda-11.4/
Pillow                           9.4.0
torchvision                      0.11.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/07 19:19:55] detectron2 INFO: Command line arguments: Namespace(config_file='configs/OpenDet_tiny_coco.yaml', dist_url='tcp://127.0.0.1:50165', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2', 'OUTPUT_DIR', '.output/test'], resume=False)
[12/07 19:19:55] detectron2 INFO: Contents of args.config_file=configs/OpenDet_tiny_coco.yaml:
[38;5;245m# _BASE_: "Base_OVCOCO_C4_1x.yaml"[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSamOpenDetector[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_sam_vit_det_backbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m#SAM vit_h[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mvit_t[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mViT-B/16[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcontext_former_pe[39m[38;5;186m'[39m[38;5;15m [39m[38;5;245m# unfrozen extra part of model, the name is relative to sam and clip[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmobile_sam.pt[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "/opt/tiger/OpenVo-Seg-master/output/wo_mask_with_prompt_encoder_roi_head_withgrad/model_final.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "sam_vit_h_4b8939.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "output/Detic-COCO/RSPrompter_anchor/model_0000999.pth"[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m4[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m16[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m32[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m64[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mLN[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m123.675[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m116.280[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m103.530[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m58.395[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.375[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDefaultAnchorGenerator[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m32[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m64[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m128[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m512[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1.0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m2.0[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m  [39m[38;5;245m# Three aspect ratios (same for all in feature maps)[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSAMRPN[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStandardRPNHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat0[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;245m# Detectron1 uses 2000 proposals per-batch,[39m
[38;5;15m    [39m[38;5;245m# (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)[39m
[38;5;15m    [39m[38;5;245m# which is approximately 1000 proposals per-image since the default batch size for FPN is 2.[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.3[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m0.7[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m[38;5;15m [39m[38;5;245m# the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbinary_ce[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m# options: centerness, binary_ce[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamAnchorPromptRoiHeads[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m[38;5;15m [39m[38;5;245m#the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m[38;5;15m  [39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mFastRCNNConvFCHead[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;245m# Shared2FCBBoxHead[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(10.0,[39m[38;5;141m [39m[38;5;141m10.0,[39m[38;5;141m [39m[38;5;141m5.0,[39m[38;5;141m [39m[38;5;141m5.0)[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamMaskHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mce_dice[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_zeroshot_train_oriorder",)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_not_zeroshot_val",)[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m [39m[38;5;245m# num_workers == batchsize_per_gpu[39m
[38;5;15m  [39m[38;5;245m# PERSISTENT_WORKERS: True [39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m  [39m[38;5;245m# change  # max 8 imgs per batch[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m[38;5;15m  [39m[38;5;245m# change0.000025[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(60000,[39m[38;5;141m [39m[38;5;141m80000)[39m[38;5;15m  [39m[38;5;245m# change [39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD [39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m[38;5;15m [39m[38;5;245m#1.0001[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mWarmupCosineLR[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;245m# LR_SCHEDULER_NAME: "WarmupMultiStepLR"[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m[38;5;15m  [39m[38;5;245m#  change[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mADAMW[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m[38;5;15m  [39m[38;5;245m# the output freq of logger writer[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(90,[39m[38;5;141m [39m[38;5;141m4)[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# PAD_MASK: True[39m
[38;5;15m  [39m[38;5;245m# MASK_PAD_VAL: 0.0[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbitmask[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m[38;5;15m  [39m[38;5;245m#test_topk_per_image[39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m[38;5;15m [39m[38;5;245m# change[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m[38;5;15m [39m[38;5;245m#every gpu has most 2 images  # change[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcls[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m./output/ovcoco[39m[38;5;186m'[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m

[12/07 19:19:55] detectron2 INFO: Running with full config:
[38;5;204mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;204mPERSISTENT_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_not_zeroshot_val[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_zeroshot_train_oriorder[39m
[38;5;204mFIND_UNUSED_PARAM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m  [39m[38;5;204mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbitmask[39m
[38;5;15m  [39m[38;5;204mMASK_PAD_VAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;204mPAD_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;204mSCALE_RANGE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;204mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcontext_former_pe[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mViT-B/16[39m
[38;5;15m    [39m[38;5;204mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_sam_vit_det_backbone[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvit_t[39m
[38;5;15m  [39m[38;5;204mCONFIGS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mONLY_DECODER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;204mINNER_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mLN[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mSELECTED_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m22[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m26[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m28[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30[39m
[38;5;15m    [39m[38;5;204mUP_SAMPLE_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSamOpenDetector[39m
[38;5;15m  [39m[38;5;204mNUM_SAMPLE_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m  [39m[38;5;204mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSAMRPN[39m
[38;5;15m  [39m[38;5;204mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;204mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;204mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;204mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFastRCNNConvFCHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamAnchorPromptRoiHeads[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m  [39m[38;5;204mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mce_dice[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamMaskHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;204mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat0[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbinary_ce[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAM_FROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSemSegFPNHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m54[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmobile_sam.pt[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m.output/test[39m
[38;5;204mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m
[38;5;15m  [39m[38;5;204mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;204mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvalue[39m
[38;5;15m    [39m[38;5;204mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupCosineLR[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;204mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m80000[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;204mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m  [39m[38;5;204mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcls[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m

[12/07 19:19:55] detectron2 INFO: Full config saved to .output/test/config.yaml
[12/07 19:19:55] d2.utils.env INFO: Using a generated random seed 56956244
[12/07 19:20:06] detectron2 INFO: Model:
SamOpenDetector(
  (backbone): SAMVitDet(
    (fpn1): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (1): Norm2d(
        (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): GELU()
      (3): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn2): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn3): Identity()
    (fpn4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (proposal_generator): SAMRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): samAnchorPromptRoiHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): SamRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): samMaskHead(
      (point_emb): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Flatten(start_dim=1, end_dim=-1)
        (4): Linear(in_features=12544, out_features=256, bias=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=True)
        (7): ReLU(inplace=True)
        (8): Linear(in_features=256, out_features=2048, bias=True)
      )
      (contextformer): build_contextformer(
        (decoder1): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (decoder2): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (q_proj): Linear(in_features=256, out_features=768, bias=True)
        (kv_proj): Linear(in_features=1536, out_features=768, bias=True)
        (proj): Linear(in_features=768, out_features=512, bias=True)
        (ln_mask): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (generator_pe): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
  )
  (sam): Sam(
    (image_encoder): TinyViT(
      (patch_embed): PatchEmbed(
        (seq): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU()
          (2): Conv2d_BN(
            (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layers): ModuleList(
        (0): ConvLayer(
          (blocks): ModuleList(
            (0): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
            (1): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (1): BasicLayer(
          dim=128, input_resolution=(128, 128), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (2): BasicLayer(
          dim=160, input_resolution=(64, 64), depth=6
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (3): BasicLayer(
          dim=320, input_resolution=(64, 64), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (neck): Sequential(
        (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): LayerNorm2d()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (3): LayerNorm2d()
      )
    )
    (prompt_encoder): PromptEncoder(
      (pe_layer): PositionEmbeddingRandom()
      (point_embeddings): ModuleList(
        (0): Embedding(1, 256)
        (1): Embedding(1, 256)
        (2): Embedding(1, 256)
        (3): Embedding(1, 256)
      )
      (not_a_point_embed): Embedding(1, 256)
      (mask_downscaling): Sequential(
        (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
        (4): LayerNorm2d()
        (5): GELU()
        (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (no_mask_embed): Embedding(1, 256)
    )
    (mask_decoder): MaskDecoder(
      (transformer): TwoWayTransformer(
        (layers): ModuleList(
          (0): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
          (1): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
        )
        (final_attn_token_to_image): Attention(
          (q_proj): Linear(in_features=256, out_features=128, bias=True)
          (k_proj): Linear(in_features=256, out_features=128, bias=True)
          (v_proj): Linear(in_features=256, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (iou_token): Embedding(1, 256)
      (mask_tokens): Embedding(4, 256)
      (output_upscaling): Sequential(
        (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
        (4): GELU()
      )
      (output_hypernetworks_mlps): ModuleList(
        (0): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (3): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
      )
      (iou_prediction_head): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
    )
  )
  (clip): CLIP(
    (visual): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
[12/07 19:20:06] detectron2 INFO: Optimized parameters:
{'backbone.fpn1.0.bias',
 'backbone.fpn1.0.weight',
 'backbone.fpn1.1.ln.bias',
 'backbone.fpn1.1.ln.weight',
 'backbone.fpn1.3.bias',
 'backbone.fpn1.3.weight',
 'backbone.fpn2.0.bias',
 'backbone.fpn2.0.weight',
 'context_former_pe',
 'proposal_generator.rpn_head.anchor_deltas.bias',
 'proposal_generator.rpn_head.anchor_deltas.weight',
 'proposal_generator.rpn_head.conv.bias',
 'proposal_generator.rpn_head.conv.weight',
 'proposal_generator.rpn_head.objectness_logits.bias',
 'proposal_generator.rpn_head.objectness_logits.weight',
 'roi_heads.box_head.fc1.bias',
 'roi_heads.box_head.fc1.weight',
 'roi_heads.box_head.fc2.bias',
 'roi_heads.box_head.fc2.weight',
 'roi_heads.box_predictor.bbox_pred.bias',
 'roi_heads.box_predictor.bbox_pred.weight',
 'roi_heads.box_predictor.cls_score.bias',
 'roi_heads.box_predictor.cls_score.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.norm.bias',
 'roi_heads.mask_head.contextformer.decoder1.norm.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.kv_proj.bias',
 'roi_heads.mask_head.contextformer.kv_proj.weight',
 'roi_heads.mask_head.contextformer.ln_mask.bias',
 'roi_heads.mask_head.contextformer.ln_mask.weight',
 'roi_heads.mask_head.contextformer.logit_scale',
 'roi_heads.mask_head.contextformer.proj.bias',
 'roi_heads.mask_head.contextformer.proj.weight',
 'roi_heads.mask_head.contextformer.q_proj.bias',
 'roi_heads.mask_head.contextformer.q_proj.weight',
 'roi_heads.mask_head.point_emb.0.bias',
 'roi_heads.mask_head.point_emb.0.weight',
 'roi_heads.mask_head.point_emb.1.bias',
 'roi_heads.mask_head.point_emb.1.weight',
 'roi_heads.mask_head.point_emb.4.bias',
 'roi_heads.mask_head.point_emb.4.weight',
 'roi_heads.mask_head.point_emb.6.bias',
 'roi_heads.mask_head.point_emb.6.weight',
 'roi_heads.mask_head.point_emb.8.bias',
 'roi_heads.mask_head.point_emb.8.weight'}
[12/07 19:20:06] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from mobile_sam.pt ...
[12/07 19:20:06] fvcore.common.checkpoint INFO: [Checkpointer] Loading from mobile_sam.pt ...
[12/07 19:20:06] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule sam - Total num: 171
[12/07 19:20:06] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn1.0.{bias, weight}[0m
[34mbackbone.fpn1.1.ln.{bias, weight}[0m
[34mbackbone.fpn1.3.{bias, weight}[0m
[34mbackbone.fpn2.0.{bias, weight}[0m
[34mclip.ln_final.{bias, weight}[0m
[34mclip.token_embedding.weight[0m
[34mclip.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.conv1.weight[0m
[34mclip.visual.ln_post.{bias, weight}[0m
[34mclip.visual.ln_pre.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.{class_embedding, positional_embedding, proj}[0m
[34mclip.{logit_scale, positional_embedding, text_projection}[0m
[34mcontext_former_pe[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.kv_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.ln_mask.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.logit_scale[0m
[34mroi_heads.mask_head.contextformer.proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.q_proj.{bias, weight}[0m
[34mroi_heads.mask_head.freq_weight[0m
[34mroi_heads.mask_head.point_emb.0.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.1.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.mask_head.point_emb.4.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.6.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.8.{bias, weight}[0m
[12/07 19:20:06] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mimage_encoder.head.{bias, weight}[0m
  [35mimage_encoder.norm_head.{bias, weight}[0m
[12/07 19:20:06] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeLongestSizeFlip(longest_length=1024), RandomFlip(prob=0.5)]
[12/07 19:20:17] d2.data.datasets.coco INFO: Loading datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json takes 10.99 seconds.
[12/07 19:20:19] d2.data.datasets.coco INFO: Loaded 107761 images in COCO format from datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json
[12/07 19:20:23] d2.data.build INFO: Removed 0 images with no usable annotations. 107761 images left.
[12/07 19:20:26] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 257253       |   bicycle    | 7056         |      car      | 43533        |
|  motorcycle   | 8654         |   airplane   | 0            |      bus      | 0            |
|     train     | 4570         |    truck     | 9970         |     boat      | 10576        |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 9820         |     bird      | 10542        |
|      cat      | 0            |     dog      | 0            |     horse     | 6567         |
|     sheep     | 9223         |     cow      | 0            |   elephant    | 0            |
|     bear      | 1294         |    zebra     | 5269         |    giraffe    | 5128         |
|   backpack    | 8714         |   umbrella   | 0            |    handbag    | 12342        |
|      tie      | 0            |   suitcase   | 6112         |    frisbee    | 2681         |
|     skis      | 6623         |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 8802         | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 6095         | tennis racket | 0            |
|    bottle     | 24070        |  wine glass  | 0            |      cup      | 0            |
|     fork      | 5474         |    knife     | 0            |     spoon     | 6159         |
|     bowl      | 14323        |    banana    | 9195         |     apple     | 5776         |
|   sandwich    | 4356         |    orange    | 6302         |   broccoli    | 7261         |
|    carrot     | 7758         |   hot dog    | 0            |     pizza     | 5807         |
|     donut     | 7005         |     cake     | 0            |     chair     | 38073        |
|     couch     | 0            | potted plant | 0            |      bed      | 4192         |
| dining table  | 0            |    toilet    | 4149         |      tv       | 5803         |
|    laptop     | 4960         |    mouse     | 2261         |    remote     | 5700         |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 1672         |
|     oven      | 3334         |   toaster    | 225          |     sink      | 0            |
| refrigerator  | 2634         |     book     | 24077        |     clock     | 6320         |
|     vase      | 6577         |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 1945         |               |              |
|     total     | 656232       |              |              |               |              |[0m
[12/07 19:20:26] d2.data.build INFO: Using training sampler TrainingSampler
[12/07 19:20:26] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 19:20:26] d2.data.common INFO: Serializing 107761 elements to byte tensors and concatenating them all ...
[12/07 19:20:28] d2.data.common INFO: Serialized dataset takes 361.37 MiB
[12/07 19:20:30] detectron2 INFO: Starting training from iteration 0
[12/07 19:21:12] detectron2 INFO: Rank of current process: 0. World size: 1
[12/07 19:21:12] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]
numpy                            1.23.4
detectron2                       0.6 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/detectron2
Compiler                         GCC 7.5
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3,4,5,6,7              NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   515.76
CUDA_HOME                        /home/xchen/cuda-11.4/
Pillow                           9.4.0
torchvision                      0.11.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/07 19:21:12] detectron2 INFO: Command line arguments: Namespace(config_file='configs/OpenDet_tiny_coco.yaml', dist_url='tcp://127.0.0.1:50165', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2', 'OUTPUT_DIR', '.output/test'], resume=False)
[12/07 19:21:12] detectron2 INFO: Contents of args.config_file=configs/OpenDet_tiny_coco.yaml:
[38;5;245m# _BASE_: "Base_OVCOCO_C4_1x.yaml"[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSamOpenDetector[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_sam_vit_det_backbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m#SAM vit_h[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mvit_t[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mViT-B/16[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcontext_former_pe[39m[38;5;186m'[39m[38;5;15m [39m[38;5;245m# unfrozen extra part of model, the name is relative to sam and clip[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmobile_sam.pt[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "/opt/tiger/OpenVo-Seg-master/output/wo_mask_with_prompt_encoder_roi_head_withgrad/model_final.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "sam_vit_h_4b8939.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "output/Detic-COCO/RSPrompter_anchor/model_0000999.pth"[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m4[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m16[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m32[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m64[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mLN[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m123.675[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m116.280[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m103.530[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m58.395[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.375[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDefaultAnchorGenerator[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m32[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m64[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m128[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m512[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1.0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m2.0[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m  [39m[38;5;245m# Three aspect ratios (same for all in feature maps)[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSAMRPN[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStandardRPNHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat0[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;245m# Detectron1 uses 2000 proposals per-batch,[39m
[38;5;15m    [39m[38;5;245m# (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)[39m
[38;5;15m    [39m[38;5;245m# which is approximately 1000 proposals per-image since the default batch size for FPN is 2.[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.3[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m0.7[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m[38;5;15m [39m[38;5;245m# the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbinary_ce[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m# options: centerness, binary_ce[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamAnchorPromptRoiHeads[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m[38;5;15m [39m[38;5;245m#the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m[38;5;15m  [39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mFastRCNNConvFCHead[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;245m# Shared2FCBBoxHead[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(10.0,[39m[38;5;141m [39m[38;5;141m10.0,[39m[38;5;141m [39m[38;5;141m5.0,[39m[38;5;141m [39m[38;5;141m5.0)[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamMaskHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mce_dice[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_zeroshot_train_oriorder",)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_not_zeroshot_val",)[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m [39m[38;5;245m# num_workers == batchsize_per_gpu[39m
[38;5;15m  [39m[38;5;245m# PERSISTENT_WORKERS: True [39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m  [39m[38;5;245m# change  # max 8 imgs per batch[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m[38;5;15m  [39m[38;5;245m# change0.000025[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(60000,[39m[38;5;141m [39m[38;5;141m80000)[39m[38;5;15m  [39m[38;5;245m# change [39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD [39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m[38;5;15m [39m[38;5;245m#1.0001[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mWarmupCosineLR[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;245m# LR_SCHEDULER_NAME: "WarmupMultiStepLR"[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m[38;5;15m  [39m[38;5;245m#  change[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mADAMW[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m[38;5;15m  [39m[38;5;245m# the output freq of logger writer[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(90,[39m[38;5;141m [39m[38;5;141m4)[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# PAD_MASK: True[39m
[38;5;15m  [39m[38;5;245m# MASK_PAD_VAL: 0.0[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbitmask[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m[38;5;15m  [39m[38;5;245m#test_topk_per_image[39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m[38;5;15m [39m[38;5;245m# change[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m[38;5;15m [39m[38;5;245m#every gpu has most 2 images  # change[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcls[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m./output/ovcoco[39m[38;5;186m'[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m

[12/07 19:21:12] detectron2 INFO: Running with full config:
[38;5;204mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;204mPERSISTENT_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_not_zeroshot_val[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_zeroshot_train_oriorder[39m
[38;5;204mFIND_UNUSED_PARAM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m  [39m[38;5;204mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbitmask[39m
[38;5;15m  [39m[38;5;204mMASK_PAD_VAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;204mPAD_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;204mSCALE_RANGE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;204mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcontext_former_pe[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mViT-B/16[39m
[38;5;15m    [39m[38;5;204mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_sam_vit_det_backbone[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvit_t[39m
[38;5;15m  [39m[38;5;204mCONFIGS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mONLY_DECODER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;204mINNER_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mLN[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mSELECTED_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m22[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m26[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m28[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30[39m
[38;5;15m    [39m[38;5;204mUP_SAMPLE_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSamOpenDetector[39m
[38;5;15m  [39m[38;5;204mNUM_SAMPLE_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m  [39m[38;5;204mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSAMRPN[39m
[38;5;15m  [39m[38;5;204mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;204mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;204mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;204mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFastRCNNConvFCHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamAnchorPromptRoiHeads[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m  [39m[38;5;204mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mce_dice[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamMaskHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;204mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat0[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbinary_ce[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAM_FROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSemSegFPNHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m54[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmobile_sam.pt[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m.output/test[39m
[38;5;204mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m
[38;5;15m  [39m[38;5;204mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;204mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvalue[39m
[38;5;15m    [39m[38;5;204mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupCosineLR[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;204mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m80000[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;204mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m  [39m[38;5;204mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcls[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m

[12/07 19:21:12] detectron2 INFO: Full config saved to .output/test/config.yaml
[12/07 19:21:12] d2.utils.env INFO: Using a generated random seed 13994758
[12/07 19:21:23] detectron2 INFO: Model:
SamOpenDetector(
  (backbone): SAMVitDet(
    (fpn1): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (1): Norm2d(
        (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): GELU()
      (3): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn2): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn3): Identity()
    (fpn4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (proposal_generator): SAMRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): samAnchorPromptRoiHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): SamRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): samMaskHead(
      (point_emb): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Flatten(start_dim=1, end_dim=-1)
        (4): Linear(in_features=12544, out_features=256, bias=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=True)
        (7): ReLU(inplace=True)
        (8): Linear(in_features=256, out_features=2048, bias=True)
      )
      (contextformer): build_contextformer(
        (decoder1): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (decoder2): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (q_proj): Linear(in_features=256, out_features=768, bias=True)
        (kv_proj): Linear(in_features=1536, out_features=768, bias=True)
        (proj): Linear(in_features=768, out_features=512, bias=True)
        (ln_mask): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (generator_pe): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
  )
  (sam): Sam(
    (image_encoder): TinyViT(
      (patch_embed): PatchEmbed(
        (seq): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU()
          (2): Conv2d_BN(
            (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layers): ModuleList(
        (0): ConvLayer(
          (blocks): ModuleList(
            (0): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
            (1): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (1): BasicLayer(
          dim=128, input_resolution=(128, 128), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (2): BasicLayer(
          dim=160, input_resolution=(64, 64), depth=6
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (3): BasicLayer(
          dim=320, input_resolution=(64, 64), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (neck): Sequential(
        (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): LayerNorm2d()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (3): LayerNorm2d()
      )
    )
    (prompt_encoder): PromptEncoder(
      (pe_layer): PositionEmbeddingRandom()
      (point_embeddings): ModuleList(
        (0): Embedding(1, 256)
        (1): Embedding(1, 256)
        (2): Embedding(1, 256)
        (3): Embedding(1, 256)
      )
      (not_a_point_embed): Embedding(1, 256)
      (mask_downscaling): Sequential(
        (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
        (4): LayerNorm2d()
        (5): GELU()
        (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (no_mask_embed): Embedding(1, 256)
    )
    (mask_decoder): MaskDecoder(
      (transformer): TwoWayTransformer(
        (layers): ModuleList(
          (0): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
          (1): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
        )
        (final_attn_token_to_image): Attention(
          (q_proj): Linear(in_features=256, out_features=128, bias=True)
          (k_proj): Linear(in_features=256, out_features=128, bias=True)
          (v_proj): Linear(in_features=256, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (iou_token): Embedding(1, 256)
      (mask_tokens): Embedding(4, 256)
      (output_upscaling): Sequential(
        (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
        (4): GELU()
      )
      (output_hypernetworks_mlps): ModuleList(
        (0): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (3): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
      )
      (iou_prediction_head): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
    )
  )
  (clip): CLIP(
    (visual): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
[12/07 19:21:23] detectron2 INFO: Optimized parameters:
{'backbone.fpn1.0.bias',
 'backbone.fpn1.0.weight',
 'backbone.fpn1.1.ln.bias',
 'backbone.fpn1.1.ln.weight',
 'backbone.fpn1.3.bias',
 'backbone.fpn1.3.weight',
 'backbone.fpn2.0.bias',
 'backbone.fpn2.0.weight',
 'context_former_pe',
 'proposal_generator.rpn_head.anchor_deltas.bias',
 'proposal_generator.rpn_head.anchor_deltas.weight',
 'proposal_generator.rpn_head.conv.bias',
 'proposal_generator.rpn_head.conv.weight',
 'proposal_generator.rpn_head.objectness_logits.bias',
 'proposal_generator.rpn_head.objectness_logits.weight',
 'roi_heads.box_head.fc1.bias',
 'roi_heads.box_head.fc1.weight',
 'roi_heads.box_head.fc2.bias',
 'roi_heads.box_head.fc2.weight',
 'roi_heads.box_predictor.bbox_pred.bias',
 'roi_heads.box_predictor.bbox_pred.weight',
 'roi_heads.box_predictor.cls_score.bias',
 'roi_heads.box_predictor.cls_score.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.norm.bias',
 'roi_heads.mask_head.contextformer.decoder1.norm.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.kv_proj.bias',
 'roi_heads.mask_head.contextformer.kv_proj.weight',
 'roi_heads.mask_head.contextformer.ln_mask.bias',
 'roi_heads.mask_head.contextformer.ln_mask.weight',
 'roi_heads.mask_head.contextformer.logit_scale',
 'roi_heads.mask_head.contextformer.proj.bias',
 'roi_heads.mask_head.contextformer.proj.weight',
 'roi_heads.mask_head.contextformer.q_proj.bias',
 'roi_heads.mask_head.contextformer.q_proj.weight',
 'roi_heads.mask_head.point_emb.0.bias',
 'roi_heads.mask_head.point_emb.0.weight',
 'roi_heads.mask_head.point_emb.1.bias',
 'roi_heads.mask_head.point_emb.1.weight',
 'roi_heads.mask_head.point_emb.4.bias',
 'roi_heads.mask_head.point_emb.4.weight',
 'roi_heads.mask_head.point_emb.6.bias',
 'roi_heads.mask_head.point_emb.6.weight',
 'roi_heads.mask_head.point_emb.8.bias',
 'roi_heads.mask_head.point_emb.8.weight'}
[12/07 19:21:23] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from mobile_sam.pt ...
[12/07 19:21:23] fvcore.common.checkpoint INFO: [Checkpointer] Loading from mobile_sam.pt ...
[12/07 19:21:24] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule sam - Total num: 171
[12/07 19:21:24] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn1.0.{bias, weight}[0m
[34mbackbone.fpn1.1.ln.{bias, weight}[0m
[34mbackbone.fpn1.3.{bias, weight}[0m
[34mbackbone.fpn2.0.{bias, weight}[0m
[34mclip.ln_final.{bias, weight}[0m
[34mclip.token_embedding.weight[0m
[34mclip.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.conv1.weight[0m
[34mclip.visual.ln_post.{bias, weight}[0m
[34mclip.visual.ln_pre.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.{class_embedding, positional_embedding, proj}[0m
[34mclip.{logit_scale, positional_embedding, text_projection}[0m
[34mcontext_former_pe[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.kv_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.ln_mask.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.logit_scale[0m
[34mroi_heads.mask_head.contextformer.proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.q_proj.{bias, weight}[0m
[34mroi_heads.mask_head.freq_weight[0m
[34mroi_heads.mask_head.point_emb.0.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.1.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.mask_head.point_emb.4.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.6.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.8.{bias, weight}[0m
[12/07 19:21:24] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mimage_encoder.head.{bias, weight}[0m
  [35mimage_encoder.norm_head.{bias, weight}[0m
[12/07 19:21:24] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeLongestSizeFlip(longest_length=1024), RandomFlip(prob=0.5)]
[12/07 19:21:35] d2.data.datasets.coco INFO: Loading datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json takes 11.18 seconds.
[12/07 19:21:36] d2.data.datasets.coco INFO: Loaded 107761 images in COCO format from datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json
[12/07 19:21:41] d2.data.build INFO: Removed 0 images with no usable annotations. 107761 images left.
[12/07 19:21:44] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 257253       |   bicycle    | 7056         |      car      | 43533        |
|  motorcycle   | 8654         |   airplane   | 0            |      bus      | 0            |
|     train     | 4570         |    truck     | 9970         |     boat      | 10576        |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 9820         |     bird      | 10542        |
|      cat      | 0            |     dog      | 0            |     horse     | 6567         |
|     sheep     | 9223         |     cow      | 0            |   elephant    | 0            |
|     bear      | 1294         |    zebra     | 5269         |    giraffe    | 5128         |
|   backpack    | 8714         |   umbrella   | 0            |    handbag    | 12342        |
|      tie      | 0            |   suitcase   | 6112         |    frisbee    | 2681         |
|     skis      | 6623         |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 8802         | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 6095         | tennis racket | 0            |
|    bottle     | 24070        |  wine glass  | 0            |      cup      | 0            |
|     fork      | 5474         |    knife     | 0            |     spoon     | 6159         |
|     bowl      | 14323        |    banana    | 9195         |     apple     | 5776         |
|   sandwich    | 4356         |    orange    | 6302         |   broccoli    | 7261         |
|    carrot     | 7758         |   hot dog    | 0            |     pizza     | 5807         |
|     donut     | 7005         |     cake     | 0            |     chair     | 38073        |
|     couch     | 0            | potted plant | 0            |      bed      | 4192         |
| dining table  | 0            |    toilet    | 4149         |      tv       | 5803         |
|    laptop     | 4960         |    mouse     | 2261         |    remote     | 5700         |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 1672         |
|     oven      | 3334         |   toaster    | 225          |     sink      | 0            |
| refrigerator  | 2634         |     book     | 24077        |     clock     | 6320         |
|     vase      | 6577         |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 1945         |               |              |
|     total     | 656232       |              |              |               |              |[0m
[12/07 19:21:44] d2.data.build INFO: Using training sampler TrainingSampler
[12/07 19:21:44] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 19:21:44] d2.data.common INFO: Serializing 107761 elements to byte tensors and concatenating them all ...
[12/07 19:21:46] d2.data.common INFO: Serialized dataset takes 361.37 MiB
[12/07 19:21:48] detectron2 INFO: Starting training from iteration 0
[12/07 19:26:01] detectron2 INFO: Rank of current process: 0. World size: 1
[12/07 19:26:01] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]
numpy                            1.23.4
detectron2                       0.6 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/detectron2
Compiler                         GCC 7.5
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3,4,5,6,7              NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   515.76
CUDA_HOME                        /home/xchen/cuda-11.4/
Pillow                           9.4.0
torchvision                      0.11.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/07 19:26:01] detectron2 INFO: Command line arguments: Namespace(config_file='configs/OpenDet_tiny_coco.yaml', dist_url='tcp://127.0.0.1:50165', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2', 'OUTPUT_DIR', '.output/test'], resume=False)
[12/07 19:26:01] detectron2 INFO: Contents of args.config_file=configs/OpenDet_tiny_coco.yaml:
[38;5;245m# _BASE_: "Base_OVCOCO_C4_1x.yaml"[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSamOpenDetector[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_sam_vit_det_backbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m#SAM vit_h[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mvit_t[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mViT-B/16[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcontext_former_pe[39m[38;5;186m'[39m[38;5;15m [39m[38;5;245m# unfrozen extra part of model, the name is relative to sam and clip[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmobile_sam.pt[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "/opt/tiger/OpenVo-Seg-master/output/wo_mask_with_prompt_encoder_roi_head_withgrad/model_final.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "sam_vit_h_4b8939.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "output/Detic-COCO/RSPrompter_anchor/model_0000999.pth"[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m4[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m16[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m32[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m64[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mLN[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m123.675[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m116.280[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m103.530[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m58.395[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.375[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDefaultAnchorGenerator[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m32[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m64[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m128[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m512[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1.0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m2.0[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m  [39m[38;5;245m# Three aspect ratios (same for all in feature maps)[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSAMRPN[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStandardRPNHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat0[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;245m# Detectron1 uses 2000 proposals per-batch,[39m
[38;5;15m    [39m[38;5;245m# (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)[39m
[38;5;15m    [39m[38;5;245m# which is approximately 1000 proposals per-image since the default batch size for FPN is 2.[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.3[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m0.7[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m[38;5;15m [39m[38;5;245m# the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbinary_ce[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m# options: centerness, binary_ce[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamAnchorPromptRoiHeads[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m[38;5;15m [39m[38;5;245m#the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m[38;5;15m  [39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mFastRCNNConvFCHead[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;245m# Shared2FCBBoxHead[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(10.0,[39m[38;5;141m [39m[38;5;141m10.0,[39m[38;5;141m [39m[38;5;141m5.0,[39m[38;5;141m [39m[38;5;141m5.0)[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamMaskHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mce_dice[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_zeroshot_train_oriorder",)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_not_zeroshot_val",)[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m [39m[38;5;245m# num_workers == batchsize_per_gpu[39m
[38;5;15m  [39m[38;5;245m# PERSISTENT_WORKERS: True [39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m  [39m[38;5;245m# change  # max 8 imgs per batch[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m[38;5;15m  [39m[38;5;245m# change0.000025[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(60000,[39m[38;5;141m [39m[38;5;141m80000)[39m[38;5;15m  [39m[38;5;245m# change [39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD [39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m[38;5;15m [39m[38;5;245m#1.0001[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mWarmupCosineLR[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;245m# LR_SCHEDULER_NAME: "WarmupMultiStepLR"[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m[38;5;15m  [39m[38;5;245m#  change[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mADAMW[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m[38;5;15m  [39m[38;5;245m# the output freq of logger writer[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(90,[39m[38;5;141m [39m[38;5;141m4)[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# PAD_MASK: True[39m
[38;5;15m  [39m[38;5;245m# MASK_PAD_VAL: 0.0[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbitmask[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m[38;5;15m  [39m[38;5;245m#test_topk_per_image[39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m[38;5;15m [39m[38;5;245m# change[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m[38;5;15m [39m[38;5;245m#every gpu has most 2 images  # change[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcls[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m./output/ovcoco[39m[38;5;186m'[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m

[12/07 19:26:01] detectron2 INFO: Running with full config:
[38;5;204mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;204mPERSISTENT_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_not_zeroshot_val[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_zeroshot_train_oriorder[39m
[38;5;204mFIND_UNUSED_PARAM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m  [39m[38;5;204mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbitmask[39m
[38;5;15m  [39m[38;5;204mMASK_PAD_VAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;204mPAD_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;204mSCALE_RANGE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;204mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcontext_former_pe[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mViT-B/16[39m
[38;5;15m    [39m[38;5;204mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_sam_vit_det_backbone[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvit_t[39m
[38;5;15m  [39m[38;5;204mCONFIGS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mONLY_DECODER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;204mINNER_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mLN[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mSELECTED_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m22[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m26[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m28[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30[39m
[38;5;15m    [39m[38;5;204mUP_SAMPLE_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSamOpenDetector[39m
[38;5;15m  [39m[38;5;204mNUM_SAMPLE_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m  [39m[38;5;204mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSAMRPN[39m
[38;5;15m  [39m[38;5;204mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;204mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;204mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;204mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFastRCNNConvFCHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamAnchorPromptRoiHeads[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m  [39m[38;5;204mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mce_dice[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamMaskHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;204mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat0[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbinary_ce[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAM_FROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSemSegFPNHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m54[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmobile_sam.pt[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m.output/test[39m
[38;5;204mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m
[38;5;15m  [39m[38;5;204mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;204mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvalue[39m
[38;5;15m    [39m[38;5;204mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupCosineLR[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;204mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m80000[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;204mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m  [39m[38;5;204mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcls[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m

[12/07 19:26:01] detectron2 INFO: Full config saved to .output/test/config.yaml
[12/07 19:26:01] d2.utils.env INFO: Using a generated random seed 3104464
[12/07 19:26:14] detectron2 INFO: Rank of current process: 0. World size: 1
[12/07 19:26:15] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]
numpy                            1.23.4
detectron2                       0.6 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/detectron2
Compiler                         GCC 7.5
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3,4,5,6,7              NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   515.76
CUDA_HOME                        /home/xchen/cuda-11.4/
Pillow                           9.4.0
torchvision                      0.11.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/07 19:26:15] detectron2 INFO: Command line arguments: Namespace(config_file='configs/OpenDet_tiny_coco.yaml', dist_url='tcp://127.0.0.1:50165', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2', 'OUTPUT_DIR', '.output/test'], resume=False)
[12/07 19:26:15] detectron2 INFO: Contents of args.config_file=configs/OpenDet_tiny_coco.yaml:
[38;5;245m# _BASE_: "Base_OVCOCO_C4_1x.yaml"[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSamOpenDetector[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_sam_vit_det_backbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m#SAM vit_h[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mvit_t[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mViT-B/16[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcontext_former_pe[39m[38;5;186m'[39m[38;5;15m [39m[38;5;245m# unfrozen extra part of model, the name is relative to sam and clip[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmobile_sam.pt[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "/opt/tiger/OpenVo-Seg-master/output/wo_mask_with_prompt_encoder_roi_head_withgrad/model_final.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "sam_vit_h_4b8939.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "output/Detic-COCO/RSPrompter_anchor/model_0000999.pth"[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m4[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m16[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m32[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m64[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mLN[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m123.675[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m116.280[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m103.530[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m58.395[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.375[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDefaultAnchorGenerator[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m32[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m64[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m128[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m512[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1.0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m2.0[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m  [39m[38;5;245m# Three aspect ratios (same for all in feature maps)[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSAMRPN[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStandardRPNHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat0[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;245m# Detectron1 uses 2000 proposals per-batch,[39m
[38;5;15m    [39m[38;5;245m# (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)[39m
[38;5;15m    [39m[38;5;245m# which is approximately 1000 proposals per-image since the default batch size for FPN is 2.[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.3[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m0.7[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m[38;5;15m [39m[38;5;245m# the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbinary_ce[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m# options: centerness, binary_ce[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamAnchorPromptRoiHeads[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m[38;5;15m [39m[38;5;245m#the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m[38;5;15m  [39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mFastRCNNConvFCHead[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;245m# Shared2FCBBoxHead[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(10.0,[39m[38;5;141m [39m[38;5;141m10.0,[39m[38;5;141m [39m[38;5;141m5.0,[39m[38;5;141m [39m[38;5;141m5.0)[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamMaskHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mce_dice[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_zeroshot_train_oriorder",)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_not_zeroshot_val",)[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m [39m[38;5;245m# num_workers == batchsize_per_gpu[39m
[38;5;15m  [39m[38;5;245m# PERSISTENT_WORKERS: True [39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m  [39m[38;5;245m# change  # max 8 imgs per batch[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m[38;5;15m  [39m[38;5;245m# change0.000025[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(60000,[39m[38;5;141m [39m[38;5;141m80000)[39m[38;5;15m  [39m[38;5;245m# change [39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD [39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m[38;5;15m [39m[38;5;245m#1.0001[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mWarmupCosineLR[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;245m# LR_SCHEDULER_NAME: "WarmupMultiStepLR"[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m[38;5;15m  [39m[38;5;245m#  change[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mADAMW[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m[38;5;15m  [39m[38;5;245m# the output freq of logger writer[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(90,[39m[38;5;141m [39m[38;5;141m4)[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# PAD_MASK: True[39m
[38;5;15m  [39m[38;5;245m# MASK_PAD_VAL: 0.0[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbitmask[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m[38;5;15m  [39m[38;5;245m#test_topk_per_image[39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m[38;5;15m [39m[38;5;245m# change[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m[38;5;15m [39m[38;5;245m#every gpu has most 2 images  # change[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcls[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m./output/ovcoco[39m[38;5;186m'[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m

[12/07 19:26:15] detectron2 INFO: Running with full config:
[38;5;204mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;204mPERSISTENT_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_not_zeroshot_val[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_zeroshot_train_oriorder[39m
[38;5;204mFIND_UNUSED_PARAM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m  [39m[38;5;204mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbitmask[39m
[38;5;15m  [39m[38;5;204mMASK_PAD_VAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;204mPAD_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;204mSCALE_RANGE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;204mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcontext_former_pe[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mViT-B/16[39m
[38;5;15m    [39m[38;5;204mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_sam_vit_det_backbone[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvit_t[39m
[38;5;15m  [39m[38;5;204mCONFIGS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mONLY_DECODER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;204mINNER_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mLN[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mSELECTED_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m22[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m26[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m28[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30[39m
[38;5;15m    [39m[38;5;204mUP_SAMPLE_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSamOpenDetector[39m
[38;5;15m  [39m[38;5;204mNUM_SAMPLE_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m  [39m[38;5;204mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSAMRPN[39m
[38;5;15m  [39m[38;5;204mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;204mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;204mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;204mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFastRCNNConvFCHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamAnchorPromptRoiHeads[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m  [39m[38;5;204mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mce_dice[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamMaskHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;204mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat0[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbinary_ce[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAM_FROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSemSegFPNHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m54[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmobile_sam.pt[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m.output/test[39m
[38;5;204mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m
[38;5;15m  [39m[38;5;204mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;204mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvalue[39m
[38;5;15m    [39m[38;5;204mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupCosineLR[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;204mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m80000[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;204mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m  [39m[38;5;204mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcls[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m

[12/07 19:26:15] detectron2 INFO: Full config saved to .output/test/config.yaml
[12/07 19:26:15] d2.utils.env INFO: Using a generated random seed 16344086
[12/07 19:26:26] detectron2 INFO: Model:
SamOpenDetector(
  (backbone): SAMVitDet(
    (fpn1): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (1): Norm2d(
        (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): GELU()
      (3): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn2): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn3): Identity()
    (fpn4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (proposal_generator): SAMRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): samAnchorPromptRoiHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): SamRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): samMaskHead(
      (point_emb): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Flatten(start_dim=1, end_dim=-1)
        (4): Linear(in_features=12544, out_features=256, bias=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=True)
        (7): ReLU(inplace=True)
        (8): Linear(in_features=256, out_features=2048, bias=True)
      )
      (contextformer): build_contextformer(
        (decoder1): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (decoder2): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (q_proj): Linear(in_features=256, out_features=768, bias=True)
        (kv_proj): Linear(in_features=1536, out_features=768, bias=True)
        (proj): Linear(in_features=768, out_features=512, bias=True)
        (ln_mask): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (generator_pe): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
  )
  (sam): Sam(
    (image_encoder): TinyViT(
      (patch_embed): PatchEmbed(
        (seq): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU()
          (2): Conv2d_BN(
            (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layers): ModuleList(
        (0): ConvLayer(
          (blocks): ModuleList(
            (0): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
            (1): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (1): BasicLayer(
          dim=128, input_resolution=(128, 128), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (2): BasicLayer(
          dim=160, input_resolution=(64, 64), depth=6
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (3): BasicLayer(
          dim=320, input_resolution=(64, 64), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (neck): Sequential(
        (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): LayerNorm2d()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (3): LayerNorm2d()
      )
    )
    (prompt_encoder): PromptEncoder(
      (pe_layer): PositionEmbeddingRandom()
      (point_embeddings): ModuleList(
        (0): Embedding(1, 256)
        (1): Embedding(1, 256)
        (2): Embedding(1, 256)
        (3): Embedding(1, 256)
      )
      (not_a_point_embed): Embedding(1, 256)
      (mask_downscaling): Sequential(
        (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
        (4): LayerNorm2d()
        (5): GELU()
        (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (no_mask_embed): Embedding(1, 256)
    )
    (mask_decoder): MaskDecoder(
      (transformer): TwoWayTransformer(
        (layers): ModuleList(
          (0): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
          (1): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
        )
        (final_attn_token_to_image): Attention(
          (q_proj): Linear(in_features=256, out_features=128, bias=True)
          (k_proj): Linear(in_features=256, out_features=128, bias=True)
          (v_proj): Linear(in_features=256, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (iou_token): Embedding(1, 256)
      (mask_tokens): Embedding(4, 256)
      (output_upscaling): Sequential(
        (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
        (4): GELU()
      )
      (output_hypernetworks_mlps): ModuleList(
        (0): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (3): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
      )
      (iou_prediction_head): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
    )
  )
  (clip): CLIP(
    (visual): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
[12/07 19:26:26] detectron2 INFO: Optimized parameters:
{'backbone.fpn1.0.bias',
 'backbone.fpn1.0.weight',
 'backbone.fpn1.1.ln.bias',
 'backbone.fpn1.1.ln.weight',
 'backbone.fpn1.3.bias',
 'backbone.fpn1.3.weight',
 'backbone.fpn2.0.bias',
 'backbone.fpn2.0.weight',
 'context_former_pe',
 'proposal_generator.rpn_head.anchor_deltas.bias',
 'proposal_generator.rpn_head.anchor_deltas.weight',
 'proposal_generator.rpn_head.conv.bias',
 'proposal_generator.rpn_head.conv.weight',
 'proposal_generator.rpn_head.objectness_logits.bias',
 'proposal_generator.rpn_head.objectness_logits.weight',
 'roi_heads.box_head.fc1.bias',
 'roi_heads.box_head.fc1.weight',
 'roi_heads.box_head.fc2.bias',
 'roi_heads.box_head.fc2.weight',
 'roi_heads.box_predictor.bbox_pred.bias',
 'roi_heads.box_predictor.bbox_pred.weight',
 'roi_heads.box_predictor.cls_score.bias',
 'roi_heads.box_predictor.cls_score.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.norm.bias',
 'roi_heads.mask_head.contextformer.decoder1.norm.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.kv_proj.bias',
 'roi_heads.mask_head.contextformer.kv_proj.weight',
 'roi_heads.mask_head.contextformer.ln_mask.bias',
 'roi_heads.mask_head.contextformer.ln_mask.weight',
 'roi_heads.mask_head.contextformer.logit_scale',
 'roi_heads.mask_head.contextformer.proj.bias',
 'roi_heads.mask_head.contextformer.proj.weight',
 'roi_heads.mask_head.contextformer.q_proj.bias',
 'roi_heads.mask_head.contextformer.q_proj.weight',
 'roi_heads.mask_head.point_emb.0.bias',
 'roi_heads.mask_head.point_emb.0.weight',
 'roi_heads.mask_head.point_emb.1.bias',
 'roi_heads.mask_head.point_emb.1.weight',
 'roi_heads.mask_head.point_emb.4.bias',
 'roi_heads.mask_head.point_emb.4.weight',
 'roi_heads.mask_head.point_emb.6.bias',
 'roi_heads.mask_head.point_emb.6.weight',
 'roi_heads.mask_head.point_emb.8.bias',
 'roi_heads.mask_head.point_emb.8.weight'}
[12/07 19:26:26] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from mobile_sam.pt ...
[12/07 19:26:26] fvcore.common.checkpoint INFO: [Checkpointer] Loading from mobile_sam.pt ...
[12/07 19:26:26] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule sam - Total num: 171
[12/07 19:26:26] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn1.0.{bias, weight}[0m
[34mbackbone.fpn1.1.ln.{bias, weight}[0m
[34mbackbone.fpn1.3.{bias, weight}[0m
[34mbackbone.fpn2.0.{bias, weight}[0m
[34mclip.ln_final.{bias, weight}[0m
[34mclip.token_embedding.weight[0m
[34mclip.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.conv1.weight[0m
[34mclip.visual.ln_post.{bias, weight}[0m
[34mclip.visual.ln_pre.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.{class_embedding, positional_embedding, proj}[0m
[34mclip.{logit_scale, positional_embedding, text_projection}[0m
[34mcontext_former_pe[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.kv_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.ln_mask.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.logit_scale[0m
[34mroi_heads.mask_head.contextformer.proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.q_proj.{bias, weight}[0m
[34mroi_heads.mask_head.freq_weight[0m
[34mroi_heads.mask_head.point_emb.0.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.1.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.mask_head.point_emb.4.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.6.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.8.{bias, weight}[0m
[12/07 19:26:26] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mimage_encoder.head.{bias, weight}[0m
  [35mimage_encoder.norm_head.{bias, weight}[0m
[12/07 19:26:26] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeLongestSizeFlip(longest_length=1024), RandomFlip(prob=0.5)]
[12/07 19:26:37] d2.data.datasets.coco INFO: Loading datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json takes 11.12 seconds.
[12/07 19:26:39] d2.data.datasets.coco INFO: Loaded 107761 images in COCO format from datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json
[12/07 19:26:43] d2.data.build INFO: Removed 0 images with no usable annotations. 107761 images left.
[12/07 19:26:47] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 257253       |   bicycle    | 7056         |      car      | 43533        |
|  motorcycle   | 8654         |   airplane   | 0            |      bus      | 0            |
|     train     | 4570         |    truck     | 9970         |     boat      | 10576        |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 9820         |     bird      | 10542        |
|      cat      | 0            |     dog      | 0            |     horse     | 6567         |
|     sheep     | 9223         |     cow      | 0            |   elephant    | 0            |
|     bear      | 1294         |    zebra     | 5269         |    giraffe    | 5128         |
|   backpack    | 8714         |   umbrella   | 0            |    handbag    | 12342        |
|      tie      | 0            |   suitcase   | 6112         |    frisbee    | 2681         |
|     skis      | 6623         |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 8802         | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 6095         | tennis racket | 0            |
|    bottle     | 24070        |  wine glass  | 0            |      cup      | 0            |
|     fork      | 5474         |    knife     | 0            |     spoon     | 6159         |
|     bowl      | 14323        |    banana    | 9195         |     apple     | 5776         |
|   sandwich    | 4356         |    orange    | 6302         |   broccoli    | 7261         |
|    carrot     | 7758         |   hot dog    | 0            |     pizza     | 5807         |
|     donut     | 7005         |     cake     | 0            |     chair     | 38073        |
|     couch     | 0            | potted plant | 0            |      bed      | 4192         |
| dining table  | 0            |    toilet    | 4149         |      tv       | 5803         |
|    laptop     | 4960         |    mouse     | 2261         |    remote     | 5700         |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 1672         |
|     oven      | 3334         |   toaster    | 225          |     sink      | 0            |
| refrigerator  | 2634         |     book     | 24077        |     clock     | 6320         |
|     vase      | 6577         |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 1945         |               |              |
|     total     | 656232       |              |              |               |              |[0m
[12/07 19:26:47] d2.data.build INFO: Using training sampler TrainingSampler
[12/07 19:26:47] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 19:26:47] d2.data.common INFO: Serializing 107761 elements to byte tensors and concatenating them all ...
[12/07 19:26:49] d2.data.common INFO: Serialized dataset takes 361.37 MiB
[12/07 19:26:51] detectron2 INFO: Starting training from iteration 0
[12/07 19:40:43] detectron2 INFO: Rank of current process: 0. World size: 1
[12/07 19:40:44] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]
numpy                            1.23.4
detectron2                       0.6 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/detectron2
Compiler                         GCC 7.5
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3,4,5,6,7              NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   515.76
CUDA_HOME                        /home/xchen/cuda-11.4/
Pillow                           9.4.0
torchvision                      0.11.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/07 19:40:44] detectron2 INFO: Command line arguments: Namespace(config_file='configs/OpenDet_tiny_coco.yaml', dist_url='tcp://127.0.0.1:50165', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2', 'OUTPUT_DIR', '.output/test'], resume=False)
[12/07 19:40:44] detectron2 INFO: Contents of args.config_file=configs/OpenDet_tiny_coco.yaml:
[38;5;245m# _BASE_: "Base_OVCOCO_C4_1x.yaml"[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSamOpenDetector[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_sam_vit_det_backbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m#SAM vit_h[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mvit_t[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mViT-B/16[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcontext_former_pe[39m[38;5;186m'[39m[38;5;15m [39m[38;5;245m# unfrozen extra part of model, the name is relative to sam and clip[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmobile_sam.pt[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "/opt/tiger/OpenVo-Seg-master/output/wo_mask_with_prompt_encoder_roi_head_withgrad/model_final.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "sam_vit_h_4b8939.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "output/Detic-COCO/RSPrompter_anchor/model_0000999.pth"[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m4[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m16[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m32[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m64[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mLN[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m123.675[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m116.280[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m103.530[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m58.395[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.375[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDefaultAnchorGenerator[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m32[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m64[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m128[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m512[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1.0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m2.0[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m  [39m[38;5;245m# Three aspect ratios (same for all in feature maps)[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSAMRPN[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStandardRPNHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat0[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;245m# Detectron1 uses 2000 proposals per-batch,[39m
[38;5;15m    [39m[38;5;245m# (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)[39m
[38;5;15m    [39m[38;5;245m# which is approximately 1000 proposals per-image since the default batch size for FPN is 2.[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.3[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m0.7[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m[38;5;15m [39m[38;5;245m# the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbinary_ce[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m# options: centerness, binary_ce[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamAnchorPromptRoiHeads[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m[38;5;15m [39m[38;5;245m#the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m[38;5;15m  [39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mFastRCNNConvFCHead[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;245m# Shared2FCBBoxHead[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(10.0,[39m[38;5;141m [39m[38;5;141m10.0,[39m[38;5;141m [39m[38;5;141m5.0,[39m[38;5;141m [39m[38;5;141m5.0)[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamMaskHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mce_dice[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_zeroshot_train_oriorder",)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_not_zeroshot_val",)[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m [39m[38;5;245m# num_workers == batchsize_per_gpu[39m
[38;5;15m  [39m[38;5;245m# PERSISTENT_WORKERS: True [39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m  [39m[38;5;245m# change  # max 8 imgs per batch[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m[38;5;15m  [39m[38;5;245m# change0.000025[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(60000,[39m[38;5;141m [39m[38;5;141m80000)[39m[38;5;15m  [39m[38;5;245m# change [39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD [39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m[38;5;15m [39m[38;5;245m#1.0001[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mWarmupCosineLR[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;245m# LR_SCHEDULER_NAME: "WarmupMultiStepLR"[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m[38;5;15m  [39m[38;5;245m#  change[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mADAMW[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m[38;5;15m  [39m[38;5;245m# the output freq of logger writer[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(90,[39m[38;5;141m [39m[38;5;141m4)[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# PAD_MASK: True[39m
[38;5;15m  [39m[38;5;245m# MASK_PAD_VAL: 0.0[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbitmask[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m[38;5;15m  [39m[38;5;245m#test_topk_per_image[39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m[38;5;15m [39m[38;5;245m# change[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m[38;5;15m [39m[38;5;245m#every gpu has most 2 images  # change[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcls[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m./output/ovcoco[39m[38;5;186m'[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m

[12/07 19:40:44] detectron2 INFO: Running with full config:
[38;5;204mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;204mPERSISTENT_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_not_zeroshot_val[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_zeroshot_train_oriorder[39m
[38;5;204mFIND_UNUSED_PARAM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m  [39m[38;5;204mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbitmask[39m
[38;5;15m  [39m[38;5;204mMASK_PAD_VAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;204mPAD_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;204mSCALE_RANGE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;204mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcontext_former_pe[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mViT-B/16[39m
[38;5;15m    [39m[38;5;204mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_sam_vit_det_backbone[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvit_t[39m
[38;5;15m  [39m[38;5;204mCONFIGS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mONLY_DECODER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;204mINNER_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mLN[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mSELECTED_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m22[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m26[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m28[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30[39m
[38;5;15m    [39m[38;5;204mUP_SAMPLE_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSamOpenDetector[39m
[38;5;15m  [39m[38;5;204mNUM_SAMPLE_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m  [39m[38;5;204mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSAMRPN[39m
[38;5;15m  [39m[38;5;204mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;204mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;204mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;204mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFastRCNNConvFCHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamAnchorPromptRoiHeads[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m  [39m[38;5;204mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mce_dice[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamMaskHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;204mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat0[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbinary_ce[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAM_FROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSemSegFPNHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m54[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmobile_sam.pt[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m.output/test[39m
[38;5;204mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m
[38;5;15m  [39m[38;5;204mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;204mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvalue[39m
[38;5;15m    [39m[38;5;204mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupCosineLR[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;204mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m80000[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;204mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m  [39m[38;5;204mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcls[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m

[12/07 19:40:44] detectron2 INFO: Full config saved to .output/test/config.yaml
[12/07 19:40:44] d2.utils.env INFO: Using a generated random seed 45367590
[12/07 19:40:55] detectron2 INFO: Model:
SamOpenDetector(
  (backbone): SAMVitDet(
    (fpn1): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (1): Norm2d(
        (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): GELU()
      (3): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn2): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn3): Identity()
    (fpn4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (proposal_generator): SAMRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): samAnchorPromptRoiHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): SamRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): samMaskHead(
      (point_emb): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Flatten(start_dim=1, end_dim=-1)
        (4): Linear(in_features=12544, out_features=256, bias=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=True)
        (7): ReLU(inplace=True)
        (8): Linear(in_features=256, out_features=2048, bias=True)
      )
      (contextformer): build_contextformer(
        (decoder1): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (decoder2): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (q_proj): Linear(in_features=256, out_features=768, bias=True)
        (kv_proj): Linear(in_features=1024, out_features=768, bias=True)
        (ln_mask): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (generator_pe): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
  )
  (sam): Sam(
    (image_encoder): TinyViT(
      (patch_embed): PatchEmbed(
        (seq): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU()
          (2): Conv2d_BN(
            (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layers): ModuleList(
        (0): ConvLayer(
          (blocks): ModuleList(
            (0): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
            (1): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (1): BasicLayer(
          dim=128, input_resolution=(128, 128), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (2): BasicLayer(
          dim=160, input_resolution=(64, 64), depth=6
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (3): BasicLayer(
          dim=320, input_resolution=(64, 64), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (neck): Sequential(
        (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): LayerNorm2d()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (3): LayerNorm2d()
      )
    )
    (prompt_encoder): PromptEncoder(
      (pe_layer): PositionEmbeddingRandom()
      (point_embeddings): ModuleList(
        (0): Embedding(1, 256)
        (1): Embedding(1, 256)
        (2): Embedding(1, 256)
        (3): Embedding(1, 256)
      )
      (not_a_point_embed): Embedding(1, 256)
      (mask_downscaling): Sequential(
        (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
        (4): LayerNorm2d()
        (5): GELU()
        (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (no_mask_embed): Embedding(1, 256)
    )
    (mask_decoder): MaskDecoder(
      (transformer): TwoWayTransformer(
        (layers): ModuleList(
          (0): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
          (1): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
        )
        (final_attn_token_to_image): Attention(
          (q_proj): Linear(in_features=256, out_features=128, bias=True)
          (k_proj): Linear(in_features=256, out_features=128, bias=True)
          (v_proj): Linear(in_features=256, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (iou_token): Embedding(1, 256)
      (mask_tokens): Embedding(4, 256)
      (output_upscaling): Sequential(
        (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
        (4): GELU()
      )
      (output_hypernetworks_mlps): ModuleList(
        (0): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (3): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
      )
      (iou_prediction_head): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
    )
  )
  (clip): CLIP(
    (visual): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
[12/07 19:40:55] detectron2 INFO: Optimized parameters:
{'backbone.fpn1.0.bias',
 'backbone.fpn1.0.weight',
 'backbone.fpn1.1.ln.bias',
 'backbone.fpn1.1.ln.weight',
 'backbone.fpn1.3.bias',
 'backbone.fpn1.3.weight',
 'backbone.fpn2.0.bias',
 'backbone.fpn2.0.weight',
 'context_former_pe',
 'proposal_generator.rpn_head.anchor_deltas.bias',
 'proposal_generator.rpn_head.anchor_deltas.weight',
 'proposal_generator.rpn_head.conv.bias',
 'proposal_generator.rpn_head.conv.weight',
 'proposal_generator.rpn_head.objectness_logits.bias',
 'proposal_generator.rpn_head.objectness_logits.weight',
 'roi_heads.box_head.fc1.bias',
 'roi_heads.box_head.fc1.weight',
 'roi_heads.box_head.fc2.bias',
 'roi_heads.box_head.fc2.weight',
 'roi_heads.box_predictor.bbox_pred.bias',
 'roi_heads.box_predictor.bbox_pred.weight',
 'roi_heads.box_predictor.cls_score.bias',
 'roi_heads.box_predictor.cls_score.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.norm.bias',
 'roi_heads.mask_head.contextformer.decoder1.norm.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.kv_proj.bias',
 'roi_heads.mask_head.contextformer.kv_proj.weight',
 'roi_heads.mask_head.contextformer.ln_mask.bias',
 'roi_heads.mask_head.contextformer.ln_mask.weight',
 'roi_heads.mask_head.contextformer.logit_scale',
 'roi_heads.mask_head.contextformer.q_proj.bias',
 'roi_heads.mask_head.contextformer.q_proj.weight',
 'roi_heads.mask_head.point_emb.0.bias',
 'roi_heads.mask_head.point_emb.0.weight',
 'roi_heads.mask_head.point_emb.1.bias',
 'roi_heads.mask_head.point_emb.1.weight',
 'roi_heads.mask_head.point_emb.4.bias',
 'roi_heads.mask_head.point_emb.4.weight',
 'roi_heads.mask_head.point_emb.6.bias',
 'roi_heads.mask_head.point_emb.6.weight',
 'roi_heads.mask_head.point_emb.8.bias',
 'roi_heads.mask_head.point_emb.8.weight'}
[12/07 19:40:55] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from mobile_sam.pt ...
[12/07 19:40:55] fvcore.common.checkpoint INFO: [Checkpointer] Loading from mobile_sam.pt ...
[12/07 19:40:55] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule sam - Total num: 171
[12/07 19:40:55] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn1.0.{bias, weight}[0m
[34mbackbone.fpn1.1.ln.{bias, weight}[0m
[34mbackbone.fpn1.3.{bias, weight}[0m
[34mbackbone.fpn2.0.{bias, weight}[0m
[34mclip.ln_final.{bias, weight}[0m
[34mclip.token_embedding.weight[0m
[34mclip.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.conv1.weight[0m
[34mclip.visual.ln_post.{bias, weight}[0m
[34mclip.visual.ln_pre.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.{class_embedding, positional_embedding, proj}[0m
[34mclip.{logit_scale, positional_embedding, text_projection}[0m
[34mcontext_former_pe[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.kv_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.ln_mask.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.logit_scale[0m
[34mroi_heads.mask_head.contextformer.q_proj.{bias, weight}[0m
[34mroi_heads.mask_head.freq_weight[0m
[34mroi_heads.mask_head.point_emb.0.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.1.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.mask_head.point_emb.4.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.6.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.8.{bias, weight}[0m
[12/07 19:40:55] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mimage_encoder.head.{bias, weight}[0m
  [35mimage_encoder.norm_head.{bias, weight}[0m
[12/07 19:40:55] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeLongestSizeFlip(longest_length=1024), RandomFlip(prob=0.5)]
[12/07 19:41:06] d2.data.datasets.coco INFO: Loading datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json takes 11.11 seconds.
[12/07 19:41:08] d2.data.datasets.coco INFO: Loaded 107761 images in COCO format from datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json
[12/07 19:41:12] d2.data.build INFO: Removed 0 images with no usable annotations. 107761 images left.
[12/07 19:41:15] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 257253       |   bicycle    | 7056         |      car      | 43533        |
|  motorcycle   | 8654         |   airplane   | 0            |      bus      | 0            |
|     train     | 4570         |    truck     | 9970         |     boat      | 10576        |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 9820         |     bird      | 10542        |
|      cat      | 0            |     dog      | 0            |     horse     | 6567         |
|     sheep     | 9223         |     cow      | 0            |   elephant    | 0            |
|     bear      | 1294         |    zebra     | 5269         |    giraffe    | 5128         |
|   backpack    | 8714         |   umbrella   | 0            |    handbag    | 12342        |
|      tie      | 0            |   suitcase   | 6112         |    frisbee    | 2681         |
|     skis      | 6623         |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 8802         | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 6095         | tennis racket | 0            |
|    bottle     | 24070        |  wine glass  | 0            |      cup      | 0            |
|     fork      | 5474         |    knife     | 0            |     spoon     | 6159         |
|     bowl      | 14323        |    banana    | 9195         |     apple     | 5776         |
|   sandwich    | 4356         |    orange    | 6302         |   broccoli    | 7261         |
|    carrot     | 7758         |   hot dog    | 0            |     pizza     | 5807         |
|     donut     | 7005         |     cake     | 0            |     chair     | 38073        |
|     couch     | 0            | potted plant | 0            |      bed      | 4192         |
| dining table  | 0            |    toilet    | 4149         |      tv       | 5803         |
|    laptop     | 4960         |    mouse     | 2261         |    remote     | 5700         |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 1672         |
|     oven      | 3334         |   toaster    | 225          |     sink      | 0            |
| refrigerator  | 2634         |     book     | 24077        |     clock     | 6320         |
|     vase      | 6577         |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 1945         |               |              |
|     total     | 656232       |              |              |               |              |[0m
[12/07 19:41:15] d2.data.build INFO: Using training sampler TrainingSampler
[12/07 19:41:15] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 19:41:15] d2.data.common INFO: Serializing 107761 elements to byte tensors and concatenating them all ...
[12/07 19:41:18] d2.data.common INFO: Serialized dataset takes 361.37 MiB
[12/07 19:41:19] detectron2 INFO: Starting training from iteration 0
[12/07 20:14:34] detectron2 INFO: Rank of current process: 0. World size: 1
[12/07 20:14:34] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]
numpy                            1.23.4
detectron2                       0.6 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/detectron2
Compiler                         GCC 7.5
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3,4,5,6,7              NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   515.76
CUDA_HOME                        /home/xchen/cuda-11.4/
Pillow                           9.4.0
torchvision                      0.11.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/07 20:14:34] detectron2 INFO: Command line arguments: Namespace(config_file='configs/OpenDet_tiny_coco.yaml', dist_url='tcp://127.0.0.1:50165', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2', 'OUTPUT_DIR', '.output/test'], resume=False)
[12/07 20:14:34] detectron2 INFO: Contents of args.config_file=configs/OpenDet_tiny_coco.yaml:
[38;5;245m# _BASE_: "Base_OVCOCO_C4_1x.yaml"[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSamOpenDetector[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_sam_vit_det_backbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m#SAM vit_h[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mvit_t[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mViT-B/16[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcontext_former_pe[39m[38;5;186m'[39m[38;5;15m [39m[38;5;245m# unfrozen extra part of model, the name is relative to sam and clip[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmobile_sam.pt[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "/opt/tiger/OpenVo-Seg-master/output/wo_mask_with_prompt_encoder_roi_head_withgrad/model_final.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "sam_vit_h_4b8939.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "output/Detic-COCO/RSPrompter_anchor/model_0000999.pth"[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m4[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m16[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m32[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m64[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mLN[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m123.675[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m116.280[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m103.530[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m58.395[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.375[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDefaultAnchorGenerator[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m32[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m64[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m128[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m512[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1.0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m2.0[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m  [39m[38;5;245m# Three aspect ratios (same for all in feature maps)[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSAMRPN[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStandardRPNHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat0[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;245m# Detectron1 uses 2000 proposals per-batch,[39m
[38;5;15m    [39m[38;5;245m# (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)[39m
[38;5;15m    [39m[38;5;245m# which is approximately 1000 proposals per-image since the default batch size for FPN is 2.[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.3[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m0.7[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m[38;5;15m [39m[38;5;245m# the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbinary_ce[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m# options: centerness, binary_ce[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamAnchorPromptRoiHeads[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m[38;5;15m [39m[38;5;245m#the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m[38;5;15m  [39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mFastRCNNConvFCHead[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;245m# Shared2FCBBoxHead[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(10.0,[39m[38;5;141m [39m[38;5;141m10.0,[39m[38;5;141m [39m[38;5;141m5.0,[39m[38;5;141m [39m[38;5;141m5.0)[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamMaskHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mce_dice[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_zeroshot_train_oriorder",)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_not_zeroshot_val",)[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m [39m[38;5;245m# num_workers == batchsize_per_gpu[39m
[38;5;15m  [39m[38;5;245m# PERSISTENT_WORKERS: True [39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m  [39m[38;5;245m# change  # max 8 imgs per batch[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m[38;5;15m  [39m[38;5;245m# change0.000025[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(60000,[39m[38;5;141m [39m[38;5;141m80000)[39m[38;5;15m  [39m[38;5;245m# change [39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD [39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m[38;5;15m [39m[38;5;245m#1.0001[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mWarmupCosineLR[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;245m# LR_SCHEDULER_NAME: "WarmupMultiStepLR"[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m[38;5;15m  [39m[38;5;245m#  change[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mADAMW[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m[38;5;15m  [39m[38;5;245m# the output freq of logger writer[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(90,[39m[38;5;141m [39m[38;5;141m4)[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# PAD_MASK: True[39m
[38;5;15m  [39m[38;5;245m# MASK_PAD_VAL: 0.0[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbitmask[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m[38;5;15m  [39m[38;5;245m#test_topk_per_image[39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m[38;5;15m [39m[38;5;245m# change[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m[38;5;15m [39m[38;5;245m#every gpu has most 2 images  # change[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcls[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m./output/ovcoco[39m[38;5;186m'[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m

[12/07 20:14:34] detectron2 INFO: Running with full config:
[38;5;204mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;204mPERSISTENT_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_not_zeroshot_val[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_zeroshot_train_oriorder[39m
[38;5;204mFIND_UNUSED_PARAM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m  [39m[38;5;204mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbitmask[39m
[38;5;15m  [39m[38;5;204mMASK_PAD_VAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;204mPAD_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;204mSCALE_RANGE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;204mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcontext_former_pe[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mViT-B/16[39m
[38;5;15m    [39m[38;5;204mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_sam_vit_det_backbone[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvit_t[39m
[38;5;15m  [39m[38;5;204mCONFIGS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mONLY_DECODER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;204mINNER_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mLN[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mSELECTED_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m22[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m26[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m28[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30[39m
[38;5;15m    [39m[38;5;204mUP_SAMPLE_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSamOpenDetector[39m
[38;5;15m  [39m[38;5;204mNUM_SAMPLE_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m  [39m[38;5;204mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSAMRPN[39m
[38;5;15m  [39m[38;5;204mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;204mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;204mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;204mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFastRCNNConvFCHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamAnchorPromptRoiHeads[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m  [39m[38;5;204mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mce_dice[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamMaskHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;204mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat0[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbinary_ce[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAM_FROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSemSegFPNHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m54[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmobile_sam.pt[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m.output/test[39m
[38;5;204mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m
[38;5;15m  [39m[38;5;204mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;204mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvalue[39m
[38;5;15m    [39m[38;5;204mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupCosineLR[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;204mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m80000[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;204mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m  [39m[38;5;204mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcls[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m

[12/07 20:14:34] detectron2 INFO: Full config saved to .output/test/config.yaml
[12/07 20:14:35] d2.utils.env INFO: Using a generated random seed 36286039
[12/07 20:14:46] detectron2 INFO: Model:
SamOpenDetector(
  (backbone): SAMVitDet(
    (fpn1): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (1): Norm2d(
        (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): GELU()
      (3): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn2): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn3): Identity()
    (fpn4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (proposal_generator): SAMRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): samAnchorPromptRoiHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): SamRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): samMaskHead(
      (point_emb): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Flatten(start_dim=1, end_dim=-1)
        (4): Linear(in_features=12544, out_features=256, bias=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=True)
        (7): ReLU(inplace=True)
        (8): Linear(in_features=256, out_features=2048, bias=True)
      )
      (contextformer): build_contextformer(
        (decoder1): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (decoder2): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (q_proj): Linear(in_features=256, out_features=768, bias=True)
        (kv_proj): Linear(in_features=1024, out_features=768, bias=True)
        (ln_mask): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (generator_pe): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
  )
  (sam): Sam(
    (image_encoder): TinyViT(
      (patch_embed): PatchEmbed(
        (seq): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU()
          (2): Conv2d_BN(
            (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layers): ModuleList(
        (0): ConvLayer(
          (blocks): ModuleList(
            (0): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
            (1): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (1): BasicLayer(
          dim=128, input_resolution=(128, 128), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (2): BasicLayer(
          dim=160, input_resolution=(64, 64), depth=6
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (3): BasicLayer(
          dim=320, input_resolution=(64, 64), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (neck): Sequential(
        (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): LayerNorm2d()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (3): LayerNorm2d()
      )
    )
    (prompt_encoder): PromptEncoder(
      (pe_layer): PositionEmbeddingRandom()
      (point_embeddings): ModuleList(
        (0): Embedding(1, 256)
        (1): Embedding(1, 256)
        (2): Embedding(1, 256)
        (3): Embedding(1, 256)
      )
      (not_a_point_embed): Embedding(1, 256)
      (mask_downscaling): Sequential(
        (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
        (4): LayerNorm2d()
        (5): GELU()
        (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (no_mask_embed): Embedding(1, 256)
    )
    (mask_decoder): MaskDecoder(
      (transformer): TwoWayTransformer(
        (layers): ModuleList(
          (0): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
          (1): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
        )
        (final_attn_token_to_image): Attention(
          (q_proj): Linear(in_features=256, out_features=128, bias=True)
          (k_proj): Linear(in_features=256, out_features=128, bias=True)
          (v_proj): Linear(in_features=256, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (iou_token): Embedding(1, 256)
      (mask_tokens): Embedding(4, 256)
      (output_upscaling): Sequential(
        (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
        (4): GELU()
      )
      (output_hypernetworks_mlps): ModuleList(
        (0): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (3): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
      )
      (iou_prediction_head): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
    )
  )
  (clip): CLIP(
    (visual): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
[12/07 20:14:46] detectron2 INFO: Optimized parameters:
{'backbone.fpn1.0.bias',
 'backbone.fpn1.0.weight',
 'backbone.fpn1.1.ln.bias',
 'backbone.fpn1.1.ln.weight',
 'backbone.fpn1.3.bias',
 'backbone.fpn1.3.weight',
 'backbone.fpn2.0.bias',
 'backbone.fpn2.0.weight',
 'context_former_pe',
 'proposal_generator.rpn_head.anchor_deltas.bias',
 'proposal_generator.rpn_head.anchor_deltas.weight',
 'proposal_generator.rpn_head.conv.bias',
 'proposal_generator.rpn_head.conv.weight',
 'proposal_generator.rpn_head.objectness_logits.bias',
 'proposal_generator.rpn_head.objectness_logits.weight',
 'roi_heads.box_head.fc1.bias',
 'roi_heads.box_head.fc1.weight',
 'roi_heads.box_head.fc2.bias',
 'roi_heads.box_head.fc2.weight',
 'roi_heads.box_predictor.bbox_pred.bias',
 'roi_heads.box_predictor.bbox_pred.weight',
 'roi_heads.box_predictor.cls_score.bias',
 'roi_heads.box_predictor.cls_score.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.norm.bias',
 'roi_heads.mask_head.contextformer.decoder1.norm.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.norm.bias',
 'roi_heads.mask_head.contextformer.decoder2.norm.weight',
 'roi_heads.mask_head.contextformer.kv_proj.bias',
 'roi_heads.mask_head.contextformer.kv_proj.weight',
 'roi_heads.mask_head.contextformer.ln_mask.bias',
 'roi_heads.mask_head.contextformer.ln_mask.weight',
 'roi_heads.mask_head.contextformer.logit_scale',
 'roi_heads.mask_head.contextformer.q_proj.bias',
 'roi_heads.mask_head.contextformer.q_proj.weight',
 'roi_heads.mask_head.point_emb.0.bias',
 'roi_heads.mask_head.point_emb.0.weight',
 'roi_heads.mask_head.point_emb.1.bias',
 'roi_heads.mask_head.point_emb.1.weight',
 'roi_heads.mask_head.point_emb.4.bias',
 'roi_heads.mask_head.point_emb.4.weight',
 'roi_heads.mask_head.point_emb.6.bias',
 'roi_heads.mask_head.point_emb.6.weight',
 'roi_heads.mask_head.point_emb.8.bias',
 'roi_heads.mask_head.point_emb.8.weight'}
[12/07 20:14:46] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from mobile_sam.pt ...
[12/07 20:14:46] fvcore.common.checkpoint INFO: [Checkpointer] Loading from mobile_sam.pt ...
[12/07 20:14:46] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule sam - Total num: 171
[12/07 20:14:46] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn1.0.{bias, weight}[0m
[34mbackbone.fpn1.1.ln.{bias, weight}[0m
[34mbackbone.fpn1.3.{bias, weight}[0m
[34mbackbone.fpn2.0.{bias, weight}[0m
[34mclip.ln_final.{bias, weight}[0m
[34mclip.token_embedding.weight[0m
[34mclip.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.conv1.weight[0m
[34mclip.visual.ln_post.{bias, weight}[0m
[34mclip.visual.ln_pre.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.{class_embedding, positional_embedding, proj}[0m
[34mclip.{logit_scale, positional_embedding, text_projection}[0m
[34mcontext_former_pe[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.kv_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.ln_mask.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.logit_scale[0m
[34mroi_heads.mask_head.contextformer.q_proj.{bias, weight}[0m
[34mroi_heads.mask_head.freq_weight[0m
[34mroi_heads.mask_head.point_emb.0.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.1.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.mask_head.point_emb.4.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.6.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.8.{bias, weight}[0m
[12/07 20:14:46] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mimage_encoder.head.{bias, weight}[0m
  [35mimage_encoder.norm_head.{bias, weight}[0m
[12/07 20:14:46] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeLongestSizeFlip(longest_length=1024), RandomFlip(prob=0.5)]
[12/07 20:14:57] d2.data.datasets.coco INFO: Loading datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json takes 11.17 seconds.
[12/07 20:14:59] d2.data.datasets.coco INFO: Loaded 107761 images in COCO format from datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json
[12/07 20:15:03] d2.data.build INFO: Removed 0 images with no usable annotations. 107761 images left.
[12/07 20:15:06] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 257253       |   bicycle    | 7056         |      car      | 43533        |
|  motorcycle   | 8654         |   airplane   | 0            |      bus      | 0            |
|     train     | 4570         |    truck     | 9970         |     boat      | 10576        |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 9820         |     bird      | 10542        |
|      cat      | 0            |     dog      | 0            |     horse     | 6567         |
|     sheep     | 9223         |     cow      | 0            |   elephant    | 0            |
|     bear      | 1294         |    zebra     | 5269         |    giraffe    | 5128         |
|   backpack    | 8714         |   umbrella   | 0            |    handbag    | 12342        |
|      tie      | 0            |   suitcase   | 6112         |    frisbee    | 2681         |
|     skis      | 6623         |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 8802         | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 6095         | tennis racket | 0            |
|    bottle     | 24070        |  wine glass  | 0            |      cup      | 0            |
|     fork      | 5474         |    knife     | 0            |     spoon     | 6159         |
|     bowl      | 14323        |    banana    | 9195         |     apple     | 5776         |
|   sandwich    | 4356         |    orange    | 6302         |   broccoli    | 7261         |
|    carrot     | 7758         |   hot dog    | 0            |     pizza     | 5807         |
|     donut     | 7005         |     cake     | 0            |     chair     | 38073        |
|     couch     | 0            | potted plant | 0            |      bed      | 4192         |
| dining table  | 0            |    toilet    | 4149         |      tv       | 5803         |
|    laptop     | 4960         |    mouse     | 2261         |    remote     | 5700         |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 1672         |
|     oven      | 3334         |   toaster    | 225          |     sink      | 0            |
| refrigerator  | 2634         |     book     | 24077        |     clock     | 6320         |
|     vase      | 6577         |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 1945         |               |              |
|     total     | 656232       |              |              |               |              |[0m
[12/07 20:15:06] d2.data.build INFO: Using training sampler TrainingSampler
[12/07 20:15:06] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 20:15:06] d2.data.common INFO: Serializing 107761 elements to byte tensors and concatenating them all ...
[12/07 20:15:08] d2.data.common INFO: Serialized dataset takes 361.37 MiB
[12/07 20:15:10] detectron2 INFO: Starting training from iteration 0
[12/07 20:18:55] detectron2 INFO: Rank of current process: 0. World size: 1
[12/07 20:18:55] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]
numpy                            1.23.4
detectron2                       0.6 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/detectron2
Compiler                         GCC 7.5
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3,4,5,6,7              NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   515.76
CUDA_HOME                        /home/xchen/cuda-11.4/
Pillow                           9.4.0
torchvision                      0.11.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/07 20:18:55] detectron2 INFO: Command line arguments: Namespace(config_file='configs/OpenDet_tiny_coco.yaml', dist_url='tcp://127.0.0.1:50165', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2', 'OUTPUT_DIR', '.output/test'], resume=False)
[12/07 20:18:55] detectron2 INFO: Contents of args.config_file=configs/OpenDet_tiny_coco.yaml:
[38;5;245m# _BASE_: "Base_OVCOCO_C4_1x.yaml"[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSamOpenDetector[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_sam_vit_det_backbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m#SAM vit_h[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mvit_t[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mViT-B/16[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcontext_former_pe[39m[38;5;186m'[39m[38;5;15m [39m[38;5;245m# unfrozen extra part of model, the name is relative to sam and clip[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmobile_sam.pt[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "/opt/tiger/OpenVo-Seg-master/output/wo_mask_with_prompt_encoder_roi_head_withgrad/model_final.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "sam_vit_h_4b8939.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "output/Detic-COCO/RSPrompter_anchor/model_0000999.pth"[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m4[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m16[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m32[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m64[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mLN[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m123.675[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m116.280[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m103.530[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m58.395[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.375[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDefaultAnchorGenerator[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m32[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m64[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m128[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m512[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1.0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m2.0[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m  [39m[38;5;245m# Three aspect ratios (same for all in feature maps)[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSAMRPN[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStandardRPNHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat0[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;245m# Detectron1 uses 2000 proposals per-batch,[39m
[38;5;15m    [39m[38;5;245m# (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)[39m
[38;5;15m    [39m[38;5;245m# which is approximately 1000 proposals per-image since the default batch size for FPN is 2.[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.3[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m0.7[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m[38;5;15m [39m[38;5;245m# the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbinary_ce[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m# options: centerness, binary_ce[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamAnchorPromptRoiHeads[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m[38;5;15m [39m[38;5;245m#the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m[38;5;15m  [39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mFastRCNNConvFCHead[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;245m# Shared2FCBBoxHead[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(10.0,[39m[38;5;141m [39m[38;5;141m10.0,[39m[38;5;141m [39m[38;5;141m5.0,[39m[38;5;141m [39m[38;5;141m5.0)[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamMaskHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mce_dice[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_zeroshot_train_oriorder",)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_not_zeroshot_val",)[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m [39m[38;5;245m# num_workers == batchsize_per_gpu[39m
[38;5;15m  [39m[38;5;245m# PERSISTENT_WORKERS: True [39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m  [39m[38;5;245m# change  # max 8 imgs per batch[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m[38;5;15m  [39m[38;5;245m# change0.000025[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(60000,[39m[38;5;141m [39m[38;5;141m80000)[39m[38;5;15m  [39m[38;5;245m# change [39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD [39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m[38;5;15m [39m[38;5;245m#1.0001[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mWarmupCosineLR[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;245m# LR_SCHEDULER_NAME: "WarmupMultiStepLR"[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m[38;5;15m  [39m[38;5;245m#  change[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mADAMW[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m[38;5;15m  [39m[38;5;245m# the output freq of logger writer[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(90,[39m[38;5;141m [39m[38;5;141m4)[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# PAD_MASK: True[39m
[38;5;15m  [39m[38;5;245m# MASK_PAD_VAL: 0.0[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbitmask[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m[38;5;15m  [39m[38;5;245m#test_topk_per_image[39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m[38;5;15m [39m[38;5;245m# change[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m[38;5;15m [39m[38;5;245m#every gpu has most 2 images  # change[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcls[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m./output/ovcoco[39m[38;5;186m'[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m

[12/07 20:18:55] detectron2 INFO: Running with full config:
[38;5;204mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;204mPERSISTENT_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_not_zeroshot_val[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_zeroshot_train_oriorder[39m
[38;5;204mFIND_UNUSED_PARAM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m  [39m[38;5;204mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbitmask[39m
[38;5;15m  [39m[38;5;204mMASK_PAD_VAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;204mPAD_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;204mSCALE_RANGE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;204mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcontext_former_pe[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mViT-B/16[39m
[38;5;15m    [39m[38;5;204mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_sam_vit_det_backbone[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvit_t[39m
[38;5;15m  [39m[38;5;204mCONFIGS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mONLY_DECODER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;204mINNER_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mLN[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mSELECTED_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m22[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m26[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m28[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30[39m
[38;5;15m    [39m[38;5;204mUP_SAMPLE_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSamOpenDetector[39m
[38;5;15m  [39m[38;5;204mNUM_SAMPLE_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m  [39m[38;5;204mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSAMRPN[39m
[38;5;15m  [39m[38;5;204mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;204mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;204mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;204mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFastRCNNConvFCHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamAnchorPromptRoiHeads[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m  [39m[38;5;204mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mce_dice[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamMaskHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;204mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat0[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbinary_ce[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAM_FROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSemSegFPNHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m54[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmobile_sam.pt[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m.output/test[39m
[38;5;204mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m
[38;5;15m  [39m[38;5;204mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;204mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvalue[39m
[38;5;15m    [39m[38;5;204mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupCosineLR[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;204mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m80000[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;204mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m  [39m[38;5;204mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcls[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m

[12/07 20:18:55] detectron2 INFO: Full config saved to .output/test/config.yaml
[12/07 20:18:56] d2.utils.env INFO: Using a generated random seed 57248454
[12/07 20:19:07] detectron2 INFO: Model:
SamOpenDetector(
  (backbone): SAMVitDet(
    (fpn1): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (1): Norm2d(
        (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): GELU()
      (3): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn2): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn3): Identity()
    (fpn4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (proposal_generator): SAMRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): samAnchorPromptRoiHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): SamRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): samMaskHead(
      (point_emb): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Flatten(start_dim=1, end_dim=-1)
        (4): Linear(in_features=12544, out_features=256, bias=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=True)
        (7): ReLU(inplace=True)
        (8): Linear(in_features=256, out_features=2048, bias=True)
      )
      (contextformer): build_contextformer(
        (decoder1): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (decoder2): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
              )
              (linear1): Linear(in_features=768, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=768, bias=True)
              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (q_proj): Linear(in_features=256, out_features=768, bias=True)
        (kv_proj): Linear(in_features=1024, out_features=768, bias=True)
        (visual_proj): Linear(in_features=512, out_features=768, bias=True)
        (ln_mask): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (generator_pe): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
  )
  (sam): Sam(
    (image_encoder): TinyViT(
      (patch_embed): PatchEmbed(
        (seq): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU()
          (2): Conv2d_BN(
            (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layers): ModuleList(
        (0): ConvLayer(
          (blocks): ModuleList(
            (0): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
            (1): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (1): BasicLayer(
          dim=128, input_resolution=(128, 128), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (2): BasicLayer(
          dim=160, input_resolution=(64, 64), depth=6
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (3): BasicLayer(
          dim=320, input_resolution=(64, 64), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (neck): Sequential(
        (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): LayerNorm2d()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (3): LayerNorm2d()
      )
    )
    (prompt_encoder): PromptEncoder(
      (pe_layer): PositionEmbeddingRandom()
      (point_embeddings): ModuleList(
        (0): Embedding(1, 256)
        (1): Embedding(1, 256)
        (2): Embedding(1, 256)
        (3): Embedding(1, 256)
      )
      (not_a_point_embed): Embedding(1, 256)
      (mask_downscaling): Sequential(
        (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
        (4): LayerNorm2d()
        (5): GELU()
        (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (no_mask_embed): Embedding(1, 256)
    )
    (mask_decoder): MaskDecoder(
      (transformer): TwoWayTransformer(
        (layers): ModuleList(
          (0): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
          (1): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
        )
        (final_attn_token_to_image): Attention(
          (q_proj): Linear(in_features=256, out_features=128, bias=True)
          (k_proj): Linear(in_features=256, out_features=128, bias=True)
          (v_proj): Linear(in_features=256, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (iou_token): Embedding(1, 256)
      (mask_tokens): Embedding(4, 256)
      (output_upscaling): Sequential(
        (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
        (4): GELU()
      )
      (output_hypernetworks_mlps): ModuleList(
        (0): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (3): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
      )
      (iou_prediction_head): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
    )
  )
  (clip): CLIP(
    (visual): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
[12/07 20:19:07] detectron2 INFO: Optimized parameters:
{'backbone.fpn1.0.bias',
 'backbone.fpn1.0.weight',
 'backbone.fpn1.1.ln.bias',
 'backbone.fpn1.1.ln.weight',
 'backbone.fpn1.3.bias',
 'backbone.fpn1.3.weight',
 'backbone.fpn2.0.bias',
 'backbone.fpn2.0.weight',
 'context_former_pe',
 'proposal_generator.rpn_head.anchor_deltas.bias',
 'proposal_generator.rpn_head.anchor_deltas.weight',
 'proposal_generator.rpn_head.conv.bias',
 'proposal_generator.rpn_head.conv.weight',
 'proposal_generator.rpn_head.objectness_logits.bias',
 'proposal_generator.rpn_head.objectness_logits.weight',
 'roi_heads.box_head.fc1.bias',
 'roi_heads.box_head.fc1.weight',
 'roi_heads.box_head.fc2.bias',
 'roi_heads.box_head.fc2.weight',
 'roi_heads.box_predictor.bbox_pred.bias',
 'roi_heads.box_predictor.bbox_pred.weight',
 'roi_heads.box_predictor.cls_score.bias',
 'roi_heads.box_predictor.cls_score.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.norm.bias',
 'roi_heads.mask_head.contextformer.decoder1.norm.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.norm.bias',
 'roi_heads.mask_head.contextformer.decoder2.norm.weight',
 'roi_heads.mask_head.contextformer.kv_proj.bias',
 'roi_heads.mask_head.contextformer.kv_proj.weight',
 'roi_heads.mask_head.contextformer.ln_mask.bias',
 'roi_heads.mask_head.contextformer.ln_mask.weight',
 'roi_heads.mask_head.contextformer.logit_scale',
 'roi_heads.mask_head.contextformer.q_proj.bias',
 'roi_heads.mask_head.contextformer.q_proj.weight',
 'roi_heads.mask_head.contextformer.visual_proj.bias',
 'roi_heads.mask_head.contextformer.visual_proj.weight',
 'roi_heads.mask_head.point_emb.0.bias',
 'roi_heads.mask_head.point_emb.0.weight',
 'roi_heads.mask_head.point_emb.1.bias',
 'roi_heads.mask_head.point_emb.1.weight',
 'roi_heads.mask_head.point_emb.4.bias',
 'roi_heads.mask_head.point_emb.4.weight',
 'roi_heads.mask_head.point_emb.6.bias',
 'roi_heads.mask_head.point_emb.6.weight',
 'roi_heads.mask_head.point_emb.8.bias',
 'roi_heads.mask_head.point_emb.8.weight'}
[12/07 20:19:07] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from mobile_sam.pt ...
[12/07 20:19:07] fvcore.common.checkpoint INFO: [Checkpointer] Loading from mobile_sam.pt ...
[12/07 20:19:07] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule sam - Total num: 171
[12/07 20:19:07] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn1.0.{bias, weight}[0m
[34mbackbone.fpn1.1.ln.{bias, weight}[0m
[34mbackbone.fpn1.3.{bias, weight}[0m
[34mbackbone.fpn2.0.{bias, weight}[0m
[34mclip.ln_final.{bias, weight}[0m
[34mclip.token_embedding.weight[0m
[34mclip.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.conv1.weight[0m
[34mclip.visual.ln_post.{bias, weight}[0m
[34mclip.visual.ln_pre.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.{class_embedding, positional_embedding, proj}[0m
[34mclip.{logit_scale, positional_embedding, text_projection}[0m
[34mcontext_former_pe[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.kv_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.ln_mask.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.logit_scale[0m
[34mroi_heads.mask_head.contextformer.q_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.visual_proj.{bias, weight}[0m
[34mroi_heads.mask_head.freq_weight[0m
[34mroi_heads.mask_head.point_emb.0.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.1.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.mask_head.point_emb.4.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.6.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.8.{bias, weight}[0m
[12/07 20:19:07] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mimage_encoder.head.{bias, weight}[0m
  [35mimage_encoder.norm_head.{bias, weight}[0m
[12/07 20:19:07] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeLongestSizeFlip(longest_length=1024), RandomFlip(prob=0.5)]
[12/07 20:19:18] d2.data.datasets.coco INFO: Loading datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json takes 11.12 seconds.
[12/07 20:19:20] d2.data.datasets.coco INFO: Loaded 107761 images in COCO format from datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json
[12/07 20:19:24] d2.data.build INFO: Removed 0 images with no usable annotations. 107761 images left.
[12/07 20:19:27] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 257253       |   bicycle    | 7056         |      car      | 43533        |
|  motorcycle   | 8654         |   airplane   | 0            |      bus      | 0            |
|     train     | 4570         |    truck     | 9970         |     boat      | 10576        |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 9820         |     bird      | 10542        |
|      cat      | 0            |     dog      | 0            |     horse     | 6567         |
|     sheep     | 9223         |     cow      | 0            |   elephant    | 0            |
|     bear      | 1294         |    zebra     | 5269         |    giraffe    | 5128         |
|   backpack    | 8714         |   umbrella   | 0            |    handbag    | 12342        |
|      tie      | 0            |   suitcase   | 6112         |    frisbee    | 2681         |
|     skis      | 6623         |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 8802         | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 6095         | tennis racket | 0            |
|    bottle     | 24070        |  wine glass  | 0            |      cup      | 0            |
|     fork      | 5474         |    knife     | 0            |     spoon     | 6159         |
|     bowl      | 14323        |    banana    | 9195         |     apple     | 5776         |
|   sandwich    | 4356         |    orange    | 6302         |   broccoli    | 7261         |
|    carrot     | 7758         |   hot dog    | 0            |     pizza     | 5807         |
|     donut     | 7005         |     cake     | 0            |     chair     | 38073        |
|     couch     | 0            | potted plant | 0            |      bed      | 4192         |
| dining table  | 0            |    toilet    | 4149         |      tv       | 5803         |
|    laptop     | 4960         |    mouse     | 2261         |    remote     | 5700         |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 1672         |
|     oven      | 3334         |   toaster    | 225          |     sink      | 0            |
| refrigerator  | 2634         |     book     | 24077        |     clock     | 6320         |
|     vase      | 6577         |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 1945         |               |              |
|     total     | 656232       |              |              |               |              |[0m
[12/07 20:19:27] d2.data.build INFO: Using training sampler TrainingSampler
[12/07 20:19:27] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 20:19:27] d2.data.common INFO: Serializing 107761 elements to byte tensors and concatenating them all ...
[12/07 20:19:30] d2.data.common INFO: Serialized dataset takes 361.37 MiB
[12/07 20:19:31] detectron2 INFO: Starting training from iteration 0
[12/07 20:31:26] detectron2 INFO: Rank of current process: 0. World size: 1
[12/07 20:31:26] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]
numpy                            1.23.4
detectron2                       0.6 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/detectron2
Compiler                         GCC 7.5
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3,4,5,6,7              NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   515.76
CUDA_HOME                        /home/xchen/cuda-11.4/
Pillow                           9.4.0
torchvision                      0.11.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/07 20:31:26] detectron2 INFO: Command line arguments: Namespace(config_file='configs/OpenDet_tiny_coco.yaml', dist_url='tcp://127.0.0.1:50165', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2', 'OUTPUT_DIR', '.output/test'], resume=False)
[12/07 20:31:26] detectron2 INFO: Contents of args.config_file=configs/OpenDet_tiny_coco.yaml:
[38;5;245m# _BASE_: "Base_OVCOCO_C4_1x.yaml"[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSamOpenDetector[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_sam_vit_det_backbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m#SAM vit_h[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mvit_t[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mViT-B/16[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcontext_former_pe[39m[38;5;186m'[39m[38;5;15m [39m[38;5;245m# unfrozen extra part of model, the name is relative to sam and clip[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmobile_sam.pt[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "/opt/tiger/OpenVo-Seg-master/output/wo_mask_with_prompt_encoder_roi_head_withgrad/model_final.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "sam_vit_h_4b8939.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "output/Detic-COCO/RSPrompter_anchor/model_0000999.pth"[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m4[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m16[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m32[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m64[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mLN[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m123.675[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m116.280[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m103.530[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m58.395[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.375[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDefaultAnchorGenerator[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m32[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m64[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m128[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m512[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1.0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m2.0[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m  [39m[38;5;245m# Three aspect ratios (same for all in feature maps)[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSAMRPN[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStandardRPNHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat0[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;245m# Detectron1 uses 2000 proposals per-batch,[39m
[38;5;15m    [39m[38;5;245m# (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)[39m
[38;5;15m    [39m[38;5;245m# which is approximately 1000 proposals per-image since the default batch size for FPN is 2.[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.3[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m0.7[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m[38;5;15m [39m[38;5;245m# the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbinary_ce[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m# options: centerness, binary_ce[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamAnchorPromptRoiHeads[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m[38;5;15m [39m[38;5;245m#the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m[38;5;15m  [39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mFastRCNNConvFCHead[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;245m# Shared2FCBBoxHead[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(10.0,[39m[38;5;141m [39m[38;5;141m10.0,[39m[38;5;141m [39m[38;5;141m5.0,[39m[38;5;141m [39m[38;5;141m5.0)[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamMaskHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mce_dice[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_zeroshot_train_oriorder",)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_not_zeroshot_val",)[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m [39m[38;5;245m# num_workers == batchsize_per_gpu[39m
[38;5;15m  [39m[38;5;245m# PERSISTENT_WORKERS: True [39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m  [39m[38;5;245m# change  # max 8 imgs per batch[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m[38;5;15m  [39m[38;5;245m# change0.000025[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(60000,[39m[38;5;141m [39m[38;5;141m80000)[39m[38;5;15m  [39m[38;5;245m# change [39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD [39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m[38;5;15m [39m[38;5;245m#1.0001[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mWarmupCosineLR[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;245m# LR_SCHEDULER_NAME: "WarmupMultiStepLR"[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m[38;5;15m  [39m[38;5;245m#  change[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mADAMW[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m[38;5;15m  [39m[38;5;245m# the output freq of logger writer[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(90,[39m[38;5;141m [39m[38;5;141m4)[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# PAD_MASK: True[39m
[38;5;15m  [39m[38;5;245m# MASK_PAD_VAL: 0.0[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbitmask[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m[38;5;15m  [39m[38;5;245m#test_topk_per_image[39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m[38;5;15m [39m[38;5;245m# change[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m[38;5;15m [39m[38;5;245m#every gpu has most 2 images  # change[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcls[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m./output/ovcoco[39m[38;5;186m'[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m

[12/07 20:31:26] detectron2 INFO: Running with full config:
[38;5;204mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;204mPERSISTENT_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_not_zeroshot_val[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_zeroshot_train_oriorder[39m
[38;5;204mFIND_UNUSED_PARAM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m  [39m[38;5;204mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbitmask[39m
[38;5;15m  [39m[38;5;204mMASK_PAD_VAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;204mPAD_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;204mSCALE_RANGE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;204mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcontext_former_pe[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mViT-B/16[39m
[38;5;15m    [39m[38;5;204mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_sam_vit_det_backbone[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvit_t[39m
[38;5;15m  [39m[38;5;204mCONFIGS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mONLY_DECODER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;204mINNER_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mLN[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mSELECTED_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m22[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m26[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m28[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30[39m
[38;5;15m    [39m[38;5;204mUP_SAMPLE_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSamOpenDetector[39m
[38;5;15m  [39m[38;5;204mNUM_SAMPLE_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m  [39m[38;5;204mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSAMRPN[39m
[38;5;15m  [39m[38;5;204mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;204mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;204mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;204mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFastRCNNConvFCHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamAnchorPromptRoiHeads[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m  [39m[38;5;204mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mce_dice[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamMaskHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;204mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat0[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbinary_ce[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAM_FROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSemSegFPNHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m54[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmobile_sam.pt[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m.output/test[39m
[38;5;204mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m
[38;5;15m  [39m[38;5;204mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;204mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvalue[39m
[38;5;15m    [39m[38;5;204mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupCosineLR[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;204mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m80000[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;204mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m  [39m[38;5;204mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcls[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m

[12/07 20:31:26] detectron2 INFO: Full config saved to .output/test/config.yaml
[12/07 20:31:26] d2.utils.env INFO: Using a generated random seed 27936723
[12/07 20:31:37] detectron2 INFO: Model:
SamOpenDetector(
  (backbone): SAMVitDet(
    (fpn1): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (1): Norm2d(
        (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): GELU()
      (3): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn2): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn3): Identity()
    (fpn4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (proposal_generator): SAMRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): samAnchorPromptRoiHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): SamRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): samMaskHead(
      (point_emb): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Flatten(start_dim=1, end_dim=-1)
        (4): Linear(in_features=12544, out_features=256, bias=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=True)
        (7): ReLU(inplace=True)
        (8): Linear(in_features=256, out_features=2048, bias=True)
      )
      (contextformer): build_contextformer(
        (decoder1): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (linear1): Linear(in_features=512, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=512, bias=True)
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (linear1): Linear(in_features=512, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=512, bias=True)
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (linear1): Linear(in_features=512, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=512, bias=True)
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (decoder2): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (linear1): Linear(in_features=512, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=512, bias=True)
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (linear1): Linear(in_features=512, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=512, bias=True)
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (linear1): Linear(in_features=512, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=512, bias=True)
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (q_proj): Linear(in_features=256, out_features=512, bias=True)
        (kv_proj): Linear(in_features=1024, out_features=512, bias=True)
        (ln_mask): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (generator_pe): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
  )
  (sam): Sam(
    (image_encoder): TinyViT(
      (patch_embed): PatchEmbed(
        (seq): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU()
          (2): Conv2d_BN(
            (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layers): ModuleList(
        (0): ConvLayer(
          (blocks): ModuleList(
            (0): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
            (1): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (1): BasicLayer(
          dim=128, input_resolution=(128, 128), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (2): BasicLayer(
          dim=160, input_resolution=(64, 64), depth=6
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (3): BasicLayer(
          dim=320, input_resolution=(64, 64), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (neck): Sequential(
        (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): LayerNorm2d()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (3): LayerNorm2d()
      )
    )
    (prompt_encoder): PromptEncoder(
      (pe_layer): PositionEmbeddingRandom()
      (point_embeddings): ModuleList(
        (0): Embedding(1, 256)
        (1): Embedding(1, 256)
        (2): Embedding(1, 256)
        (3): Embedding(1, 256)
      )
      (not_a_point_embed): Embedding(1, 256)
      (mask_downscaling): Sequential(
        (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
        (4): LayerNorm2d()
        (5): GELU()
        (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (no_mask_embed): Embedding(1, 256)
    )
    (mask_decoder): MaskDecoder(
      (transformer): TwoWayTransformer(
        (layers): ModuleList(
          (0): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
          (1): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
        )
        (final_attn_token_to_image): Attention(
          (q_proj): Linear(in_features=256, out_features=128, bias=True)
          (k_proj): Linear(in_features=256, out_features=128, bias=True)
          (v_proj): Linear(in_features=256, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (iou_token): Embedding(1, 256)
      (mask_tokens): Embedding(4, 256)
      (output_upscaling): Sequential(
        (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
        (4): GELU()
      )
      (output_hypernetworks_mlps): ModuleList(
        (0): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (3): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
      )
      (iou_prediction_head): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
    )
  )
  (clip): CLIP(
    (visual): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
[12/07 20:31:37] detectron2 INFO: Optimized parameters:
{'backbone.fpn1.0.bias',
 'backbone.fpn1.0.weight',
 'backbone.fpn1.1.ln.bias',
 'backbone.fpn1.1.ln.weight',
 'backbone.fpn1.3.bias',
 'backbone.fpn1.3.weight',
 'backbone.fpn2.0.bias',
 'backbone.fpn2.0.weight',
 'context_former_pe',
 'proposal_generator.rpn_head.anchor_deltas.bias',
 'proposal_generator.rpn_head.anchor_deltas.weight',
 'proposal_generator.rpn_head.conv.bias',
 'proposal_generator.rpn_head.conv.weight',
 'proposal_generator.rpn_head.objectness_logits.bias',
 'proposal_generator.rpn_head.objectness_logits.weight',
 'roi_heads.box_head.fc1.bias',
 'roi_heads.box_head.fc1.weight',
 'roi_heads.box_head.fc2.bias',
 'roi_heads.box_head.fc2.weight',
 'roi_heads.box_predictor.bbox_pred.bias',
 'roi_heads.box_predictor.bbox_pred.weight',
 'roi_heads.box_predictor.cls_score.bias',
 'roi_heads.box_predictor.cls_score.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.norm.bias',
 'roi_heads.mask_head.contextformer.decoder1.norm.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.norm.bias',
 'roi_heads.mask_head.contextformer.decoder2.norm.weight',
 'roi_heads.mask_head.contextformer.kv_proj.bias',
 'roi_heads.mask_head.contextformer.kv_proj.weight',
 'roi_heads.mask_head.contextformer.ln_mask.bias',
 'roi_heads.mask_head.contextformer.ln_mask.weight',
 'roi_heads.mask_head.contextformer.logit_scale',
 'roi_heads.mask_head.contextformer.q_proj.bias',
 'roi_heads.mask_head.contextformer.q_proj.weight',
 'roi_heads.mask_head.point_emb.0.bias',
 'roi_heads.mask_head.point_emb.0.weight',
 'roi_heads.mask_head.point_emb.1.bias',
 'roi_heads.mask_head.point_emb.1.weight',
 'roi_heads.mask_head.point_emb.4.bias',
 'roi_heads.mask_head.point_emb.4.weight',
 'roi_heads.mask_head.point_emb.6.bias',
 'roi_heads.mask_head.point_emb.6.weight',
 'roi_heads.mask_head.point_emb.8.bias',
 'roi_heads.mask_head.point_emb.8.weight'}
[12/07 20:31:37] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from mobile_sam.pt ...
[12/07 20:31:37] fvcore.common.checkpoint INFO: [Checkpointer] Loading from mobile_sam.pt ...
[12/07 20:31:37] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule sam - Total num: 171
[12/07 20:31:37] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn1.0.{bias, weight}[0m
[34mbackbone.fpn1.1.ln.{bias, weight}[0m
[34mbackbone.fpn1.3.{bias, weight}[0m
[34mbackbone.fpn2.0.{bias, weight}[0m
[34mclip.ln_final.{bias, weight}[0m
[34mclip.token_embedding.weight[0m
[34mclip.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.conv1.weight[0m
[34mclip.visual.ln_post.{bias, weight}[0m
[34mclip.visual.ln_pre.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.{class_embedding, positional_embedding, proj}[0m
[34mclip.{logit_scale, positional_embedding, text_projection}[0m
[34mcontext_former_pe[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.kv_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.ln_mask.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.logit_scale[0m
[34mroi_heads.mask_head.contextformer.q_proj.{bias, weight}[0m
[34mroi_heads.mask_head.freq_weight[0m
[34mroi_heads.mask_head.point_emb.0.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.1.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.mask_head.point_emb.4.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.6.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.8.{bias, weight}[0m
[12/07 20:31:37] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mimage_encoder.head.{bias, weight}[0m
  [35mimage_encoder.norm_head.{bias, weight}[0m
[12/07 20:31:37] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeLongestSizeFlip(longest_length=1024), RandomFlip(prob=0.5)]
[12/07 20:31:48] d2.data.datasets.coco INFO: Loading datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json takes 10.91 seconds.
[12/07 20:31:50] d2.data.datasets.coco INFO: Loaded 107761 images in COCO format from datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json
[12/07 20:31:54] d2.data.build INFO: Removed 0 images with no usable annotations. 107761 images left.
[12/07 20:31:57] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 257253       |   bicycle    | 7056         |      car      | 43533        |
|  motorcycle   | 8654         |   airplane   | 0            |      bus      | 0            |
|     train     | 4570         |    truck     | 9970         |     boat      | 10576        |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 9820         |     bird      | 10542        |
|      cat      | 0            |     dog      | 0            |     horse     | 6567         |
|     sheep     | 9223         |     cow      | 0            |   elephant    | 0            |
|     bear      | 1294         |    zebra     | 5269         |    giraffe    | 5128         |
|   backpack    | 8714         |   umbrella   | 0            |    handbag    | 12342        |
|      tie      | 0            |   suitcase   | 6112         |    frisbee    | 2681         |
|     skis      | 6623         |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 8802         | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 6095         | tennis racket | 0            |
|    bottle     | 24070        |  wine glass  | 0            |      cup      | 0            |
|     fork      | 5474         |    knife     | 0            |     spoon     | 6159         |
|     bowl      | 14323        |    banana    | 9195         |     apple     | 5776         |
|   sandwich    | 4356         |    orange    | 6302         |   broccoli    | 7261         |
|    carrot     | 7758         |   hot dog    | 0            |     pizza     | 5807         |
|     donut     | 7005         |     cake     | 0            |     chair     | 38073        |
|     couch     | 0            | potted plant | 0            |      bed      | 4192         |
| dining table  | 0            |    toilet    | 4149         |      tv       | 5803         |
|    laptop     | 4960         |    mouse     | 2261         |    remote     | 5700         |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 1672         |
|     oven      | 3334         |   toaster    | 225          |     sink      | 0            |
| refrigerator  | 2634         |     book     | 24077        |     clock     | 6320         |
|     vase      | 6577         |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 1945         |               |              |
|     total     | 656232       |              |              |               |              |[0m
[12/07 20:31:57] d2.data.build INFO: Using training sampler TrainingSampler
[12/07 20:31:57] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 20:31:57] d2.data.common INFO: Serializing 107761 elements to byte tensors and concatenating them all ...
[12/07 20:31:59] d2.data.common INFO: Serialized dataset takes 361.37 MiB
[12/07 20:32:00] detectron2 INFO: Starting training from iteration 0
[12/07 20:33:50] detectron2 INFO: Rank of current process: 0. World size: 1
[12/07 20:33:50] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]
numpy                            1.23.4
detectron2                       0.6 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/detectron2
Compiler                         GCC 7.5
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3,4,5,6,7              NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   515.76
CUDA_HOME                        /home/xchen/cuda-11.4/
Pillow                           9.4.0
torchvision                      0.11.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/07 20:33:50] detectron2 INFO: Command line arguments: Namespace(config_file='configs/OpenDet_tiny_coco.yaml', dist_url='tcp://127.0.0.1:50165', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2', 'OUTPUT_DIR', '.output/test'], resume=False)
[12/07 20:33:50] detectron2 INFO: Contents of args.config_file=configs/OpenDet_tiny_coco.yaml:
[38;5;245m# _BASE_: "Base_OVCOCO_C4_1x.yaml"[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSamOpenDetector[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_sam_vit_det_backbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m#SAM vit_h[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mvit_t[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mViT-B/16[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcontext_former_pe[39m[38;5;186m'[39m[38;5;15m [39m[38;5;245m# unfrozen extra part of model, the name is relative to sam and clip[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmobile_sam.pt[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "/opt/tiger/OpenVo-Seg-master/output/wo_mask_with_prompt_encoder_roi_head_withgrad/model_final.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "sam_vit_h_4b8939.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "output/Detic-COCO/RSPrompter_anchor/model_0000999.pth"[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m4[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m16[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m32[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m64[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mLN[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m123.675[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m116.280[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m103.530[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m58.395[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.375[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDefaultAnchorGenerator[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m32[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m64[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m128[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m512[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1.0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m2.0[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m  [39m[38;5;245m# Three aspect ratios (same for all in feature maps)[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSAMRPN[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStandardRPNHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat0[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;245m# Detectron1 uses 2000 proposals per-batch,[39m
[38;5;15m    [39m[38;5;245m# (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)[39m
[38;5;15m    [39m[38;5;245m# which is approximately 1000 proposals per-image since the default batch size for FPN is 2.[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.3[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m0.7[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m[38;5;15m [39m[38;5;245m# the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbinary_ce[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m# options: centerness, binary_ce[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamAnchorPromptRoiHeads[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m[38;5;15m [39m[38;5;245m#the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m[38;5;15m  [39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mFastRCNNConvFCHead[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;245m# Shared2FCBBoxHead[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(10.0,[39m[38;5;141m [39m[38;5;141m10.0,[39m[38;5;141m [39m[38;5;141m5.0,[39m[38;5;141m [39m[38;5;141m5.0)[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamMaskHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mce_dice[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_zeroshot_train_oriorder",)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_not_zeroshot_val",)[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m [39m[38;5;245m# num_workers == batchsize_per_gpu[39m
[38;5;15m  [39m[38;5;245m# PERSISTENT_WORKERS: True [39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m  [39m[38;5;245m# change  # max 8 imgs per batch[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m[38;5;15m  [39m[38;5;245m# change0.000025[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(60000,[39m[38;5;141m [39m[38;5;141m80000)[39m[38;5;15m  [39m[38;5;245m# change [39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD [39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m[38;5;15m [39m[38;5;245m#1.0001[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mWarmupCosineLR[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;245m# LR_SCHEDULER_NAME: "WarmupMultiStepLR"[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m[38;5;15m  [39m[38;5;245m#  change[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mADAMW[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m[38;5;15m  [39m[38;5;245m# the output freq of logger writer[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(90,[39m[38;5;141m [39m[38;5;141m4)[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# PAD_MASK: True[39m
[38;5;15m  [39m[38;5;245m# MASK_PAD_VAL: 0.0[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbitmask[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m[38;5;15m  [39m[38;5;245m#test_topk_per_image[39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m[38;5;15m [39m[38;5;245m# change[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m[38;5;15m [39m[38;5;245m#every gpu has most 2 images  # change[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcls[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m./output/ovcoco[39m[38;5;186m'[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m

[12/07 20:33:50] detectron2 INFO: Running with full config:
[38;5;204mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;204mPERSISTENT_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_not_zeroshot_val[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_zeroshot_train_oriorder[39m
[38;5;204mFIND_UNUSED_PARAM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m  [39m[38;5;204mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbitmask[39m
[38;5;15m  [39m[38;5;204mMASK_PAD_VAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;204mPAD_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;204mSCALE_RANGE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;204mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcontext_former_pe[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mViT-B/16[39m
[38;5;15m    [39m[38;5;204mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_sam_vit_det_backbone[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvit_t[39m
[38;5;15m  [39m[38;5;204mCONFIGS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mONLY_DECODER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;204mINNER_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mLN[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mSELECTED_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m22[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m26[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m28[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30[39m
[38;5;15m    [39m[38;5;204mUP_SAMPLE_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSamOpenDetector[39m
[38;5;15m  [39m[38;5;204mNUM_SAMPLE_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m  [39m[38;5;204mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSAMRPN[39m
[38;5;15m  [39m[38;5;204mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;204mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;204mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;204mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFastRCNNConvFCHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamAnchorPromptRoiHeads[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m  [39m[38;5;204mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mce_dice[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamMaskHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;204mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat0[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbinary_ce[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAM_FROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSemSegFPNHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m54[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmobile_sam.pt[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m.output/test[39m
[38;5;204mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m
[38;5;15m  [39m[38;5;204mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;204mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvalue[39m
[38;5;15m    [39m[38;5;204mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupCosineLR[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;204mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m80000[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;204mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m  [39m[38;5;204mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcls[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m

[12/07 20:33:50] detectron2 INFO: Full config saved to .output/test/config.yaml
[12/07 20:33:50] d2.utils.env INFO: Using a generated random seed 51969112
[12/07 20:34:01] detectron2 INFO: Model:
SamOpenDetector(
  (backbone): SAMVitDet(
    (fpn1): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (1): Norm2d(
        (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): GELU()
      (3): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn2): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn3): Identity()
    (fpn4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (proposal_generator): SAMRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): samAnchorPromptRoiHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): SamRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): samMaskHead(
      (point_emb): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Flatten(start_dim=1, end_dim=-1)
        (4): Linear(in_features=12544, out_features=256, bias=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=True)
        (7): ReLU(inplace=True)
        (8): Linear(in_features=256, out_features=2048, bias=True)
      )
      (contextformer): build_contextformer(
        (decoder1): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (linear1): Linear(in_features=512, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=512, bias=True)
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (linear1): Linear(in_features=512, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=512, bias=True)
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (linear1): Linear(in_features=512, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=512, bias=True)
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (decoder2): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (linear1): Linear(in_features=512, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=512, bias=True)
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (linear1): Linear(in_features=512, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=512, bias=True)
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (linear1): Linear(in_features=512, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=512, bias=True)
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (q_proj): Linear(in_features=256, out_features=512, bias=True)
        (kv_proj): Linear(in_features=1024, out_features=512, bias=True)
        (ln_mask): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (generator_pe): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
  )
  (sam): Sam(
    (image_encoder): TinyViT(
      (patch_embed): PatchEmbed(
        (seq): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU()
          (2): Conv2d_BN(
            (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layers): ModuleList(
        (0): ConvLayer(
          (blocks): ModuleList(
            (0): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
            (1): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (1): BasicLayer(
          dim=128, input_resolution=(128, 128), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (2): BasicLayer(
          dim=160, input_resolution=(64, 64), depth=6
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (3): BasicLayer(
          dim=320, input_resolution=(64, 64), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (neck): Sequential(
        (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): LayerNorm2d()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (3): LayerNorm2d()
      )
    )
    (prompt_encoder): PromptEncoder(
      (pe_layer): PositionEmbeddingRandom()
      (point_embeddings): ModuleList(
        (0): Embedding(1, 256)
        (1): Embedding(1, 256)
        (2): Embedding(1, 256)
        (3): Embedding(1, 256)
      )
      (not_a_point_embed): Embedding(1, 256)
      (mask_downscaling): Sequential(
        (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
        (4): LayerNorm2d()
        (5): GELU()
        (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (no_mask_embed): Embedding(1, 256)
    )
    (mask_decoder): MaskDecoder(
      (transformer): TwoWayTransformer(
        (layers): ModuleList(
          (0): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
          (1): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
        )
        (final_attn_token_to_image): Attention(
          (q_proj): Linear(in_features=256, out_features=128, bias=True)
          (k_proj): Linear(in_features=256, out_features=128, bias=True)
          (v_proj): Linear(in_features=256, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (iou_token): Embedding(1, 256)
      (mask_tokens): Embedding(4, 256)
      (output_upscaling): Sequential(
        (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
        (4): GELU()
      )
      (output_hypernetworks_mlps): ModuleList(
        (0): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (3): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
      )
      (iou_prediction_head): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
    )
  )
  (clip): CLIP(
    (visual): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
[12/07 20:34:01] detectron2 INFO: Optimized parameters:
{'backbone.fpn1.0.bias',
 'backbone.fpn1.0.weight',
 'backbone.fpn1.1.ln.bias',
 'backbone.fpn1.1.ln.weight',
 'backbone.fpn1.3.bias',
 'backbone.fpn1.3.weight',
 'backbone.fpn2.0.bias',
 'backbone.fpn2.0.weight',
 'context_former_pe',
 'proposal_generator.rpn_head.anchor_deltas.bias',
 'proposal_generator.rpn_head.anchor_deltas.weight',
 'proposal_generator.rpn_head.conv.bias',
 'proposal_generator.rpn_head.conv.weight',
 'proposal_generator.rpn_head.objectness_logits.bias',
 'proposal_generator.rpn_head.objectness_logits.weight',
 'roi_heads.box_head.fc1.bias',
 'roi_heads.box_head.fc1.weight',
 'roi_heads.box_head.fc2.bias',
 'roi_heads.box_head.fc2.weight',
 'roi_heads.box_predictor.bbox_pred.bias',
 'roi_heads.box_predictor.bbox_pred.weight',
 'roi_heads.box_predictor.cls_score.bias',
 'roi_heads.box_predictor.cls_score.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.norm.bias',
 'roi_heads.mask_head.contextformer.decoder1.norm.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.norm.bias',
 'roi_heads.mask_head.contextformer.decoder2.norm.weight',
 'roi_heads.mask_head.contextformer.kv_proj.bias',
 'roi_heads.mask_head.contextformer.kv_proj.weight',
 'roi_heads.mask_head.contextformer.ln_mask.bias',
 'roi_heads.mask_head.contextformer.ln_mask.weight',
 'roi_heads.mask_head.contextformer.logit_scale',
 'roi_heads.mask_head.contextformer.q_proj.bias',
 'roi_heads.mask_head.contextformer.q_proj.weight',
 'roi_heads.mask_head.point_emb.0.bias',
 'roi_heads.mask_head.point_emb.0.weight',
 'roi_heads.mask_head.point_emb.1.bias',
 'roi_heads.mask_head.point_emb.1.weight',
 'roi_heads.mask_head.point_emb.4.bias',
 'roi_heads.mask_head.point_emb.4.weight',
 'roi_heads.mask_head.point_emb.6.bias',
 'roi_heads.mask_head.point_emb.6.weight',
 'roi_heads.mask_head.point_emb.8.bias',
 'roi_heads.mask_head.point_emb.8.weight'}
[12/07 20:34:01] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from mobile_sam.pt ...
[12/07 20:34:01] fvcore.common.checkpoint INFO: [Checkpointer] Loading from mobile_sam.pt ...
[12/07 20:34:01] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule sam - Total num: 171
[12/07 20:34:02] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn1.0.{bias, weight}[0m
[34mbackbone.fpn1.1.ln.{bias, weight}[0m
[34mbackbone.fpn1.3.{bias, weight}[0m
[34mbackbone.fpn2.0.{bias, weight}[0m
[34mclip.ln_final.{bias, weight}[0m
[34mclip.token_embedding.weight[0m
[34mclip.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.conv1.weight[0m
[34mclip.visual.ln_post.{bias, weight}[0m
[34mclip.visual.ln_pre.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.{class_embedding, positional_embedding, proj}[0m
[34mclip.{logit_scale, positional_embedding, text_projection}[0m
[34mcontext_former_pe[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.kv_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.ln_mask.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.logit_scale[0m
[34mroi_heads.mask_head.contextformer.q_proj.{bias, weight}[0m
[34mroi_heads.mask_head.freq_weight[0m
[34mroi_heads.mask_head.point_emb.0.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.1.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.mask_head.point_emb.4.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.6.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.8.{bias, weight}[0m
[12/07 20:34:02] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mimage_encoder.head.{bias, weight}[0m
  [35mimage_encoder.norm_head.{bias, weight}[0m
[12/07 20:34:02] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeLongestSizeFlip(longest_length=1024), RandomFlip(prob=0.5)]
[12/07 20:34:13] d2.data.datasets.coco INFO: Loading datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json takes 11.25 seconds.
[12/07 20:34:15] d2.data.datasets.coco INFO: Loaded 107761 images in COCO format from datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json
[12/07 20:34:19] d2.data.build INFO: Removed 0 images with no usable annotations. 107761 images left.
[12/07 20:34:22] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 257253       |   bicycle    | 7056         |      car      | 43533        |
|  motorcycle   | 8654         |   airplane   | 0            |      bus      | 0            |
|     train     | 4570         |    truck     | 9970         |     boat      | 10576        |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 9820         |     bird      | 10542        |
|      cat      | 0            |     dog      | 0            |     horse     | 6567         |
|     sheep     | 9223         |     cow      | 0            |   elephant    | 0            |
|     bear      | 1294         |    zebra     | 5269         |    giraffe    | 5128         |
|   backpack    | 8714         |   umbrella   | 0            |    handbag    | 12342        |
|      tie      | 0            |   suitcase   | 6112         |    frisbee    | 2681         |
|     skis      | 6623         |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 8802         | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 6095         | tennis racket | 0            |
|    bottle     | 24070        |  wine glass  | 0            |      cup      | 0            |
|     fork      | 5474         |    knife     | 0            |     spoon     | 6159         |
|     bowl      | 14323        |    banana    | 9195         |     apple     | 5776         |
|   sandwich    | 4356         |    orange    | 6302         |   broccoli    | 7261         |
|    carrot     | 7758         |   hot dog    | 0            |     pizza     | 5807         |
|     donut     | 7005         |     cake     | 0            |     chair     | 38073        |
|     couch     | 0            | potted plant | 0            |      bed      | 4192         |
| dining table  | 0            |    toilet    | 4149         |      tv       | 5803         |
|    laptop     | 4960         |    mouse     | 2261         |    remote     | 5700         |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 1672         |
|     oven      | 3334         |   toaster    | 225          |     sink      | 0            |
| refrigerator  | 2634         |     book     | 24077        |     clock     | 6320         |
|     vase      | 6577         |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 1945         |               |              |
|     total     | 656232       |              |              |               |              |[0m
[12/07 20:34:22] d2.data.build INFO: Using training sampler TrainingSampler
[12/07 20:34:22] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 20:34:22] d2.data.common INFO: Serializing 107761 elements to byte tensors and concatenating them all ...
[12/07 20:34:24] d2.data.common INFO: Serialized dataset takes 361.37 MiB
[12/07 20:34:26] detectron2 INFO: Starting training from iteration 0
[12/07 20:36:13] detectron2 INFO: Rank of current process: 0. World size: 1
[12/07 20:36:14] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 | packaged by conda-forge | (default, Oct 10 2023, 15:44:36) [GCC 12.3.0]
numpy                            1.23.4
detectron2                       0.6 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/detectron2
Compiler                         GCC 7.5
CUDA compiler                    CUDA 11.4
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          1.10.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3,4,5,6,7              NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   515.76
CUDA_HOME                        /home/xchen/cuda-11.4/
Pillow                           9.4.0
torchvision                      0.11.0 @/home/xchen/anaconda3/envs/Agri/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[12/07 20:36:14] detectron2 INFO: Command line arguments: Namespace(config_file='configs/OpenDet_tiny_coco.yaml', dist_url='tcp://127.0.0.1:50165', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2', 'OUTPUT_DIR', '.output/test'], resume=False)
[12/07 20:36:14] detectron2 INFO: Contents of args.config_file=configs/OpenDet_tiny_coco.yaml:
[38;5;245m# _BASE_: "Base_OVCOCO_C4_1x.yaml"[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSamOpenDetector[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_sam_vit_det_backbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m#SAM vit_h[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mvit_t[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mViT-B/16[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcontext_former_pe[39m[38;5;186m'[39m[38;5;15m [39m[38;5;245m# unfrozen extra part of model, the name is relative to sam and clip[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mmobile_sam.pt[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "/opt/tiger/OpenVo-Seg-master/output/wo_mask_with_prompt_encoder_roi_head_withgrad/model_final.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "sam_vit_h_4b8939.pth"[39m
[38;5;15m  [39m[38;5;245m# WEIGHTS: "output/Detic-COCO/RSPrompter_anchor/model_0000999.pth"[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m4[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m8[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m16[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m32[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m64[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mLN[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m123.675[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m116.280[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m103.530[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m58.395[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.12[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m57.375[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mDefaultAnchorGenerator[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m32[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m64[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m128[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m256[39m[38;5;15m][39m[38;5;15m,[39m[38;5;15m[[39m[38;5;15m512[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1.0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m2.0[39m[38;5;15m][39m[38;5;15m][39m[38;5;15m  [39m[38;5;245m# Three aspect ratios (same for all in feature maps)[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mSAMRPN[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStandardRPNHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat0[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m[38;5;15m  [39m[38;5;245m# Per FPN level[39m
[38;5;15m    [39m[38;5;245m# Detectron1 uses 2000 proposals per-batch,[39m
[38;5;15m    [39m[38;5;245m# (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)[39m
[38;5;15m    [39m[38;5;245m# which is approximately 1000 proposals per-image since the default batch size for FPN is 2.[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.3[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m0.7[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m[38;5;15m [39m[38;5;245m# the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbinary_ce[39m[38;5;186m"[39m[38;5;15m [39m[38;5;245m# options: centerness, binary_ce[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamAnchorPromptRoiHeads[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mfeat4[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat2[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;186m"[39m[38;5;186mfeat1[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m[38;5;15m [39m[38;5;245m#the sampling num [39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0.5[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m0[39m[38;5;15m,[39m[38;5;15m [39m[38;5;15m1[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m[38;5;15m  [39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mFastRCNNConvFCHead[39m[38;5;186m"[39m[38;5;15m  [39m[38;5;245m# Shared2FCBBoxHead[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msmooth_l1[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(10.0,[39m[38;5;141m [39m[38;5;141m10.0,[39m[38;5;141m [39m[38;5;141m5.0,[39m[38;5;141m [39m[38;5;141m5.0)[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186msamMaskHead[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mce_dice[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mROIAlignV2[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_zeroshot_train_oriorder",)[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m("coco_not_zeroshot_val",)[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m [39m[38;5;245m# num_workers == batchsize_per_gpu[39m
[38;5;15m  [39m[38;5;245m# PERSISTENT_WORKERS: True [39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m[38;5;15m  [39m[38;5;245m# change  # max 8 imgs per batch[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m[38;5;15m  [39m[38;5;245m# change0.000025[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(60000,[39m[38;5;141m [39m[38;5;141m80000)[39m[38;5;15m  [39m[38;5;245m# change [39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD [39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mlinear[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m[38;5;15m [39m[38;5;245m#1.0001[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mWarmupCosineLR[39m[38;5;186m"[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;245m# LR_SCHEDULER_NAME: "WarmupMultiStepLR"[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m[38;5;15m  [39m[38;5;245m#  change[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mADAMW[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m[38;5;15m  [39m[38;5;245m# the output freq of logger writer[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m[38;5;15m [39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(90,[39m[38;5;141m [39m[38;5;141m4)[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mRGB[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;245m# PAD_MASK: True[39m
[38;5;15m  [39m[38;5;245m# MASK_PAD_VAL: 0.0[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbitmask[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m[38;5;15m  [39m[38;5;245m#test_topk_per_image[39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m[38;5;15m  [39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m[38;5;15m [39m[38;5;245m# change[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m[38;5;15m [39m[38;5;245m#every gpu has most 2 images  # change[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mcls[39m[38;5;186m'[39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m./output/ovcoco[39m[38;5;186m'[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m

[12/07 20:36:14] detectron2 INFO: Running with full config:
[38;5;204mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;204mPERSISTENT_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_not_zeroshot_val[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mcoco_zeroshot_train_oriorder[39m
[38;5;204mFIND_UNUSED_PARAM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mFP16[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mCLIP_TRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m224[39m
[38;5;15m  [39m[38;5;204mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;204mCUSTOM_AUG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRGB[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbitmask[39m
[38;5;15m  [39m[38;5;204mMASK_PAD_VAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;204mPAD_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mPROMPT_SIZE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;15m  [39m[38;5;204mSCALE_RANGE[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mTEST_INPUT_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mResizeLongestSize[39m
[38;5;15m  [39m[38;5;204mTEST_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m  [39m[38;5;204mTRAIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;204mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mADD_UNFROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcontext_former_pe[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mViT-B/16[39m
[38;5;15m    [39m[38;5;204mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_sam_vit_det_backbone[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvit_t[39m
[38;5;15m  [39m[38;5;204mCONFIGS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mONLY_DECODER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANCHOR_STRIDE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;204mINNER_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;204mIN_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mLN[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mSELECTED_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m12[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m22[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m24[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m26[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m28[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30[39m
[38;5;15m    [39m[38;5;204mUP_SAMPLE_SCALE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSamOpenDetector[39m
[38;5;15m  [39m[38;5;204mNUM_SAMPLE_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m  [39m[38;5;204mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSAMRPN[39m
[38;5;15m  [39m[38;5;204mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;204mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;204mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;204mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;204mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;204mCAT_FREQ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdatasets/coco/zero-shot/instances_train2017_seen_2_oriorder_cat_info.json[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mIGNORE_ZERO_CATS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFastRCNNConvFCHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mALLOW_LOW_QUALITY_MATCHES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamAnchorPromptRoiHeads[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.02[39m
[38;5;15m  [39m[38;5;204mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mce_dice[39m
[38;5;15m    [39m[38;5;204mMASK_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msamMaskHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPER_QUERY_POINT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mWITH_SINCOS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;204mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfeat0[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mOBJECTNESS_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbinary_ce[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAM_FROZEN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSemSegFPNHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m54[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mmobile_sam.pt[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m.output/test[39m
[38;5;204mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0005[39m
[38;5;15m  [39m[38;5;204mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;204mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvalue[39m
[38;5;15m    [39m[38;5;204mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m  [39m[38;5;204mLOGGER_FREQ[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupCosineLR[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;204mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mADAMW[39m
[38;5;15m  [39m[38;5;204mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m60000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m80000[39m
[38;5;15m  [39m[38;5;204mUSE_CUSTOM_SOLVER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7500[39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;204mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m300[39m
[38;5;15m  [39m[38;5;204mDO_POSTPROCESS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m90000[39m
[38;5;15m  [39m[38;5;204mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mGEOMETRIC_FACT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.35[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mMASK_THR_BINARY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m  [39m[38;5;204mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;15m  [39m[38;5;204mSCORE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcls[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;204mWANDB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m

[12/07 20:36:14] detectron2 INFO: Full config saved to .output/test/config.yaml
[12/07 20:36:14] d2.utils.env INFO: Using a generated random seed 15493118
[12/07 20:36:25] detectron2 INFO: Model:
SamOpenDetector(
  (backbone): SAMVitDet(
    (fpn1): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (1): Norm2d(
        (ln): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
      )
      (2): GELU()
      (3): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn2): Sequential(
      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    )
    (fpn3): Identity()
    (fpn4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (proposal_generator): SAMRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): samAnchorPromptRoiHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): SamRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): samMaskHead(
      (point_emb): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
        (3): Flatten(start_dim=1, end_dim=-1)
        (4): Linear(in_features=12544, out_features=256, bias=True)
        (5): ReLU(inplace=True)
        (6): Linear(in_features=256, out_features=256, bias=True)
        (7): ReLU(inplace=True)
        (8): Linear(in_features=256, out_features=2048, bias=True)
      )
      (contextformer): build_contextformer(
        (decoder1): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (linear1): Linear(in_features=512, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=512, bias=True)
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (linear1): Linear(in_features=512, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=512, bias=True)
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (linear1): Linear(in_features=512, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=512, bias=True)
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (decoder2): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (linear1): Linear(in_features=512, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=512, bias=True)
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (linear1): Linear(in_features=512, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=512, bias=True)
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (linear1): Linear(in_features=512, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=512, bias=True)
              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (q_proj): Linear(in_features=256, out_features=512, bias=True)
        (kv_proj): Linear(in_features=1024, out_features=512, bias=True)
        (ln_mask): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (generator_pe): SinePositionalEncoding(num_feats=128, temperature=10000, normalize=True, scale=6.283185307179586, eps=1e-06)
  )
  (sam): Sam(
    (image_encoder): TinyViT(
      (patch_embed): PatchEmbed(
        (seq): Sequential(
          (0): Conv2d_BN(
            (c): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): GELU()
          (2): Conv2d_BN(
            (c): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (layers): ModuleList(
        (0): ConvLayer(
          (blocks): ModuleList(
            (0): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
            (1): MBConv(
              (conv1): Conv2d_BN(
                (c): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act1): GELU()
              (conv2): Conv2d_BN(
                (c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act2): GELU()
              (conv3): Conv2d_BN(
                (c): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (act3): GELU()
              (drop_path): Identity()
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (1): BasicLayer(
          dim=128, input_resolution=(128, 128), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=128, input_resolution=(128, 128), num_heads=4, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=128, out_features=384, bias=True)
                (proj): Linear(in_features=128, out_features=128, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=128, out_features=512, bias=True)
                (fc2): Linear(in_features=512, out_features=128, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(128, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (2): BasicLayer(
          dim=160, input_resolution=(64, 64), depth=6
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (4): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (5): TinyViTBlock(
              dim=160, input_resolution=(64, 64), num_heads=5, window_size=14, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=160, out_features=480, bias=True)
                (proj): Linear(in_features=160, out_features=160, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=160, out_features=640, bias=True)
                (fc2): Linear(in_features=640, out_features=160, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
          (downsample): PatchMerging(
            (act): GELU()
            (conv1): Conv2d_BN(
              (c): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv2): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (conv3): Conv2d_BN(
              (c): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (3): BasicLayer(
          dim=320, input_resolution=(64, 64), depth=2
          (blocks): ModuleList(
            (0): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): TinyViTBlock(
              dim=320, input_resolution=(64, 64), num_heads=10, window_size=7, mlp_ratio=4.0
              (drop_path): Identity()
              (attn): Attention(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (qkv): Linear(in_features=320, out_features=960, bias=True)
                (proj): Linear(in_features=320, out_features=320, bias=True)
              )
              (mlp): Mlp(
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (act): GELU()
                (drop): Dropout(p=0.0, inplace=False)
              )
              (local_conv): Conv2d_BN(
                (c): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
                (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
          )
        )
      )
      (neck): Sequential(
        (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): LayerNorm2d()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (3): LayerNorm2d()
      )
    )
    (prompt_encoder): PromptEncoder(
      (pe_layer): PositionEmbeddingRandom()
      (point_embeddings): ModuleList(
        (0): Embedding(1, 256)
        (1): Embedding(1, 256)
        (2): Embedding(1, 256)
        (3): Embedding(1, 256)
      )
      (not_a_point_embed): Embedding(1, 256)
      (mask_downscaling): Sequential(
        (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
        (4): LayerNorm2d()
        (5): GELU()
        (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (no_mask_embed): Embedding(1, 256)
    )
    (mask_decoder): MaskDecoder(
      (transformer): TwoWayTransformer(
        (layers): ModuleList(
          (0): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
          (1): TwoWayAttentionBlock(
            (self_attn): Attention(
              (q_proj): Linear(in_features=256, out_features=256, bias=True)
              (k_proj): Linear(in_features=256, out_features=256, bias=True)
              (v_proj): Linear(in_features=256, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=256, bias=True)
            )
            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_token_to_image): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (mlp): MLPBlock(
              (lin1): Linear(in_features=256, out_features=2048, bias=True)
              (lin2): Linear(in_features=2048, out_features=256, bias=True)
              (act): ReLU()
            )
            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (cross_attn_image_to_token): Attention(
              (q_proj): Linear(in_features=256, out_features=128, bias=True)
              (k_proj): Linear(in_features=256, out_features=128, bias=True)
              (v_proj): Linear(in_features=256, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=256, bias=True)
            )
          )
        )
        (final_attn_token_to_image): Attention(
          (q_proj): Linear(in_features=256, out_features=128, bias=True)
          (k_proj): Linear(in_features=256, out_features=128, bias=True)
          (v_proj): Linear(in_features=256, out_features=128, bias=True)
          (out_proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (iou_token): Embedding(1, 256)
      (mask_tokens): Embedding(4, 256)
      (output_upscaling): Sequential(
        (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm2d()
        (2): GELU()
        (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
        (4): GELU()
      )
      (output_hypernetworks_mlps): ModuleList(
        (0): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (1): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (2): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
        (3): MLP(
          (layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=32, bias=True)
          )
        )
      )
      (iou_prediction_head): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
    )
  )
  (clip): CLIP(
    (visual): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
[12/07 20:36:25] detectron2 INFO: Optimized parameters:
{'backbone.fpn1.0.bias',
 'backbone.fpn1.0.weight',
 'backbone.fpn1.1.ln.bias',
 'backbone.fpn1.1.ln.weight',
 'backbone.fpn1.3.bias',
 'backbone.fpn1.3.weight',
 'backbone.fpn2.0.bias',
 'backbone.fpn2.0.weight',
 'context_former_pe',
 'proposal_generator.rpn_head.anchor_deltas.bias',
 'proposal_generator.rpn_head.anchor_deltas.weight',
 'proposal_generator.rpn_head.conv.bias',
 'proposal_generator.rpn_head.conv.weight',
 'proposal_generator.rpn_head.objectness_logits.bias',
 'proposal_generator.rpn_head.objectness_logits.weight',
 'roi_heads.box_head.fc1.bias',
 'roi_heads.box_head.fc1.weight',
 'roi_heads.box_head.fc2.bias',
 'roi_heads.box_head.fc2.weight',
 'roi_heads.box_predictor.bbox_pred.bias',
 'roi_heads.box_predictor.bbox_pred.weight',
 'roi_heads.box_predictor.cls_score.bias',
 'roi_heads.box_predictor.cls_score.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder1.norm.bias',
 'roi_heads.mask_head.contextformer.decoder1.norm.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.linear2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm1.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm2.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.norm3.weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.in_proj_weight',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.bias',
 'roi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.weight',
 'roi_heads.mask_head.contextformer.decoder2.norm.bias',
 'roi_heads.mask_head.contextformer.decoder2.norm.weight',
 'roi_heads.mask_head.contextformer.kv_proj.bias',
 'roi_heads.mask_head.contextformer.kv_proj.weight',
 'roi_heads.mask_head.contextformer.ln_mask.bias',
 'roi_heads.mask_head.contextformer.ln_mask.weight',
 'roi_heads.mask_head.contextformer.logit_scale',
 'roi_heads.mask_head.contextformer.q_proj.bias',
 'roi_heads.mask_head.contextformer.q_proj.weight',
 'roi_heads.mask_head.point_emb.0.bias',
 'roi_heads.mask_head.point_emb.0.weight',
 'roi_heads.mask_head.point_emb.1.bias',
 'roi_heads.mask_head.point_emb.1.weight',
 'roi_heads.mask_head.point_emb.4.bias',
 'roi_heads.mask_head.point_emb.4.weight',
 'roi_heads.mask_head.point_emb.6.bias',
 'roi_heads.mask_head.point_emb.6.weight',
 'roi_heads.mask_head.point_emb.8.bias',
 'roi_heads.mask_head.point_emb.8.weight'}
[12/07 20:36:25] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from mobile_sam.pt ...
[12/07 20:36:25] fvcore.common.checkpoint INFO: [Checkpointer] Loading from mobile_sam.pt ...
[12/07 20:36:25] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule sam - Total num: 171
[12/07 20:36:25] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn1.0.{bias, weight}[0m
[34mbackbone.fpn1.1.ln.{bias, weight}[0m
[34mbackbone.fpn1.3.{bias, weight}[0m
[34mbackbone.fpn2.0.{bias, weight}[0m
[34mclip.ln_final.{bias, weight}[0m
[34mclip.token_embedding.weight[0m
[34mclip.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.conv1.weight[0m
[34mclip.visual.ln_post.{bias, weight}[0m
[34mclip.visual.ln_pre.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.0.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.1.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.10.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.11.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.2.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.3.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.4.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.5.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.6.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.7.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.8.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.out_proj.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.attn.{in_proj_bias, in_proj_weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_1.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.ln_2.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_fc.{bias, weight}[0m
[34mclip.visual.transformer.resblocks.9.mlp.c_proj.{bias, weight}[0m
[34mclip.visual.{class_embedding, positional_embedding, proj}[0m
[34mclip.{logit_scale, positional_embedding, text_projection}[0m
[34mcontext_former_pe[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.fc1.{bias, weight}[0m
[34mroi_heads.box_head.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder1.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.0.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.1.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.linear2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.multihead_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm1.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm2.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.norm3.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.out_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.layers.2.self_attn.{in_proj_bias, in_proj_weight}[0m
[34mroi_heads.mask_head.contextformer.decoder2.norm.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.kv_proj.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.ln_mask.{bias, weight}[0m
[34mroi_heads.mask_head.contextformer.logit_scale[0m
[34mroi_heads.mask_head.contextformer.q_proj.{bias, weight}[0m
[34mroi_heads.mask_head.freq_weight[0m
[34mroi_heads.mask_head.point_emb.0.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.1.{bias, running_mean, running_var, weight}[0m
[34mroi_heads.mask_head.point_emb.4.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.6.{bias, weight}[0m
[34mroi_heads.mask_head.point_emb.8.{bias, weight}[0m
[12/07 20:36:25] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mimage_encoder.head.{bias, weight}[0m
  [35mimage_encoder.norm_head.{bias, weight}[0m
[12/07 20:36:25] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeLongestSizeFlip(longest_length=1024), RandomFlip(prob=0.5)]
[12/07 20:36:36] d2.data.datasets.coco INFO: Loading datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json takes 10.97 seconds.
[12/07 20:36:38] d2.data.datasets.coco INFO: Loaded 107761 images in COCO format from datasets/coco/zero-shot/instances_train2017_seen_2_oriorder.json
[12/07 20:36:42] d2.data.build INFO: Removed 0 images with no usable annotations. 107761 images left.
[12/07 20:36:45] d2.data.build INFO: Distribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 257253       |   bicycle    | 7056         |      car      | 43533        |
|  motorcycle   | 8654         |   airplane   | 0            |      bus      | 0            |
|     train     | 4570         |    truck     | 9970         |     boat      | 10576        |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 9820         |     bird      | 10542        |
|      cat      | 0            |     dog      | 0            |     horse     | 6567         |
|     sheep     | 9223         |     cow      | 0            |   elephant    | 0            |
|     bear      | 1294         |    zebra     | 5269         |    giraffe    | 5128         |
|   backpack    | 8714         |   umbrella   | 0            |    handbag    | 12342        |
|      tie      | 0            |   suitcase   | 6112         |    frisbee    | 2681         |
|     skis      | 6623         |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 8802         | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 6095         | tennis racket | 0            |
|    bottle     | 24070        |  wine glass  | 0            |      cup      | 0            |
|     fork      | 5474         |    knife     | 0            |     spoon     | 6159         |
|     bowl      | 14323        |    banana    | 9195         |     apple     | 5776         |
|   sandwich    | 4356         |    orange    | 6302         |   broccoli    | 7261         |
|    carrot     | 7758         |   hot dog    | 0            |     pizza     | 5807         |
|     donut     | 7005         |     cake     | 0            |     chair     | 38073        |
|     couch     | 0            | potted plant | 0            |      bed      | 4192         |
| dining table  | 0            |    toilet    | 4149         |      tv       | 5803         |
|    laptop     | 4960         |    mouse     | 2261         |    remote     | 5700         |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 1672         |
|     oven      | 3334         |   toaster    | 225          |     sink      | 0            |
| refrigerator  | 2634         |     book     | 24077        |     clock     | 6320         |
|     vase      | 6577         |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 1945         |               |              |
|     total     | 656232       |              |              |               |              |[0m
[12/07 20:36:45] d2.data.build INFO: Using training sampler TrainingSampler
[12/07 20:36:45] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/07 20:36:45] d2.data.common INFO: Serializing 107761 elements to byte tensors and concatenating them all ...
[12/07 20:36:47] d2.data.common INFO: Serialized dataset takes 361.37 MiB
[12/07 20:36:49] detectron2 INFO: Starting training from iteration 0
[12/07 20:36:58] d2.utils.events INFO:  iter: 19  total_loss: 2.323  loss_box_reg: 0.0007867  loss_mask: 1.515  loss_cls: 0.03859  loss_rpn_cls: 0.6903  loss_rpn_loc: 0.03036     lr: 1.295e-06  max_mem: 4970M
[12/07 20:37:04] d2.utils.events INFO:  eta: 7:13:39  iter: 39  total_loss: 2.34  loss_box_reg: 0.0003745  loss_mask: 1.58  loss_cls: 0.01719  loss_rpn_cls: 0.6895  loss_rpn_loc: 0.03365     lr: 2.6054e-06  max_mem: 5438M
[12/07 20:37:07] d2.utils.events INFO:  eta: 4:23:24  iter: 59  total_loss: 2.25  loss_box_reg: 0.0002571  loss_mask: 1.451  loss_cls: 0.007174  loss_rpn_cls: 0.6882  loss_rpn_loc: 0.04074     lr: 3.9159e-06  max_mem: 5438M
[12/07 20:37:11] d2.utils.events INFO:  eta: 4:13:05  iter: 79  total_loss: 2.045  loss_box_reg: 0.01979  loss_mask: 1.278  loss_cls: 0.007543  loss_rpn_cls: 0.686  loss_rpn_loc: 0.05523     lr: 5.2264e-06  max_mem: 5438M
[12/07 20:37:14] d2.utils.events INFO:  eta: 4:17:10  iter: 99  total_loss: 2.04  loss_box_reg: 0.0218  loss_mask: 1.229  loss_cls: 0.007035  loss_rpn_cls: 0.6827  loss_rpn_loc: 0.04552     lr: 6.5369e-06  max_mem: 6493M
[12/07 20:37:18] d2.utils.events INFO:  eta: 4:35:26  iter: 119  total_loss: 1.966  loss_box_reg: 0.05931  loss_mask: 1.075  loss_cls: 0.006889  loss_rpn_cls: 0.6788  loss_rpn_loc: 0.03158     lr: 7.8474e-06  max_mem: 7733M
[12/07 20:37:21] d2.utils.events INFO:  eta: 4:23:18  iter: 139  total_loss: 1.804  loss_box_reg: 0.1011  loss_mask: 0.9586  loss_cls: 0.006696  loss_rpn_cls: 0.6724  loss_rpn_loc: 0.04483     lr: 9.1579e-06  max_mem: 7733M
[12/07 20:37:25] d2.utils.events INFO:  eta: 4:34:57  iter: 159  total_loss: 1.656  loss_box_reg: 0.03186  loss_mask: 0.8956  loss_cls: 0.006104  loss_rpn_cls: 0.6651  loss_rpn_loc: 0.02404     lr: 1.0468e-05  max_mem: 7733M
[12/07 20:37:29] d2.utils.events INFO:  eta: 4:44:57  iter: 179  total_loss: 1.833  loss_box_reg: 0.1359  loss_mask: 0.9493  loss_cls: 0.006069  loss_rpn_cls: 0.6562  loss_rpn_loc: 0.0467     lr: 1.1779e-05  max_mem: 7733M
[12/07 20:37:32] d2.utils.events INFO:  eta: 4:46:08  iter: 199  total_loss: 1.683  loss_box_reg: 0.08214  loss_mask: 0.8042  loss_cls: 0.005192  loss_rpn_cls: 0.6423  loss_rpn_loc: 0.04014     lr: 1.3089e-05  max_mem: 7733M
[12/07 20:37:36] d2.utils.events INFO:  eta: 4:17:14  iter: 219  total_loss: 1.681  loss_box_reg: 0.1  loss_mask: 0.8855  loss_cls: 0.005899  loss_rpn_cls: 0.6245  loss_rpn_loc: 0.03265     lr: 1.44e-05  max_mem: 7733M
[12/07 20:37:40] d2.utils.events INFO:  eta: 4:38:42  iter: 239  total_loss: 1.605  loss_box_reg: 0.07757  loss_mask: 0.8545  loss_cls: 0.005589  loss_rpn_cls: 0.5975  loss_rpn_loc: 0.03696     lr: 1.571e-05  max_mem: 7733M
[12/07 20:37:44] d2.utils.events INFO:  eta: 5:01:06  iter: 259  total_loss: 1.576  loss_box_reg: 0.1395  loss_mask: 0.8113  loss_cls: 0.005861  loss_rpn_cls: 0.5642  loss_rpn_loc: 0.03717     lr: 1.7021e-05  max_mem: 7998M
[12/07 20:37:48] d2.utils.events INFO:  eta: 5:04:00  iter: 279  total_loss: 1.637  loss_box_reg: 0.2517  loss_mask: 0.7856  loss_cls: 0.005592  loss_rpn_cls: 0.5248  loss_rpn_loc: 0.03044     lr: 1.8331e-05  max_mem: 7998M
[12/07 20:37:52] d2.utils.events INFO:  eta: 5:22:00  iter: 299  total_loss: 1.563  loss_box_reg: 0.2973  loss_mask: 0.7097  loss_cls: 0.005536  loss_rpn_cls: 0.4624  loss_rpn_loc: 0.05594     lr: 1.9642e-05  max_mem: 8013M
[12/07 20:37:56] d2.utils.events INFO:  eta: 5:15:07  iter: 319  total_loss: 1.567  loss_box_reg: 0.3166  loss_mask: 0.7669  loss_cls: 0.004894  loss_rpn_cls: 0.4095  loss_rpn_loc: 0.03349     lr: 2.0952e-05  max_mem: 8013M
[12/07 20:38:01] d2.utils.events INFO:  eta: 5:23:20  iter: 339  total_loss: 1.58  loss_box_reg: 0.452  loss_mask: 0.6987  loss_cls: 0.004545  loss_rpn_cls: 0.3626  loss_rpn_loc: 0.06666     lr: 2.2263e-05  max_mem: 8013M
[12/07 20:38:05] d2.utils.events INFO:  eta: 5:28:24  iter: 359  total_loss: 1.498  loss_box_reg: 0.4092  loss_mask: 0.6999  loss_cls: 0.004296  loss_rpn_cls: 0.2964  loss_rpn_loc: 0.05132     lr: 2.3573e-05  max_mem: 8013M
[12/07 20:38:09] d2.utils.events INFO:  eta: 5:23:18  iter: 379  total_loss: 1.501  loss_box_reg: 0.4594  loss_mask: 0.6765  loss_cls: 0.004467  loss_rpn_cls: 0.2583  loss_rpn_loc: 0.05407     lr: 2.4884e-05  max_mem: 8014M
[12/07 20:38:14] d2.utils.events INFO:  eta: 5:36:34  iter: 399  total_loss: 1.429  loss_box_reg: 0.4909  loss_mask: 0.5943  loss_cls: 0.004616  loss_rpn_cls: 0.2672  loss_rpn_loc: 0.04617     lr: 2.6194e-05  max_mem: 8014M
[12/07 20:38:18] d2.utils.events INFO:  eta: 5:22:53  iter: 419  total_loss: 1.258  loss_box_reg: 0.3383  loss_mask: 0.565  loss_cls: 0.004814  loss_rpn_cls: 0.245  loss_rpn_loc: 0.02665     lr: 2.7505e-05  max_mem: 8014M
[12/07 20:38:22] d2.utils.events INFO:  eta: 5:14:32  iter: 439  total_loss: 1.296  loss_box_reg: 0.4813  loss_mask: 0.5766  loss_cls: 0.004988  loss_rpn_cls: 0.208  loss_rpn_loc: 0.03436     lr: 2.8815e-05  max_mem: 8014M
[12/07 20:38:26] d2.utils.events INFO:  eta: 5:11:17  iter: 459  total_loss: 1.305  loss_box_reg: 0.4537  loss_mask: 0.5273  loss_cls: 0.005  loss_rpn_cls: 0.1901  loss_rpn_loc: 0.03478     lr: 3.0126e-05  max_mem: 8014M
[12/07 20:38:31] d2.utils.events INFO:  eta: 5:16:28  iter: 479  total_loss: 1.295  loss_box_reg: 0.5101  loss_mask: 0.6303  loss_cls: 0.005563  loss_rpn_cls: 0.1799  loss_rpn_loc: 0.02974     lr: 3.1436e-05  max_mem: 8014M
[12/07 20:38:35] d2.utils.events INFO:  eta: 5:27:18  iter: 499  total_loss: 1.343  loss_box_reg: 0.4854  loss_mask: 0.5566  loss_cls: 0.005188  loss_rpn_cls: 0.1961  loss_rpn_loc: 0.0393     lr: 3.2747e-05  max_mem: 8014M
[12/07 20:38:39] d2.utils.events INFO:  eta: 5:14:10  iter: 519  total_loss: 1.216  loss_box_reg: 0.4947  loss_mask: 0.4358  loss_cls: 0.005593  loss_rpn_cls: 0.1564  loss_rpn_loc: 0.01608     lr: 3.4057e-05  max_mem: 8014M
[12/07 20:38:44] d2.utils.events INFO:  eta: 5:13:48  iter: 539  total_loss: 1.148  loss_box_reg: 0.3447  loss_mask: 0.5931  loss_cls: 0.004001  loss_rpn_cls: 0.1709  loss_rpn_loc: 0.03181     lr: 3.5368e-05  max_mem: 8014M
[12/07 20:38:48] d2.utils.events INFO:  eta: 5:20:26  iter: 559  total_loss: 1.237  loss_box_reg: 0.4073  loss_mask: 0.4955  loss_cls: 0.004519  loss_rpn_cls: 0.1604  loss_rpn_loc: 0.03393     lr: 3.6678e-05  max_mem: 8014M
[12/07 20:38:52] d2.utils.events INFO:  eta: 5:25:38  iter: 579  total_loss: 1.192  loss_box_reg: 0.4305  loss_mask: 0.5796  loss_cls: 0.005123  loss_rpn_cls: 0.1384  loss_rpn_loc: 0.02491     lr: 3.7989e-05  max_mem: 8014M
[12/07 20:38:57] d2.utils.events INFO:  eta: 5:54:17  iter: 599  total_loss: 1.488  loss_box_reg: 0.5785  loss_mask: 0.5176  loss_cls: 0.00542  loss_rpn_cls: 0.1607  loss_rpn_loc: 0.02924     lr: 3.9299e-05  max_mem: 8014M
[12/07 20:39:01] d2.utils.events INFO:  eta: 5:36:29  iter: 619  total_loss: 1.273  loss_box_reg: 0.5291  loss_mask: 0.5206  loss_cls: 0.004584  loss_rpn_cls: 0.1287  loss_rpn_loc: 0.02025     lr: 4.0609e-05  max_mem: 8014M
[12/07 20:39:06] d2.utils.events INFO:  eta: 5:31:09  iter: 639  total_loss: 1.229  loss_box_reg: 0.5016  loss_mask: 0.461  loss_cls: 0.00456  loss_rpn_cls: 0.1221  loss_rpn_loc: 0.02713     lr: 4.192e-05  max_mem: 8014M
[12/07 20:39:10] d2.utils.events INFO:  eta: 4:59:07  iter: 659  total_loss: 1.021  loss_box_reg: 0.4553  loss_mask: 0.4243  loss_cls: 0.004527  loss_rpn_cls: 0.1064  loss_rpn_loc: 0.02093     lr: 4.323e-05  max_mem: 8014M
[12/07 20:39:15] d2.utils.events INFO:  eta: 6:02:21  iter: 679  total_loss: 1.47  loss_box_reg: 0.5932  loss_mask: 0.5464  loss_cls: 0.004623  loss_rpn_cls: 0.1641  loss_rpn_loc: 0.05576     lr: 4.4541e-05  max_mem: 8014M
[12/07 20:39:19] d2.utils.events INFO:  eta: 5:47:11  iter: 699  total_loss: 1.221  loss_box_reg: 0.4899  loss_mask: 0.5093  loss_cls: 0.004431  loss_rpn_cls: 0.1461  loss_rpn_loc: 0.03883     lr: 4.5851e-05  max_mem: 8014M
[12/07 20:39:24] d2.utils.events INFO:  eta: 5:08:14  iter: 719  total_loss: 1.253  loss_box_reg: 0.3889  loss_mask: 0.5348  loss_cls: 0.004535  loss_rpn_cls: 0.1278  loss_rpn_loc: 0.05022     lr: 4.7162e-05  max_mem: 8014M
[12/07 20:39:28] d2.utils.events INFO:  eta: 5:15:27  iter: 739  total_loss: 1.271  loss_box_reg: 0.589  loss_mask: 0.4925  loss_cls: 0.004373  loss_rpn_cls: 0.1049  loss_rpn_loc: 0.03191     lr: 4.8472e-05  max_mem: 8014M
[12/07 20:39:32] d2.utils.events INFO:  eta: 5:23:11  iter: 759  total_loss: 1.146  loss_box_reg: 0.4505  loss_mask: 0.5332  loss_cls: 0.003877  loss_rpn_cls: 0.129  loss_rpn_loc: 0.05135     lr: 4.9783e-05  max_mem: 8014M
[12/07 20:39:37] d2.utils.events INFO:  eta: 5:29:36  iter: 779  total_loss: 1.253  loss_box_reg: 0.5665  loss_mask: 0.526  loss_cls: 0.005266  loss_rpn_cls: 0.1013  loss_rpn_loc: 0.03137     lr: 5.1093e-05  max_mem: 8014M
[12/07 20:39:41] d2.utils.events INFO:  eta: 5:35:37  iter: 799  total_loss: 1.263  loss_box_reg: 0.6013  loss_mask: 0.468  loss_cls: 0.00408  loss_rpn_cls: 0.0979  loss_rpn_loc: 0.02843     lr: 5.2404e-05  max_mem: 8014M
[12/07 20:39:46] d2.utils.events INFO:  eta: 5:30:14  iter: 819  total_loss: 1.352  loss_box_reg: 0.5713  loss_mask: 0.5164  loss_cls: 0.004758  loss_rpn_cls: 0.1142  loss_rpn_loc: 0.03534     lr: 5.3714e-05  max_mem: 8014M
